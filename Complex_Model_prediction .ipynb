{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248b7f88",
   "metadata": {},
   "source": [
    "# Create a simple predictive model of the target variable - \"simple\" meaning choose just ONE explanatory variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "96f63c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf               \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from bioinfokit.analys import stat\n",
    "from bioinfokit import visuz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8e5eb",
   "metadata": {},
   "source": [
    "# DATASET 1 - AIRFARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9a1f2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF = pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\Airfares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0bb16bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF = ADF.drop(columns=[ 'S_CODE', 'S_CITY', 'E_CODE','E_CITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5eac1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF = pd.get_dummies(ADF, columns = ['SLOT', 'GATE', 'VACATION','SW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b06149cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# ADF_norm = pd.DataFrame(scaler.fit_transform(ADF), columns=ADF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cdff2",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6df1b7",
   "metadata": {},
   "source": [
    "# How did you choose the explanatory variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "16069c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FARE                1.000000\n",
       "DISTANCE            0.670016\n",
       "SW_No               0.543813\n",
       "COUPON              0.496537\n",
       "E_INCOME            0.326092\n",
       "E_POP               0.285043\n",
       "VACATION_No         0.276868\n",
       "SLOT_Controlled     0.209438\n",
       "S_INCOME            0.209135\n",
       "GATE_Constrained    0.208540\n",
       "S_POP               0.145097\n",
       "NEW                 0.091730\n",
       "HI                  0.025195\n",
       "PAX                -0.090705\n",
       "GATE_Free          -0.208540\n",
       "SLOT_Free          -0.209438\n",
       "VACATION_Yes       -0.276868\n",
       "SW_Yes             -0.543813\n",
       "Name: FARE, dtype: float64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choosing the variable with highest correlation - \"DISTANCE\"\n",
    "ADFcorr_matrix = ADF.corr()\n",
    "ADFcorr_matrix[\"FARE\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "28d35715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "DISTANCE=%{x}<br>FARE=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          312,
          576,
          364,
          612,
          612,
          309,
          1220,
          921,
          1249,
          964,
          2104,
          2329,
          587,
          992,
          181,
          181,
          181,
          788,
          2001,
          1866,
          2290,
          2454,
          729,
          846,
          576,
          576,
          403,
          939,
          291,
          291,
          291,
          637,
          637,
          637,
          227,
          722,
          589,
          589,
          940,
          539,
          539,
          539,
          595,
          595,
          974,
          974,
          854,
          854,
          254,
          254,
          371,
          561,
          316,
          316,
          592,
          817,
          602,
          833,
          1636,
          1636,
          1636,
          550,
          1476,
          1476,
          445,
          633,
          286,
          286,
          573,
          734,
          184,
          1559,
          805,
          805,
          354,
          1200,
          1755,
          902,
          902,
          638,
          600,
          616,
          237,
          237,
          1001,
          1139,
          548,
          578,
          1229,
          1168,
          1168,
          1118,
          1128,
          1245,
          1108,
          1108,
          1088,
          457,
          457,
          457,
          854,
          779,
          779,
          2764,
          2555,
          2401,
          2679,
          701,
          138,
          1605,
          939,
          939,
          1117,
          184,
          234,
          866,
          1102,
          430,
          167,
          167,
          241,
          943,
          1588,
          1815,
          657,
          657,
          657,
          828,
          1491,
          1941,
          844,
          280,
          865,
          865,
          303,
          685,
          407,
          407,
          458,
          541,
          639,
          652,
          1140,
          1365,
          479,
          1744,
          1087,
          2372,
          226,
          1519,
          1519,
          1831,
          1769,
          1052,
          618,
          1756,
          1222,
          238,
          238,
          308,
          673,
          1946,
          2605,
          1751,
          1751,
          2062,
          1996,
          1234,
          854,
          1988,
          2341,
          1379,
          320,
          495,
          276,
          276,
          283,
          331,
          595,
          1259,
          1187,
          1187,
          1116,
          1151,
          2336,
          1521,
          736,
          736,
          736,
          1066,
          1461,
          904,
          1114,
          342,
          342,
          857,
          693,
          530,
          401,
          1301,
          1539,
          401,
          401,
          634,
          466,
          671,
          1798,
          760,
          760,
          760,
          615,
          419,
          829,
          829,
          455,
          319,
          1678,
          1822,
          1822,
          1822,
          756,
          756,
          756,
          1515,
          1515,
          1515,
          183,
          183,
          183,
          723,
          723,
          723,
          723,
          723,
          723,
          582,
          582,
          582,
          408,
          408,
          408,
          475,
          475,
          475,
          1389,
          1389,
          1389,
          1624,
          1624,
          1624,
          492,
          492,
          492,
          1068,
          1068,
          1068,
          1076,
          1076,
          1076,
          613,
          613,
          613,
          1426,
          1426,
          1426,
          842,
          842,
          842,
          1103,
          1103,
          1103,
          2237,
          2237,
          2237,
          2467,
          2467,
          2467,
          951,
          951,
          951,
          1097,
          1097,
          1097,
          1015,
          1015,
          1015,
          1173,
          1173,
          1173,
          291,
          291,
          291,
          325,
          407,
          334,
          180,
          410,
          428,
          428,
          474,
          404,
          1119,
          995,
          995,
          756,
          902,
          802,
          984,
          1545,
          963,
          174,
          1045,
          856,
          1064,
          2035,
          2216,
          192,
          192,
          1308,
          541,
          947,
          947,
          947,
          674,
          265,
          673,
          673,
          1314,
          1568,
          450,
          997,
          1347,
          2179,
          2407,
          1026,
          979,
          872,
          327,
          1591,
          876,
          2295,
          363,
          1446,
          1446,
          1749,
          1673,
          870,
          590,
          1682,
          353,
          1014,
          1046,
          248,
          366,
          1279,
          2148,
          2148,
          2148,
          638,
          1031,
          1851,
          2083,
          525,
          483,
          412,
          412,
          325,
          325,
          325,
          325,
          831,
          264,
          344,
          1749,
          1749,
          992,
          2603,
          760,
          831,
          2444,
          2444,
          2444,
          543,
          1001,
          485,
          633,
          933,
          542,
          569,
          135,
          281,
          328,
          842,
          842,
          147,
          147,
          147,
          1075,
          356,
          606,
          636,
          636,
          1065,
          426,
          426,
          426,
          346,
          225,
          225,
          1680,
          1680,
          344,
          388,
          180,
          592,
          444,
          488,
          188,
          569,
          287,
          287,
          287,
          254,
          254,
          254,
          349,
          387,
          361,
          629,
          472,
          618,
          1588,
          1259,
          1259,
          388,
          359,
          584,
          1982,
          1982,
          1982,
          586,
          495,
          525,
          617,
          593,
          696,
          1038,
          1038,
          242,
          177,
          1074,
          1218,
          1577,
          1577,
          1577,
          1032,
          1886,
          2576,
          1724,
          1724,
          1163,
          840,
          258,
          114,
          114,
          1532,
          2433,
          2433,
          2433,
          448,
          295,
          455,
          1056,
          2137,
          2694,
          332,
          1851,
          1851,
          1463,
          960,
          2084,
          1637,
          1500,
          416,
          341,
          2579,
          1589,
          2574,
          2574,
          2574,
          2443,
          2523,
          646,
          676,
          1473,
          2682,
          296,
          1837,
          1837,
          1436,
          943,
          387,
          305,
          614,
          419,
          702,
          1042,
          1042,
          1042,
          1443,
          2182,
          2489,
          943,
          1731,
          1731,
          1662,
          1028,
          1932,
          869,
          957,
          1402,
          2411,
          2411,
          2411,
          677,
          2553,
          1103,
          225,
          471,
          257,
          257,
          492,
          556,
          785,
          447,
          682,
          244,
          1379,
          1602,
          457,
          877,
          877,
          877,
          869,
          1272,
          199,
          199,
          199,
          1054,
          399,
          414,
          1183,
          1008,
          1008,
          834,
          936,
          994,
          187,
          1108,
          1989,
          2164,
          194,
          1009,
          1009,
          1009,
          932,
          874,
          865,
          357,
          447,
          358,
          239,
          444,
          1643,
          1643,
          539,
          539,
          400,
          400,
          591,
          591,
          591,
          591,
          310,
          310,
          1185,
          1185,
          1470,
          1470,
          391,
          391,
          896,
          896,
          315,
          315,
          1213,
          1213,
          935,
          935,
          2300,
          2300,
          924,
          924,
          916,
          916,
          956,
          956,
          217,
          217,
          217,
          217,
          217,
          217,
          760,
          760,
          1970,
          1970,
          2259,
          2259,
          2428,
          2428,
          2317,
          2317,
          699,
          699,
          815,
          815,
          546,
          1193,
          1134,
          1134,
          1125,
          1030,
          1030,
          1030,
          960,
          858,
          858
         ],
         "xaxis": "x",
         "y": [
          64.11,
          174.47,
          207.76,
          85.47,
          85.47,
          56.76,
          228,
          116.54,
          172.63,
          114.76,
          158.2,
          228.99,
          79.17,
          132.05,
          117.23,
          117.23,
          117.23,
          106.11,
          181.16,
          157.5,
          200.2,
          246.85,
          99.7,
          106.77,
          113.5,
          113.5,
          69.12,
          210,
          134.3,
          134.3,
          134.3,
          118.95,
          118.95,
          118.95,
          97.96,
          237.8,
          234.15,
          234.15,
          203.17,
          250.73,
          250.73,
          250.73,
          106.6,
          106.6,
          136.27,
          136.27,
          230.87,
          230.87,
          180.56,
          180.56,
          215.83,
          197.1,
          69.1,
          69.1,
          91.83,
          111.66,
          57.62,
          104.72,
          154.74,
          154.74,
          154.74,
          77.98,
          157.2,
          157.2,
          113.2,
          143.59,
          75.07,
          75.07,
          84.46,
          113.99,
          67.17,
          320.37,
          244.5,
          244.5,
          78.62,
          210.9,
          311.46,
          174.06,
          174.06,
          155.81,
          106.56,
          110.42,
          74.28,
          74.28,
          245.28,
          256.48,
          84.23,
          105.1,
          121.09,
          153.95,
          153.95,
          207.84,
          113.39,
          126.62,
          136.68,
          136.68,
          108.15,
          180.85,
          180.85,
          180.85,
          175.81,
          240.88,
          240.88,
          183.19,
          167.16,
          177.09,
          221.89,
          233.16,
          67.1,
          349.97,
          139.56,
          139.56,
          191.63,
          65.31,
          67.78,
          204.68,
          177.22,
          109.78,
          62.63,
          62.63,
          169.58,
          105.73,
          114.13,
          153.5,
          195.64,
          195.64,
          195.64,
          97.36,
          138.08,
          157.45,
          99.43,
          87.59,
          158.63,
          158.63,
          114.93,
          116.18,
          75.71,
          75.71,
          116.57,
          110.25,
          123.27,
          127.78,
          78.24,
          116,
          72.43,
          143.62,
          80.31,
          133.35,
          52.92,
          123.74,
          123.74,
          159.12,
          115.84,
          164.88,
          89.47,
          163.78,
          112.99,
          55.57,
          55.57,
          59.77,
          76.79,
          225.56,
          301.79,
          233.78,
          233.78,
          231.97,
          179.23,
          272.06,
          129.8,
          295.49,
          193.5,
          195.28,
          101.68,
          60.26,
          68.06,
          68.06,
          60.87,
          70.62,
          97.93,
          158.5,
          168.92,
          168.92,
          185.11,
          133.98,
          207.83,
          146.36,
          190.09,
          190.09,
          190.09,
          104.87,
          154.06,
          269.43,
          258.85,
          156.93,
          156.93,
          230.71,
          133.5,
          286.54,
          232.55,
          171.67,
          246.1,
          84.21,
          84.21,
          181.99,
          166.25,
          107.86,
          181.02,
          215.01,
          215.01,
          215.01,
          87.8,
          120.7,
          132.85,
          132.85,
          84.53,
          76.81,
          202,
          208.79,
          208.79,
          208.79,
          162.28,
          162.28,
          162.28,
          287.23,
          287.23,
          287.23,
          116.78,
          116.78,
          116.78,
          159.71,
          159.71,
          159.71,
          159.71,
          159.71,
          159.71,
          205,
          205,
          205,
          143.44,
          143.44,
          143.44,
          174.87,
          174.87,
          174.87,
          304.18,
          304.18,
          304.18,
          270.36,
          270.36,
          270.36,
          209.35,
          209.35,
          209.35,
          123.18,
          123.18,
          123.18,
          143.2,
          143.2,
          143.2,
          144.6,
          144.6,
          144.6,
          349.53,
          349.53,
          349.53,
          183.43,
          183.43,
          183.43,
          223.99,
          223.99,
          223.99,
          169.41,
          169.41,
          169.41,
          326.47,
          326.47,
          326.47,
          234.31,
          234.31,
          234.31,
          124.92,
          124.92,
          124.92,
          278.39,
          278.39,
          278.39,
          208.71,
          208.71,
          208.71,
          150.13,
          150.13,
          150.13,
          56.43,
          58.03,
          53.8,
          66.14,
          96.18,
          67.77,
          67.77,
          139.81,
          92.78,
          117.97,
          121.67,
          121.67,
          138.88,
          140.9,
          104.33,
          153.58,
          201.43,
          102.95,
          45.55,
          114.5,
          150.04,
          121.35,
          117.59,
          258.43,
          96.53,
          96.53,
          204.62,
          92.35,
          123.97,
          123.97,
          123.97,
          125.09,
          138.56,
          215.06,
          215.06,
          249.45,
          335.55,
          175.66,
          132.77,
          353.56,
          165.9,
          293.21,
          152.67,
          295.46,
          114.28,
          57.05,
          200.09,
          105.41,
          197.42,
          57.33,
          152.1,
          152.1,
          166.66,
          158,
          229.84,
          133.04,
          191.66,
          60.73,
          148.28,
          85.48,
          53.07,
          51.73,
          195.91,
          273.12,
          273.12,
          273.12,
          84.15,
          81.32,
          162.53,
          291.78,
          93.55,
          186.28,
          208.86,
          208.86,
          169.9,
          169.9,
          169.9,
          169.9,
          122.62,
          134.09,
          66.88,
          279.61,
          279.61,
          188.46,
          205.51,
          69.19,
          91.97,
          302.33,
          302.33,
          302.33,
          63.76,
          114.95,
          65.8,
          79.48,
          96.58,
          68.41,
          65.84,
          88.46,
          50.38,
          176.88,
          219.38,
          219.38,
          106.29,
          106.29,
          106.29,
          108.96,
          123.44,
          140.07,
          193.67,
          193.67,
          230.56,
          154.73,
          154.73,
          154.73,
          144.86,
          109.44,
          109.44,
          125.9,
          125.9,
          54.38,
          60.28,
          47.85,
          72.42,
          44.89,
          68.59,
          42.47,
          45.11,
          218.54,
          218.54,
          218.54,
          127.38,
          127.38,
          127.38,
          52.53,
          56.91,
          56.79,
          78.67,
          57.57,
          64.39,
          179.13,
          185.65,
          185.65,
          69.6,
          57.4,
          66.46,
          259.32,
          259.32,
          259.32,
          69.95,
          73.69,
          72.22,
          65.91,
          85.19,
          78.3,
          128.36,
          128.36,
          63.69,
          63.92,
          86.71,
          130.09,
          273.53,
          273.53,
          273.53,
          118.17,
          204.35,
          291.51,
          219.63,
          219.63,
          252.97,
          134.79,
          53.14,
          70.41,
          70.41,
          251.73,
          299.17,
          299.17,
          299.17,
          57.29,
          50.1,
          58.68,
          100.8,
          248.49,
          367.72,
          83.74,
          291.66,
          291.66,
          297.83,
          168.96,
          314.88,
          241.04,
          116.52,
          72.58,
          79.23,
          261.67,
          224.17,
          374.4,
          374.4,
          374.4,
          261.74,
          326.76,
          85.52,
          81.28,
          200.41,
          402.02,
          59.8,
          294.18,
          294.18,
          325.02,
          263.48,
          55.16,
          58.98,
          92.57,
          63.39,
          63.3,
          137.25,
          137.25,
          137.25,
          142.83,
          200.2,
          297.61,
          97.46,
          260.16,
          260.16,
          239.66,
          169.92,
          285.34,
          70.16,
          101.64,
          186.96,
          289.25,
          289.25,
          289.25,
          63.06,
          238.73,
          110,
          51.3,
          199.8,
          76.96,
          76.96,
          77.62,
          188.11,
          207.17,
          77.46,
          105.13,
          56.8,
          141.48,
          210.16,
          202.77,
          261.63,
          261.63,
          261.63,
          142.98,
          137.2,
          120.84,
          120.84,
          120.84,
          119.9,
          105.45,
          87.35,
          124.82,
          127.06,
          127.06,
          106.65,
          200.69,
          107.51,
          46.32,
          125.25,
          128.97,
          224.21,
          85.62,
          123.89,
          123.89,
          123.89,
          122.99,
          119.84,
          135.76,
          49.77,
          49.02,
          54.96,
          64.97,
          100.36,
          215.57,
          215.57,
          166.67,
          166.67,
          132.79,
          132.79,
          145.61,
          145.61,
          145.61,
          145.61,
          100.95,
          100.95,
          256.86,
          256.86,
          240.48,
          240.48,
          205.96,
          205.96,
          127.67,
          127.67,
          117.35,
          117.35,
          297.2,
          297.2,
          182.56,
          182.56,
          303.82,
          303.82,
          147.8,
          147.8,
          235.1,
          235.1,
          164.3,
          164.3,
          114.35,
          114.35,
          114.35,
          114.35,
          114.35,
          114.35,
          125.8,
          125.8,
          279.83,
          279.83,
          273.83,
          273.83,
          347.82,
          347.82,
          281.06,
          281.06,
          258.37,
          258.37,
          132.94,
          132.94,
          104.11,
          127.83,
          145.53,
          145.53,
          130.15,
          129.63,
          129.63,
          129.63,
          124.87,
          129.62,
          129.62
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>OLS trendline</b><br>FARE = 0.0788191 * DISTANCE + 83.9765<br>R<sup>2</sup>=0.448921<br><br>DISTANCE=%{x}<br>FARE=%{y} <b>(trend)</b><extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          114,
          114,
          135,
          138,
          147,
          147,
          147,
          167,
          167,
          174,
          177,
          180,
          180,
          181,
          181,
          181,
          183,
          183,
          183,
          184,
          184,
          187,
          188,
          192,
          192,
          194,
          199,
          199,
          199,
          217,
          217,
          217,
          217,
          217,
          217,
          225,
          225,
          225,
          226,
          227,
          234,
          237,
          237,
          238,
          238,
          239,
          241,
          242,
          244,
          248,
          254,
          254,
          254,
          254,
          254,
          257,
          257,
          258,
          264,
          265,
          276,
          276,
          280,
          281,
          283,
          286,
          286,
          287,
          287,
          287,
          291,
          291,
          291,
          291,
          291,
          291,
          295,
          296,
          303,
          305,
          308,
          309,
          310,
          310,
          312,
          315,
          315,
          316,
          316,
          319,
          320,
          325,
          325,
          325,
          325,
          325,
          327,
          328,
          331,
          332,
          334,
          341,
          342,
          342,
          344,
          344,
          346,
          349,
          353,
          354,
          356,
          357,
          358,
          359,
          361,
          363,
          364,
          366,
          371,
          387,
          387,
          388,
          388,
          391,
          391,
          399,
          400,
          400,
          401,
          401,
          401,
          403,
          404,
          407,
          407,
          407,
          408,
          408,
          408,
          410,
          412,
          412,
          414,
          416,
          419,
          419,
          426,
          426,
          426,
          428,
          428,
          430,
          444,
          444,
          445,
          447,
          447,
          448,
          450,
          455,
          455,
          457,
          457,
          457,
          457,
          458,
          466,
          471,
          472,
          474,
          475,
          475,
          475,
          479,
          483,
          485,
          488,
          492,
          492,
          492,
          492,
          495,
          495,
          525,
          525,
          530,
          539,
          539,
          539,
          539,
          539,
          541,
          541,
          542,
          543,
          546,
          548,
          550,
          556,
          561,
          569,
          569,
          573,
          576,
          576,
          576,
          578,
          582,
          582,
          582,
          584,
          586,
          587,
          589,
          589,
          590,
          591,
          591,
          591,
          591,
          592,
          592,
          593,
          595,
          595,
          595,
          600,
          602,
          606,
          612,
          612,
          613,
          613,
          613,
          614,
          615,
          616,
          617,
          618,
          618,
          629,
          633,
          633,
          634,
          636,
          636,
          637,
          637,
          637,
          638,
          638,
          639,
          646,
          652,
          657,
          657,
          657,
          671,
          673,
          673,
          673,
          674,
          676,
          677,
          682,
          685,
          693,
          696,
          699,
          699,
          701,
          702,
          722,
          723,
          723,
          723,
          723,
          723,
          723,
          729,
          734,
          736,
          736,
          736,
          756,
          756,
          756,
          756,
          760,
          760,
          760,
          760,
          760,
          760,
          779,
          779,
          785,
          788,
          802,
          805,
          805,
          815,
          815,
          817,
          828,
          829,
          829,
          831,
          831,
          833,
          834,
          840,
          842,
          842,
          842,
          842,
          842,
          844,
          846,
          854,
          854,
          854,
          854,
          856,
          857,
          858,
          858,
          865,
          865,
          865,
          866,
          869,
          869,
          870,
          872,
          874,
          876,
          877,
          877,
          877,
          896,
          896,
          902,
          902,
          902,
          904,
          916,
          916,
          921,
          924,
          924,
          932,
          933,
          935,
          935,
          936,
          939,
          939,
          939,
          940,
          943,
          943,
          943,
          947,
          947,
          947,
          951,
          951,
          951,
          956,
          956,
          957,
          960,
          960,
          963,
          964,
          974,
          974,
          979,
          984,
          992,
          992,
          994,
          995,
          995,
          997,
          1001,
          1001,
          1008,
          1008,
          1009,
          1009,
          1009,
          1014,
          1015,
          1015,
          1015,
          1026,
          1028,
          1030,
          1030,
          1030,
          1031,
          1032,
          1038,
          1038,
          1042,
          1042,
          1042,
          1045,
          1046,
          1052,
          1054,
          1056,
          1064,
          1065,
          1066,
          1068,
          1068,
          1068,
          1074,
          1075,
          1076,
          1076,
          1076,
          1087,
          1088,
          1097,
          1097,
          1097,
          1102,
          1103,
          1103,
          1103,
          1103,
          1108,
          1108,
          1108,
          1114,
          1116,
          1117,
          1118,
          1119,
          1125,
          1128,
          1134,
          1134,
          1139,
          1140,
          1151,
          1163,
          1168,
          1168,
          1173,
          1173,
          1173,
          1183,
          1185,
          1185,
          1187,
          1187,
          1193,
          1200,
          1213,
          1213,
          1218,
          1220,
          1222,
          1229,
          1234,
          1245,
          1249,
          1259,
          1259,
          1259,
          1272,
          1279,
          1301,
          1308,
          1314,
          1347,
          1365,
          1379,
          1379,
          1389,
          1389,
          1389,
          1402,
          1426,
          1426,
          1426,
          1436,
          1443,
          1446,
          1446,
          1461,
          1463,
          1470,
          1470,
          1473,
          1476,
          1476,
          1491,
          1500,
          1515,
          1515,
          1515,
          1519,
          1519,
          1521,
          1532,
          1539,
          1545,
          1559,
          1568,
          1577,
          1577,
          1577,
          1588,
          1588,
          1589,
          1591,
          1602,
          1605,
          1624,
          1624,
          1624,
          1636,
          1636,
          1636,
          1637,
          1643,
          1643,
          1662,
          1673,
          1678,
          1680,
          1680,
          1682,
          1724,
          1724,
          1731,
          1731,
          1744,
          1749,
          1749,
          1749,
          1751,
          1751,
          1755,
          1756,
          1769,
          1798,
          1815,
          1822,
          1822,
          1822,
          1831,
          1837,
          1837,
          1851,
          1851,
          1851,
          1866,
          1886,
          1932,
          1941,
          1946,
          1970,
          1970,
          1982,
          1982,
          1982,
          1988,
          1989,
          1996,
          2001,
          2035,
          2062,
          2083,
          2084,
          2104,
          2137,
          2148,
          2148,
          2148,
          2164,
          2179,
          2182,
          2216,
          2237,
          2237,
          2237,
          2259,
          2259,
          2290,
          2295,
          2300,
          2300,
          2317,
          2317,
          2329,
          2336,
          2341,
          2372,
          2401,
          2407,
          2411,
          2411,
          2411,
          2428,
          2428,
          2433,
          2433,
          2433,
          2443,
          2444,
          2444,
          2444,
          2454,
          2467,
          2467,
          2467,
          2489,
          2523,
          2553,
          2555,
          2574,
          2574,
          2574,
          2576,
          2579,
          2603,
          2605,
          2679,
          2682,
          2694,
          2764
         ],
         "xaxis": "x",
         "y": [
          92.96191045494713,
          92.96191045494713,
          94.61711167685336,
          94.85356899426853,
          95.56294094651405,
          95.56294094651405,
          95.56294094651405,
          97.13932306261522,
          97.13932306261522,
          97.69105680325063,
          97.9275141206658,
          98.16397143808098,
          98.16397143808098,
          98.24279054388603,
          98.24279054388603,
          98.24279054388603,
          98.40042875549615,
          98.40042875549615,
          98.40042875549615,
          98.47924786130122,
          98.47924786130122,
          98.71570517871639,
          98.79452428452144,
          99.10980070774167,
          99.10980070774167,
          99.26743891935179,
          99.66153444837708,
          99.66153444837708,
          99.66153444837708,
          101.08027835286813,
          101.08027835286813,
          101.08027835286813,
          101.08027835286813,
          101.08027835286813,
          101.08027835286813,
          101.7108311993086,
          101.7108311993086,
          101.7108311993086,
          101.78965030511367,
          101.86846941091872,
          102.42020315155412,
          102.6566604689693,
          102.6566604689693,
          102.73547957477436,
          102.73547957477436,
          102.81429868057941,
          102.97193689218953,
          103.0507559979946,
          103.2083942096047,
          103.52367063282495,
          103.99658526765529,
          103.99658526765529,
          103.99658526765529,
          103.99658526765529,
          103.99658526765529,
          104.23304258507048,
          104.23304258507048,
          104.31186169087553,
          104.78477632570588,
          104.86359543151093,
          105.73060559536658,
          105.73060559536658,
          106.04588201858681,
          106.12470112439186,
          106.28233933600198,
          106.51879665341716,
          106.51879665341716,
          106.59761575922222,
          106.59761575922222,
          106.59761575922222,
          106.91289218244245,
          106.91289218244245,
          106.91289218244245,
          106.91289218244245,
          106.91289218244245,
          106.91289218244245,
          107.22816860566269,
          107.30698771146774,
          107.85872145210315,
          108.01635966371327,
          108.25281698112845,
          108.3316360869335,
          108.41045519273857,
          108.41045519273857,
          108.56809340434867,
          108.80455072176386,
          108.80455072176386,
          108.88336982756891,
          108.88336982756891,
          109.11982714498409,
          109.19864625078915,
          109.59274177981445,
          109.59274177981445,
          109.59274177981445,
          109.59274177981445,
          109.59274177981445,
          109.75037999142455,
          109.8291990972296,
          110.06565641464479,
          110.14447552044984,
          110.30211373205996,
          110.85384747269538,
          110.93266657850043,
          110.93266657850043,
          111.09030479011055,
          111.09030479011055,
          111.24794300172067,
          111.48440031913583,
          111.79967674235607,
          111.87849584816112,
          112.03613405977124,
          112.11495316557631,
          112.19377227138136,
          112.27259137718642,
          112.43022958879654,
          112.58786780040666,
          112.66668690621171,
          112.82432511782183,
          113.21842064684712,
          114.47952633972805,
          114.47952633972805,
          114.55834544553312,
          114.55834544553312,
          114.7948027629483,
          114.7948027629483,
          115.42535560938876,
          115.50417471519381,
          115.50417471519381,
          115.58299382099887,
          115.58299382099887,
          115.58299382099887,
          115.74063203260899,
          115.81945113841405,
          116.05590845582923,
          116.05590845582923,
          116.05590845582923,
          116.13472756163428,
          116.13472756163428,
          116.13472756163428,
          116.2923657732444,
          116.4500039848545,
          116.4500039848545,
          116.60764219646464,
          116.76528040807474,
          117.00173772548993,
          117.00173772548993,
          117.55347146612533,
          117.55347146612533,
          117.55347146612533,
          117.71110967773545,
          117.71110967773545,
          117.86874788934557,
          118.97221537061638,
          118.97221537061638,
          119.05103447642145,
          119.20867268803156,
          119.20867268803156,
          119.28749179383661,
          119.44513000544674,
          119.83922553447202,
          119.83922553447202,
          119.99686374608214,
          119.99686374608214,
          119.99686374608214,
          119.99686374608214,
          120.0756828518872,
          120.70623569832767,
          121.10033122735297,
          121.17915033315802,
          121.33678854476813,
          121.4156076505732,
          121.4156076505732,
          121.4156076505732,
          121.73088407379342,
          122.04616049701366,
          122.20379870862376,
          122.44025602603895,
          122.75553244925919,
          122.75553244925919,
          122.75553244925919,
          122.75553244925919,
          122.99198976667435,
          122.99198976667435,
          125.35656294082611,
          125.35656294082611,
          125.7506584698514,
          126.46003042209693,
          126.46003042209693,
          126.46003042209693,
          126.46003042209693,
          126.46003042209693,
          126.61766863370704,
          126.61766863370704,
          126.6964877395121,
          126.77530684531716,
          127.01176416273233,
          127.16940237434245,
          127.32704058595257,
          127.79995522078292,
          128.1940507498082,
          128.82460359624866,
          128.82460359624866,
          129.1398800194689,
          129.3763373368841,
          129.3763373368841,
          129.3763373368841,
          129.5339755484942,
          129.84925197171444,
          129.84925197171444,
          129.84925197171444,
          130.00689018332454,
          130.16452839493468,
          130.24334750073973,
          130.40098571234984,
          130.40098571234984,
          130.4798048181549,
          130.55862392395994,
          130.55862392395994,
          130.55862392395994,
          130.55862392395994,
          130.63744302976502,
          130.63744302976502,
          130.71626213557008,
          130.8739003471802,
          130.8739003471802,
          130.8739003471802,
          131.26799587620548,
          131.4256340878156,
          131.74091051103585,
          132.2138251458662,
          132.2138251458662,
          132.29264425167125,
          132.29264425167125,
          132.29264425167125,
          132.3714633574763,
          132.45028246328135,
          132.52910156908644,
          132.6079206748915,
          132.68673978069654,
          132.68673978069654,
          133.55374994455218,
          133.86902636777242,
          133.86902636777242,
          133.94784547357747,
          134.10548368518758,
          134.10548368518758,
          134.18430279099266,
          134.18430279099266,
          134.18430279099266,
          134.2631218967977,
          134.2631218967977,
          134.34194100260277,
          134.89367474323817,
          135.3665893780685,
          135.7606849070938,
          135.7606849070938,
          135.7606849070938,
          136.86415238836463,
          137.02179059997474,
          137.02179059997474,
          137.02179059997474,
          137.1006097057798,
          137.25824791738992,
          137.33706702319498,
          137.73116255222027,
          137.96761986963543,
          138.5981727160759,
          138.8346300334911,
          139.07108735090625,
          139.07108735090625,
          139.2287255625164,
          139.30754466832144,
          140.8839267844226,
          140.96274589022767,
          140.96274589022767,
          140.96274589022767,
          140.96274589022767,
          140.96274589022767,
          140.96274589022767,
          141.435660525058,
          141.8297560540833,
          141.9873942656934,
          141.9873942656934,
          141.9873942656934,
          143.56377638179458,
          143.56377638179458,
          143.56377638179458,
          143.56377638179458,
          143.87905280501482,
          143.87905280501482,
          143.87905280501482,
          143.87905280501482,
          143.87905280501482,
          143.87905280501482,
          145.3766158153109,
          145.3766158153109,
          145.8495304501413,
          146.08598776755645,
          147.18945524882727,
          147.42591256624246,
          147.42591256624246,
          148.21410362429305,
          148.21410362429305,
          148.37174183590315,
          149.2387519997588,
          149.31757110556384,
          149.31757110556384,
          149.47520931717395,
          149.47520931717395,
          149.63284752878408,
          149.71166663458914,
          150.18458126941948,
          150.3422194810296,
          150.3422194810296,
          150.3422194810296,
          150.3422194810296,
          150.3422194810296,
          150.49985769263972,
          150.65749590424986,
          151.2880487506903,
          151.2880487506903,
          151.2880487506903,
          151.2880487506903,
          151.44568696230044,
          151.5245060681055,
          151.60332517391055,
          151.60332517391055,
          152.15505891454595,
          152.15505891454595,
          152.15505891454595,
          152.23387802035103,
          152.4703353377662,
          152.4703353377662,
          152.54915444357124,
          152.70679265518135,
          152.86443086679148,
          153.02206907840159,
          153.10088818420667,
          153.10088818420667,
          153.10088818420667,
          154.59845119450276,
          154.59845119450276,
          155.0713658293331,
          155.0713658293331,
          155.0713658293331,
          155.2290040409432,
          156.17483331060393,
          156.17483331060393,
          156.56892883962922,
          156.80538615704438,
          156.80538615704438,
          157.43593900348486,
          157.51475810928991,
          157.67239632090002,
          157.67239632090002,
          157.75121542670507,
          157.98767274412026,
          157.98767274412026,
          157.98767274412026,
          158.06649184992534,
          158.3029491673405,
          158.3029491673405,
          158.3029491673405,
          158.61822559056074,
          158.61822559056074,
          158.61822559056074,
          158.93350201378098,
          158.93350201378098,
          158.93350201378098,
          159.32759754280625,
          159.32759754280625,
          159.4064166486113,
          159.6428739660265,
          159.6428739660265,
          159.87933128344167,
          159.95815038924673,
          160.7463414472973,
          160.7463414472973,
          161.1404369763226,
          161.5345325053479,
          162.16508535178838,
          162.16508535178838,
          162.32272356339848,
          162.40154266920354,
          162.40154266920354,
          162.55918088081364,
          162.87445730403388,
          162.87445730403388,
          163.42619104466928,
          163.42619104466928,
          163.50501015047433,
          163.50501015047433,
          163.50501015047433,
          163.89910567949966,
          163.9779247853047,
          163.9779247853047,
          163.9779247853047,
          164.84493494916035,
          165.00257316077045,
          165.16021137238056,
          165.16021137238056,
          165.16021137238056,
          165.23903047818564,
          165.3178495839907,
          165.79076421882104,
          165.79076421882104,
          166.10604064204128,
          166.10604064204128,
          166.10604064204128,
          166.34249795945647,
          166.42131706526152,
          166.89423170009186,
          167.05186991170197,
          167.2095081233121,
          167.84006096975256,
          167.91888007555764,
          167.9976991813627,
          168.1553373929728,
          168.1553373929728,
          168.1553373929728,
          168.62825202780314,
          168.70707113360822,
          168.78589023941328,
          168.78589023941328,
          168.78589023941328,
          169.65290040326892,
          169.73171950907397,
          170.4410914613195,
          170.4410914613195,
          170.4410914613195,
          170.83518699034477,
          170.91400609614982,
          170.91400609614982,
          170.91400609614982,
          170.91400609614982,
          171.30810162517514,
          171.30810162517514,
          171.30810162517514,
          171.78101626000546,
          171.9386544716156,
          172.01747357742067,
          172.09629268322573,
          172.17511178903078,
          172.64802642386113,
          172.8844837412763,
          173.35739837610663,
          173.35739837610663,
          173.75149390513195,
          173.830313010937,
          174.69732317479264,
          175.64315244445334,
          176.03724797347863,
          176.03724797347863,
          176.43134350250392,
          176.43134350250392,
          176.43134350250392,
          177.2195345605545,
          177.3771727721646,
          177.3771727721646,
          177.53481098377472,
          177.53481098377472,
          178.0077256186051,
          178.5594593592405,
          179.58410773470627,
          179.58410773470627,
          179.97820326373153,
          180.13584147534166,
          180.2934796869518,
          180.84521342758717,
          181.2393089566125,
          182.10631912046813,
          182.42159554368834,
          183.20978660173893,
          183.20978660173893,
          183.20978660173893,
          184.2344349772047,
          184.7861687178401,
          186.52018904555138,
          187.0719227861868,
          187.54483742101715,
          190.1458679125841,
          191.56461181707513,
          192.66807929834596,
          192.66807929834596,
          193.45627035639654,
          193.45627035639654,
          193.45627035639654,
          194.4809187318623,
          196.37257727118367,
          196.37257727118367,
          196.37257727118367,
          197.16076832923426,
          197.71250206986969,
          197.94895938728484,
          197.94895938728484,
          199.13124597436072,
          199.28888418597086,
          199.84061792660626,
          199.84061792660626,
          200.07707524402144,
          200.3135325614366,
          200.3135325614366,
          201.49581914851248,
          202.205191100758,
          203.3874776878339,
          203.3874776878339,
          203.3874776878339,
          203.7027541110541,
          203.7027541110541,
          203.8603923226642,
          204.72740248651985,
          205.27913622715528,
          205.75205086198562,
          206.85551834325645,
          207.56489029550198,
          208.27426224774752,
          208.27426224774752,
          208.27426224774752,
          209.14127241160315,
          209.14127241160315,
          209.2200915174082,
          209.3777297290183,
          210.24473989287395,
          210.4811972102891,
          211.97876022058523,
          211.97876022058523,
          211.97876022058523,
          212.92458949024592,
          212.92458949024592,
          212.92458949024592,
          213.00340859605097,
          213.47632323088135,
          213.47632323088135,
          214.97388624117747,
          215.8408964050331,
          216.23499193405837,
          216.39263014566853,
          216.39263014566853,
          216.55026835727864,
          219.8606708010911,
          219.8606708010911,
          220.41240454172646,
          220.41240454172646,
          221.43705291719226,
          221.83114844621753,
          221.83114844621753,
          221.83114844621753,
          221.98878665782763,
          221.98878665782763,
          222.3040630810479,
          222.38288218685295,
          223.4075305623187,
          225.6932846306654,
          227.03320942935136,
          227.5849431699868,
          227.5849431699868,
          227.5849431699868,
          228.29431512223232,
          228.7672297570627,
          228.7672297570627,
          229.8706972383335,
          229.8706972383335,
          229.8706972383335,
          231.05298382540934,
          232.6293659415105,
          236.25504480854323,
          236.96441676078877,
          237.35851228981403,
          239.2501708291354,
          239.2501708291354,
          240.1960000987961,
          240.1960000987961,
          240.1960000987961,
          240.66891473362648,
          240.74773383943153,
          241.29946758006696,
          241.69356310909222,
          244.37341270646425,
          246.5015285632008,
          248.15672978510702,
          248.23554889091207,
          249.81193100701324,
          252.41296149858016,
          253.2799716624358,
          253.2799716624358,
          253.2799716624358,
          254.54107735531676,
          255.7233639423926,
          255.95982125980782,
          258.6396708571798,
          260.294872079086,
          260.294872079086,
          260.294872079086,
          262.0288924067973,
          262.0288924067973,
          264.4722846867541,
          264.8663802157794,
          265.2604757448047,
          265.2604757448047,
          266.60040054349065,
          266.60040054349065,
          267.5462298131514,
          268.09796355378677,
          268.4920590828121,
          270.9354513627689,
          273.2212054311156,
          273.6941200659459,
          274.00939648916614,
          274.00939648916614,
          274.00939648916614,
          275.34932128785215,
          275.34932128785215,
          275.74341681687747,
          275.74341681687747,
          275.74341681687747,
          276.53160787492806,
          276.6104269807331,
          276.6104269807331,
          276.6104269807331,
          277.3986180387837,
          278.42326641424944,
          278.42326641424944,
          278.42326641424944,
          280.1572867419607,
          282.8371363393327,
          285.20170951348445,
          285.35934772509455,
          286.85691073539067,
          286.85691073539067,
          286.85691073539067,
          287.0145489470008,
          287.251006264416,
          289.1426648037374,
          289.3003030153475,
          295.1329168449218,
          295.36937416233695,
          296.3152034319977,
          301.83254083835175
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 500,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "DISTANCE"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "FARE"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"63d5bc93-2962-4182-98e4-6b30c770f09e\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"63d5bc93-2962-4182-98e4-6b30c770f09e\")) {                    Plotly.newPlot(                        \"63d5bc93-2962-4182-98e4-6b30c770f09e\",                        [{\"hovertemplate\":\"DISTANCE=%{x}<br>FARE=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[312,576,364,612,612,309,1220,921,1249,964,2104,2329,587,992,181,181,181,788,2001,1866,2290,2454,729,846,576,576,403,939,291,291,291,637,637,637,227,722,589,589,940,539,539,539,595,595,974,974,854,854,254,254,371,561,316,316,592,817,602,833,1636,1636,1636,550,1476,1476,445,633,286,286,573,734,184,1559,805,805,354,1200,1755,902,902,638,600,616,237,237,1001,1139,548,578,1229,1168,1168,1118,1128,1245,1108,1108,1088,457,457,457,854,779,779,2764,2555,2401,2679,701,138,1605,939,939,1117,184,234,866,1102,430,167,167,241,943,1588,1815,657,657,657,828,1491,1941,844,280,865,865,303,685,407,407,458,541,639,652,1140,1365,479,1744,1087,2372,226,1519,1519,1831,1769,1052,618,1756,1222,238,238,308,673,1946,2605,1751,1751,2062,1996,1234,854,1988,2341,1379,320,495,276,276,283,331,595,1259,1187,1187,1116,1151,2336,1521,736,736,736,1066,1461,904,1114,342,342,857,693,530,401,1301,1539,401,401,634,466,671,1798,760,760,760,615,419,829,829,455,319,1678,1822,1822,1822,756,756,756,1515,1515,1515,183,183,183,723,723,723,723,723,723,582,582,582,408,408,408,475,475,475,1389,1389,1389,1624,1624,1624,492,492,492,1068,1068,1068,1076,1076,1076,613,613,613,1426,1426,1426,842,842,842,1103,1103,1103,2237,2237,2237,2467,2467,2467,951,951,951,1097,1097,1097,1015,1015,1015,1173,1173,1173,291,291,291,325,407,334,180,410,428,428,474,404,1119,995,995,756,902,802,984,1545,963,174,1045,856,1064,2035,2216,192,192,1308,541,947,947,947,674,265,673,673,1314,1568,450,997,1347,2179,2407,1026,979,872,327,1591,876,2295,363,1446,1446,1749,1673,870,590,1682,353,1014,1046,248,366,1279,2148,2148,2148,638,1031,1851,2083,525,483,412,412,325,325,325,325,831,264,344,1749,1749,992,2603,760,831,2444,2444,2444,543,1001,485,633,933,542,569,135,281,328,842,842,147,147,147,1075,356,606,636,636,1065,426,426,426,346,225,225,1680,1680,344,388,180,592,444,488,188,569,287,287,287,254,254,254,349,387,361,629,472,618,1588,1259,1259,388,359,584,1982,1982,1982,586,495,525,617,593,696,1038,1038,242,177,1074,1218,1577,1577,1577,1032,1886,2576,1724,1724,1163,840,258,114,114,1532,2433,2433,2433,448,295,455,1056,2137,2694,332,1851,1851,1463,960,2084,1637,1500,416,341,2579,1589,2574,2574,2574,2443,2523,646,676,1473,2682,296,1837,1837,1436,943,387,305,614,419,702,1042,1042,1042,1443,2182,2489,943,1731,1731,1662,1028,1932,869,957,1402,2411,2411,2411,677,2553,1103,225,471,257,257,492,556,785,447,682,244,1379,1602,457,877,877,877,869,1272,199,199,199,1054,399,414,1183,1008,1008,834,936,994,187,1108,1989,2164,194,1009,1009,1009,932,874,865,357,447,358,239,444,1643,1643,539,539,400,400,591,591,591,591,310,310,1185,1185,1470,1470,391,391,896,896,315,315,1213,1213,935,935,2300,2300,924,924,916,916,956,956,217,217,217,217,217,217,760,760,1970,1970,2259,2259,2428,2428,2317,2317,699,699,815,815,546,1193,1134,1134,1125,1030,1030,1030,960,858,858],\"xaxis\":\"x\",\"y\":[64.11,174.47,207.76,85.47,85.47,56.76,228.0,116.54,172.63,114.76,158.2,228.99,79.17,132.05,117.23,117.23,117.23,106.11,181.16,157.5,200.2,246.85,99.7,106.77,113.5,113.5,69.12,210.0,134.3,134.3,134.3,118.95,118.95,118.95,97.96,237.8,234.15,234.15,203.17,250.73,250.73,250.73,106.6,106.6,136.27,136.27,230.87,230.87,180.56,180.56,215.83,197.1,69.1,69.1,91.83,111.66,57.62,104.72,154.74,154.74,154.74,77.98,157.2,157.2,113.2,143.59,75.07,75.07,84.46,113.99,67.17,320.37,244.5,244.5,78.62,210.9,311.46,174.06,174.06,155.81,106.56,110.42,74.28,74.28,245.28,256.48,84.23,105.1,121.09,153.95,153.95,207.84,113.39,126.62,136.68,136.68,108.15,180.85,180.85,180.85,175.81,240.88,240.88,183.19,167.16,177.09,221.89,233.16,67.1,349.97,139.56,139.56,191.63,65.31,67.78,204.68,177.22,109.78,62.63,62.63,169.58,105.73,114.13,153.5,195.64,195.64,195.64,97.36,138.08,157.45,99.43,87.59,158.63,158.63,114.93,116.18,75.71,75.71,116.57,110.25,123.27,127.78,78.24,116.0,72.43,143.62,80.31,133.35,52.92,123.74,123.74,159.12,115.84,164.88,89.47,163.78,112.99,55.57,55.57,59.77,76.79,225.56,301.79,233.78,233.78,231.97,179.23,272.06,129.8,295.49,193.5,195.28,101.68,60.26,68.06,68.06,60.87,70.62,97.93,158.5,168.92,168.92,185.11,133.98,207.83,146.36,190.09,190.09,190.09,104.87,154.06,269.43,258.85,156.93,156.93,230.71,133.5,286.54,232.55,171.67,246.1,84.21,84.21,181.99,166.25,107.86,181.02,215.01,215.01,215.01,87.8,120.7,132.85,132.85,84.53,76.81,202.0,208.79,208.79,208.79,162.28,162.28,162.28,287.23,287.23,287.23,116.78,116.78,116.78,159.71,159.71,159.71,159.71,159.71,159.71,205.0,205.0,205.0,143.44,143.44,143.44,174.87,174.87,174.87,304.18,304.18,304.18,270.36,270.36,270.36,209.35,209.35,209.35,123.18,123.18,123.18,143.2,143.2,143.2,144.6,144.6,144.6,349.53,349.53,349.53,183.43,183.43,183.43,223.99,223.99,223.99,169.41,169.41,169.41,326.47,326.47,326.47,234.31,234.31,234.31,124.92,124.92,124.92,278.39,278.39,278.39,208.71,208.71,208.71,150.13,150.13,150.13,56.43,58.03,53.8,66.14,96.18,67.77,67.77,139.81,92.78,117.97,121.67,121.67,138.88,140.9,104.33,153.58,201.43,102.95,45.55,114.5,150.04,121.35,117.59,258.43,96.53,96.53,204.62,92.35,123.97,123.97,123.97,125.09,138.56,215.06,215.06,249.45,335.55,175.66,132.77,353.56,165.9,293.21,152.67,295.46,114.28,57.05,200.09,105.41,197.42,57.33,152.1,152.1,166.66,158.0,229.84,133.04,191.66,60.73,148.28,85.48,53.07,51.73,195.91,273.12,273.12,273.12,84.15,81.32,162.53,291.78,93.55,186.28,208.86,208.86,169.9,169.9,169.9,169.9,122.62,134.09,66.88,279.61,279.61,188.46,205.51,69.19,91.97,302.33,302.33,302.33,63.76,114.95,65.8,79.48,96.58,68.41,65.84,88.46,50.38,176.88,219.38,219.38,106.29,106.29,106.29,108.96,123.44,140.07,193.67,193.67,230.56,154.73,154.73,154.73,144.86,109.44,109.44,125.9,125.9,54.38,60.28,47.85,72.42,44.89,68.59,42.47,45.11,218.54,218.54,218.54,127.38,127.38,127.38,52.53,56.91,56.79,78.67,57.57,64.39,179.13,185.65,185.65,69.6,57.4,66.46,259.32,259.32,259.32,69.95,73.69,72.22,65.91,85.19,78.3,128.36,128.36,63.69,63.92,86.71,130.09,273.53,273.53,273.53,118.17,204.35,291.51,219.63,219.63,252.97,134.79,53.14,70.41,70.41,251.73,299.17,299.17,299.17,57.29,50.1,58.68,100.8,248.49,367.72,83.74,291.66,291.66,297.83,168.96,314.88,241.04,116.52,72.58,79.23,261.67,224.17,374.4,374.4,374.4,261.74,326.76,85.52,81.28,200.41,402.02,59.8,294.18,294.18,325.02,263.48,55.16,58.98,92.57,63.39,63.3,137.25,137.25,137.25,142.83,200.2,297.61,97.46,260.16,260.16,239.66,169.92,285.34,70.16,101.64,186.96,289.25,289.25,289.25,63.06,238.73,110.0,51.3,199.8,76.96,76.96,77.62,188.11,207.17,77.46,105.13,56.8,141.48,210.16,202.77,261.63,261.63,261.63,142.98,137.2,120.84,120.84,120.84,119.9,105.45,87.35,124.82,127.06,127.06,106.65,200.69,107.51,46.32,125.25,128.97,224.21,85.62,123.89,123.89,123.89,122.99,119.84,135.76,49.77,49.02,54.96,64.97,100.36,215.57,215.57,166.67,166.67,132.79,132.79,145.61,145.61,145.61,145.61,100.95,100.95,256.86,256.86,240.48,240.48,205.96,205.96,127.67,127.67,117.35,117.35,297.2,297.2,182.56,182.56,303.82,303.82,147.8,147.8,235.1,235.1,164.3,164.3,114.35,114.35,114.35,114.35,114.35,114.35,125.8,125.8,279.83,279.83,273.83,273.83,347.82,347.82,281.06,281.06,258.37,258.37,132.94,132.94,104.11,127.83,145.53,145.53,130.15,129.63,129.63,129.63,124.87,129.62,129.62],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>OLS trendline</b><br>FARE = 0.0788191 * DISTANCE + 83.9765<br>R<sup>2</sup>=0.448921<br><br>DISTANCE=%{x}<br>FARE=%{y} <b>(trend)</b><extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[114,114,135,138,147,147,147,167,167,174,177,180,180,181,181,181,183,183,183,184,184,187,188,192,192,194,199,199,199,217,217,217,217,217,217,225,225,225,226,227,234,237,237,238,238,239,241,242,244,248,254,254,254,254,254,257,257,258,264,265,276,276,280,281,283,286,286,287,287,287,291,291,291,291,291,291,295,296,303,305,308,309,310,310,312,315,315,316,316,319,320,325,325,325,325,325,327,328,331,332,334,341,342,342,344,344,346,349,353,354,356,357,358,359,361,363,364,366,371,387,387,388,388,391,391,399,400,400,401,401,401,403,404,407,407,407,408,408,408,410,412,412,414,416,419,419,426,426,426,428,428,430,444,444,445,447,447,448,450,455,455,457,457,457,457,458,466,471,472,474,475,475,475,479,483,485,488,492,492,492,492,495,495,525,525,530,539,539,539,539,539,541,541,542,543,546,548,550,556,561,569,569,573,576,576,576,578,582,582,582,584,586,587,589,589,590,591,591,591,591,592,592,593,595,595,595,600,602,606,612,612,613,613,613,614,615,616,617,618,618,629,633,633,634,636,636,637,637,637,638,638,639,646,652,657,657,657,671,673,673,673,674,676,677,682,685,693,696,699,699,701,702,722,723,723,723,723,723,723,729,734,736,736,736,756,756,756,756,760,760,760,760,760,760,779,779,785,788,802,805,805,815,815,817,828,829,829,831,831,833,834,840,842,842,842,842,842,844,846,854,854,854,854,856,857,858,858,865,865,865,866,869,869,870,872,874,876,877,877,877,896,896,902,902,902,904,916,916,921,924,924,932,933,935,935,936,939,939,939,940,943,943,943,947,947,947,951,951,951,956,956,957,960,960,963,964,974,974,979,984,992,992,994,995,995,997,1001,1001,1008,1008,1009,1009,1009,1014,1015,1015,1015,1026,1028,1030,1030,1030,1031,1032,1038,1038,1042,1042,1042,1045,1046,1052,1054,1056,1064,1065,1066,1068,1068,1068,1074,1075,1076,1076,1076,1087,1088,1097,1097,1097,1102,1103,1103,1103,1103,1108,1108,1108,1114,1116,1117,1118,1119,1125,1128,1134,1134,1139,1140,1151,1163,1168,1168,1173,1173,1173,1183,1185,1185,1187,1187,1193,1200,1213,1213,1218,1220,1222,1229,1234,1245,1249,1259,1259,1259,1272,1279,1301,1308,1314,1347,1365,1379,1379,1389,1389,1389,1402,1426,1426,1426,1436,1443,1446,1446,1461,1463,1470,1470,1473,1476,1476,1491,1500,1515,1515,1515,1519,1519,1521,1532,1539,1545,1559,1568,1577,1577,1577,1588,1588,1589,1591,1602,1605,1624,1624,1624,1636,1636,1636,1637,1643,1643,1662,1673,1678,1680,1680,1682,1724,1724,1731,1731,1744,1749,1749,1749,1751,1751,1755,1756,1769,1798,1815,1822,1822,1822,1831,1837,1837,1851,1851,1851,1866,1886,1932,1941,1946,1970,1970,1982,1982,1982,1988,1989,1996,2001,2035,2062,2083,2084,2104,2137,2148,2148,2148,2164,2179,2182,2216,2237,2237,2237,2259,2259,2290,2295,2300,2300,2317,2317,2329,2336,2341,2372,2401,2407,2411,2411,2411,2428,2428,2433,2433,2433,2443,2444,2444,2444,2454,2467,2467,2467,2489,2523,2553,2555,2574,2574,2574,2576,2579,2603,2605,2679,2682,2694,2764],\"xaxis\":\"x\",\"y\":[92.96191045494713,92.96191045494713,94.61711167685336,94.85356899426853,95.56294094651405,95.56294094651405,95.56294094651405,97.13932306261522,97.13932306261522,97.69105680325063,97.9275141206658,98.16397143808098,98.16397143808098,98.24279054388603,98.24279054388603,98.24279054388603,98.40042875549615,98.40042875549615,98.40042875549615,98.47924786130122,98.47924786130122,98.71570517871639,98.79452428452144,99.10980070774167,99.10980070774167,99.26743891935179,99.66153444837708,99.66153444837708,99.66153444837708,101.08027835286813,101.08027835286813,101.08027835286813,101.08027835286813,101.08027835286813,101.08027835286813,101.7108311993086,101.7108311993086,101.7108311993086,101.78965030511367,101.86846941091872,102.42020315155412,102.6566604689693,102.6566604689693,102.73547957477436,102.73547957477436,102.81429868057941,102.97193689218953,103.0507559979946,103.2083942096047,103.52367063282495,103.99658526765529,103.99658526765529,103.99658526765529,103.99658526765529,103.99658526765529,104.23304258507048,104.23304258507048,104.31186169087553,104.78477632570588,104.86359543151093,105.73060559536658,105.73060559536658,106.04588201858681,106.12470112439186,106.28233933600198,106.51879665341716,106.51879665341716,106.59761575922222,106.59761575922222,106.59761575922222,106.91289218244245,106.91289218244245,106.91289218244245,106.91289218244245,106.91289218244245,106.91289218244245,107.22816860566269,107.30698771146774,107.85872145210315,108.01635966371327,108.25281698112845,108.3316360869335,108.41045519273857,108.41045519273857,108.56809340434867,108.80455072176386,108.80455072176386,108.88336982756891,108.88336982756891,109.11982714498409,109.19864625078915,109.59274177981445,109.59274177981445,109.59274177981445,109.59274177981445,109.59274177981445,109.75037999142455,109.8291990972296,110.06565641464479,110.14447552044984,110.30211373205996,110.85384747269538,110.93266657850043,110.93266657850043,111.09030479011055,111.09030479011055,111.24794300172067,111.48440031913583,111.79967674235607,111.87849584816112,112.03613405977124,112.11495316557631,112.19377227138136,112.27259137718642,112.43022958879654,112.58786780040666,112.66668690621171,112.82432511782183,113.21842064684712,114.47952633972805,114.47952633972805,114.55834544553312,114.55834544553312,114.7948027629483,114.7948027629483,115.42535560938876,115.50417471519381,115.50417471519381,115.58299382099887,115.58299382099887,115.58299382099887,115.74063203260899,115.81945113841405,116.05590845582923,116.05590845582923,116.05590845582923,116.13472756163428,116.13472756163428,116.13472756163428,116.2923657732444,116.4500039848545,116.4500039848545,116.60764219646464,116.76528040807474,117.00173772548993,117.00173772548993,117.55347146612533,117.55347146612533,117.55347146612533,117.71110967773545,117.71110967773545,117.86874788934557,118.97221537061638,118.97221537061638,119.05103447642145,119.20867268803156,119.20867268803156,119.28749179383661,119.44513000544674,119.83922553447202,119.83922553447202,119.99686374608214,119.99686374608214,119.99686374608214,119.99686374608214,120.0756828518872,120.70623569832767,121.10033122735297,121.17915033315802,121.33678854476813,121.4156076505732,121.4156076505732,121.4156076505732,121.73088407379342,122.04616049701366,122.20379870862376,122.44025602603895,122.75553244925919,122.75553244925919,122.75553244925919,122.75553244925919,122.99198976667435,122.99198976667435,125.35656294082611,125.35656294082611,125.7506584698514,126.46003042209693,126.46003042209693,126.46003042209693,126.46003042209693,126.46003042209693,126.61766863370704,126.61766863370704,126.6964877395121,126.77530684531716,127.01176416273233,127.16940237434245,127.32704058595257,127.79995522078292,128.1940507498082,128.82460359624866,128.82460359624866,129.1398800194689,129.3763373368841,129.3763373368841,129.3763373368841,129.5339755484942,129.84925197171444,129.84925197171444,129.84925197171444,130.00689018332454,130.16452839493468,130.24334750073973,130.40098571234984,130.40098571234984,130.4798048181549,130.55862392395994,130.55862392395994,130.55862392395994,130.55862392395994,130.63744302976502,130.63744302976502,130.71626213557008,130.8739003471802,130.8739003471802,130.8739003471802,131.26799587620548,131.4256340878156,131.74091051103585,132.2138251458662,132.2138251458662,132.29264425167125,132.29264425167125,132.29264425167125,132.3714633574763,132.45028246328135,132.52910156908644,132.6079206748915,132.68673978069654,132.68673978069654,133.55374994455218,133.86902636777242,133.86902636777242,133.94784547357747,134.10548368518758,134.10548368518758,134.18430279099266,134.18430279099266,134.18430279099266,134.2631218967977,134.2631218967977,134.34194100260277,134.89367474323817,135.3665893780685,135.7606849070938,135.7606849070938,135.7606849070938,136.86415238836463,137.02179059997474,137.02179059997474,137.02179059997474,137.1006097057798,137.25824791738992,137.33706702319498,137.73116255222027,137.96761986963543,138.5981727160759,138.8346300334911,139.07108735090625,139.07108735090625,139.2287255625164,139.30754466832144,140.8839267844226,140.96274589022767,140.96274589022767,140.96274589022767,140.96274589022767,140.96274589022767,140.96274589022767,141.435660525058,141.8297560540833,141.9873942656934,141.9873942656934,141.9873942656934,143.56377638179458,143.56377638179458,143.56377638179458,143.56377638179458,143.87905280501482,143.87905280501482,143.87905280501482,143.87905280501482,143.87905280501482,143.87905280501482,145.3766158153109,145.3766158153109,145.8495304501413,146.08598776755645,147.18945524882727,147.42591256624246,147.42591256624246,148.21410362429305,148.21410362429305,148.37174183590315,149.2387519997588,149.31757110556384,149.31757110556384,149.47520931717395,149.47520931717395,149.63284752878408,149.71166663458914,150.18458126941948,150.3422194810296,150.3422194810296,150.3422194810296,150.3422194810296,150.3422194810296,150.49985769263972,150.65749590424986,151.2880487506903,151.2880487506903,151.2880487506903,151.2880487506903,151.44568696230044,151.5245060681055,151.60332517391055,151.60332517391055,152.15505891454595,152.15505891454595,152.15505891454595,152.23387802035103,152.4703353377662,152.4703353377662,152.54915444357124,152.70679265518135,152.86443086679148,153.02206907840159,153.10088818420667,153.10088818420667,153.10088818420667,154.59845119450276,154.59845119450276,155.0713658293331,155.0713658293331,155.0713658293331,155.2290040409432,156.17483331060393,156.17483331060393,156.56892883962922,156.80538615704438,156.80538615704438,157.43593900348486,157.51475810928991,157.67239632090002,157.67239632090002,157.75121542670507,157.98767274412026,157.98767274412026,157.98767274412026,158.06649184992534,158.3029491673405,158.3029491673405,158.3029491673405,158.61822559056074,158.61822559056074,158.61822559056074,158.93350201378098,158.93350201378098,158.93350201378098,159.32759754280625,159.32759754280625,159.4064166486113,159.6428739660265,159.6428739660265,159.87933128344167,159.95815038924673,160.7463414472973,160.7463414472973,161.1404369763226,161.5345325053479,162.16508535178838,162.16508535178838,162.32272356339848,162.40154266920354,162.40154266920354,162.55918088081364,162.87445730403388,162.87445730403388,163.42619104466928,163.42619104466928,163.50501015047433,163.50501015047433,163.50501015047433,163.89910567949966,163.9779247853047,163.9779247853047,163.9779247853047,164.84493494916035,165.00257316077045,165.16021137238056,165.16021137238056,165.16021137238056,165.23903047818564,165.3178495839907,165.79076421882104,165.79076421882104,166.10604064204128,166.10604064204128,166.10604064204128,166.34249795945647,166.42131706526152,166.89423170009186,167.05186991170197,167.2095081233121,167.84006096975256,167.91888007555764,167.9976991813627,168.1553373929728,168.1553373929728,168.1553373929728,168.62825202780314,168.70707113360822,168.78589023941328,168.78589023941328,168.78589023941328,169.65290040326892,169.73171950907397,170.4410914613195,170.4410914613195,170.4410914613195,170.83518699034477,170.91400609614982,170.91400609614982,170.91400609614982,170.91400609614982,171.30810162517514,171.30810162517514,171.30810162517514,171.78101626000546,171.9386544716156,172.01747357742067,172.09629268322573,172.17511178903078,172.64802642386113,172.8844837412763,173.35739837610663,173.35739837610663,173.75149390513195,173.830313010937,174.69732317479264,175.64315244445334,176.03724797347863,176.03724797347863,176.43134350250392,176.43134350250392,176.43134350250392,177.2195345605545,177.3771727721646,177.3771727721646,177.53481098377472,177.53481098377472,178.0077256186051,178.5594593592405,179.58410773470627,179.58410773470627,179.97820326373153,180.13584147534166,180.2934796869518,180.84521342758717,181.2393089566125,182.10631912046813,182.42159554368834,183.20978660173893,183.20978660173893,183.20978660173893,184.2344349772047,184.7861687178401,186.52018904555138,187.0719227861868,187.54483742101715,190.1458679125841,191.56461181707513,192.66807929834596,192.66807929834596,193.45627035639654,193.45627035639654,193.45627035639654,194.4809187318623,196.37257727118367,196.37257727118367,196.37257727118367,197.16076832923426,197.71250206986969,197.94895938728484,197.94895938728484,199.13124597436072,199.28888418597086,199.84061792660626,199.84061792660626,200.07707524402144,200.3135325614366,200.3135325614366,201.49581914851248,202.205191100758,203.3874776878339,203.3874776878339,203.3874776878339,203.7027541110541,203.7027541110541,203.8603923226642,204.72740248651985,205.27913622715528,205.75205086198562,206.85551834325645,207.56489029550198,208.27426224774752,208.27426224774752,208.27426224774752,209.14127241160315,209.14127241160315,209.2200915174082,209.3777297290183,210.24473989287395,210.4811972102891,211.97876022058523,211.97876022058523,211.97876022058523,212.92458949024592,212.92458949024592,212.92458949024592,213.00340859605097,213.47632323088135,213.47632323088135,214.97388624117747,215.8408964050331,216.23499193405837,216.39263014566853,216.39263014566853,216.55026835727864,219.8606708010911,219.8606708010911,220.41240454172646,220.41240454172646,221.43705291719226,221.83114844621753,221.83114844621753,221.83114844621753,221.98878665782763,221.98878665782763,222.3040630810479,222.38288218685295,223.4075305623187,225.6932846306654,227.03320942935136,227.5849431699868,227.5849431699868,227.5849431699868,228.29431512223232,228.7672297570627,228.7672297570627,229.8706972383335,229.8706972383335,229.8706972383335,231.05298382540934,232.6293659415105,236.25504480854323,236.96441676078877,237.35851228981403,239.2501708291354,239.2501708291354,240.1960000987961,240.1960000987961,240.1960000987961,240.66891473362648,240.74773383943153,241.29946758006696,241.69356310909222,244.37341270646425,246.5015285632008,248.15672978510702,248.23554889091207,249.81193100701324,252.41296149858016,253.2799716624358,253.2799716624358,253.2799716624358,254.54107735531676,255.7233639423926,255.95982125980782,258.6396708571798,260.294872079086,260.294872079086,260.294872079086,262.0288924067973,262.0288924067973,264.4722846867541,264.8663802157794,265.2604757448047,265.2604757448047,266.60040054349065,266.60040054349065,267.5462298131514,268.09796355378677,268.4920590828121,270.9354513627689,273.2212054311156,273.6941200659459,274.00939648916614,274.00939648916614,274.00939648916614,275.34932128785215,275.34932128785215,275.74341681687747,275.74341681687747,275.74341681687747,276.53160787492806,276.6104269807331,276.6104269807331,276.6104269807331,277.3986180387837,278.42326641424944,278.42326641424944,278.42326641424944,280.1572867419607,282.8371363393327,285.20170951348445,285.35934772509455,286.85691073539067,286.85691073539067,286.85691073539067,287.0145489470008,287.251006264416,289.1426648037374,289.3003030153475,295.1329168449218,295.36937416233695,296.3152034319977,301.83254083835175],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DISTANCE\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"FARE\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('63d5bc93-2962-4182-98e4-6b30c770f09e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(ADF, \n",
    "                 x=\"DISTANCE\", \n",
    "                 y=\"FARE\", \n",
    "                 height=500,\n",
    "                 trendline='ols',\n",
    "                 template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# showing positively correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bac0c8",
   "metadata": {},
   "source": [
    "# 1. Create a simple predictive model of the target variable - \"simple\" meaning choose just ONE explanatory variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fdf10613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ADF[['DISTANCE']].values\n",
    "y = ADF[['FARE']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "85d9d363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c72a12a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model1=LinearRegression()\n",
    "linear_model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "14443215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 55.8668\n",
      "            Mean Absolute Error (MAE) : 46.0702\n",
      "          Mean Percentage Error (MPE) : -14.9004\n",
      "Mean Absolute Percentage Error (MAPE) : 35.3175\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -3.1413\n",
      "       Root Mean Squared Error (RMSE) : 58.0845\n",
      "            Mean Absolute Error (MAE) : 50.4340\n",
      "          Mean Percentage Error (MPE) : -16.9390\n",
      "Mean Absolute Percentage Error (MAPE) : 38.0777\n"
     ]
    }
   ],
   "source": [
    "from dmba import regressionSummary\n",
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model1.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0ed7dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.46374225175587347\n",
      "R2 for testing dataset 0.39902908644846047\n"
     ]
    }
   ],
   "source": [
    "#R-squared values for train & test data set.\n",
    "\n",
    "y_pred_train = linear_model1.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model1.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eb5690ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1b = ADF['DISTANCE']\n",
    "y1b = ADF['FARE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "306660a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1b, y1b, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "185a638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "38513dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>FARE</td>       <th>  R-squared:         </th> <td>   0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   411.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>2.09e-66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:23:07</td>     <th>  Log-Likelihood:    </th> <td> -2601.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   478</td>      <th>  AIC:               </th> <td>   5206.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   476</td>      <th>  BIC:               </th> <td>   5215.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   81.7647</td> <td>    4.632</td> <td>   17.652</td> <td> 0.000</td> <td>   72.663</td> <td>   90.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DISTANCE</th> <td>    0.0819</td> <td>    0.004</td> <td>   20.289</td> <td> 0.000</td> <td>    0.074</td> <td>    0.090</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>22.465</td> <th>  Durbin-Watson:     </th> <td>   2.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.531</td> <th>  Prob(JB):          </th> <td>5.69e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.711</td> <th>  Cond. No.          </th> <td>2.08e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.08e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   FARE   R-squared:                       0.464\n",
       "Model:                            OLS   Adj. R-squared:                  0.463\n",
       "Method:                 Least Squares   F-statistic:                     411.6\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):           2.09e-66\n",
       "Time:                        11:23:07   Log-Likelihood:                -2601.2\n",
       "No. Observations:                 478   AIC:                             5206.\n",
       "Df Residuals:                     476   BIC:                             5215.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         81.7647      4.632     17.652      0.000      72.663      90.866\n",
       "DISTANCE       0.0819      0.004     20.289      0.000       0.074       0.090\n",
       "==============================================================================\n",
       "Omnibus:                       22.465   Durbin-Watson:                   2.307\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.155\n",
       "Skew:                           0.531   Prob(JB):                     5.69e-06\n",
       "Kurtosis:                       2.711   Cond. No.                     2.08e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.08e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for checking the p-values checking OLS summary\n",
    "linear_model1b=sm.OLS(y_train,X_train).fit()\n",
    "linear_model1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e99a895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [81.76468303]\n",
      "coefficient [[0.08189359]]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', linear_model1.intercept_) # Printing the interecept for linear regression\n",
    "print('coefficient', linear_model1.coef_ )    # Printing the coefficient for linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5ff7acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form Dataset 1(A)=> FARE = [81.76468303] + [[0.08189359]] * DISTANCE\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form Dataset 1(A)=>','FARE =', linear_model1.intercept_, '+', linear_model1.coef_,'* DISTANCE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c553bc6",
   "metadata": {},
   "source": [
    "# Does your model under or overfit the data?  How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18439ede",
   "metadata": {},
   "source": [
    "No I don't the model overfits or underfits as there is not much diference in the MAPE value of Training and Testing datasets as we calculated above. I think model is working fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd1a48",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13065b6",
   "metadata": {},
   "source": [
    "# Create a slightly more complicated predictive model of the target variable.  In particular, add 1-3 more variables that you think have potential to improve your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fb0bb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF = pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\Airfares.csv')\n",
    "\n",
    "ADF = ADF.drop(columns=[ 'S_CODE', 'S_CITY', 'E_CODE','E_CITY'])\n",
    "\n",
    "ADF = pd.get_dummies(ADF, columns = ['SLOT', 'GATE', 'VACATION','SW'])\n",
    "\n",
    "X1 = ADF.drop(columns=['FARE'])\n",
    "y1 = ADF['FARE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cc8e6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0a5aad9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.8s finished\n",
      "\n",
      "[2022-11-03 11:32:15] Features: 1/5 -- score: 0.4354576560486362[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:15] Features: 2/5 -- score: 0.5880761592999174[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:15] Features: 3/5 -- score: 0.7004572411719286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 4/5 -- score: 0.7189046256404406[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 5/5 -- score: 0.7289393215943825"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# selecting 5 best features - forward selection\n",
    "Forward_Selection = SFS(linear_model1,\n",
    "                        k_features=(1,5),\n",
    "                        forward=True,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring=\"r2\",\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fee947d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 16/1 -- score: 0.7579533855483624[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 15/1 -- score: 0.7581103256690737[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 14/1 -- score: 0.7582560096600284[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 13/1 -- score: 0.7582560096600288[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 12/1 -- score: 0.7582560096600286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 11/1 -- score: 0.7582560096600275[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 10/1 -- score: 0.7582560096600268[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 9/1 -- score: 0.7577014567570461[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 8/1 -- score: 0.7499711169501924[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 7/1 -- score: 0.7467417454316363[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 6/1 -- score: 0.7359054870157412[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 5/1 -- score: 0.7258026287805537[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 4/1 -- score: 0.7189046256404406[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 3/1 -- score: 0.7004572411719286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 2/1 -- score: 0.5880761592999174[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:32:16] Features: 1/1 -- score: 0.4354576560486362"
     ]
    }
   ],
   "source": [
    "# selecting 5 best features - backward selection\n",
    "Backward_Selection = SFS(linear_model1,\n",
    "                        k_features=(1,6),\n",
    "                        forward=False,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring='r2',\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3620f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for backward selected features 0.7359054870157412\n",
      "\n",
      "Backard selected features ('HI', 'S_POP', 'E_POP', 'DISTANCE', 'VACATION_No', 'SW_No')\n",
      "\n",
      "Score for forward selected features 0.7289393215943825\n",
      "\n",
      "Forward selected features ('HI', 'DISTANCE', 'SLOT_Controlled', 'VACATION_No', 'SW_No')\n"
     ]
    }
   ],
   "source": [
    "print('Score for backward selected features',Backward_Selection.k_score_)\n",
    "print()\n",
    "print('Backard selected features',Backward_Selection.k_feature_names_)\n",
    "print()\n",
    "print('Score for forward selected features',Forward_Selection.k_score_)\n",
    "print()\n",
    "print('Forward selected features',Forward_Selection.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5c1e0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 9248/9248"
     ]
    }
   ],
   "source": [
    "#selecting 3 best features - using EFS\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "Exhaustive_Selection = EFS(linear_model1,\n",
    "                           min_features= 3,\n",
    "                           max_features= 5,\n",
    "                           scoring='r2',\n",
    "                           n_jobs=-1).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "32f600a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7289393215943826"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exhaustive_Selection.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4fbd9edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HI', 'DISTANCE', 'SLOT_Free', 'VACATION_Yes', 'SW_No')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exhaustive_Selection.best_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b8600ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = ADF[['DISTANCE','HI', 'VACATION_Yes','SLOT_Free', 'SW_No']].values\n",
    "y2 = ADF['FARE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2f48ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "309215d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# considering following features to build the model - 'HI', 'DISTANCE', 'SW_No',\n",
    "\n",
    "linear_model2=LinearRegression()\n",
    "linear_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8f35167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 37.8169\n",
      "            Mean Absolute Error (MAE) : 29.9863\n",
      "          Mean Percentage Error (MPE) : -5.8641\n",
      "Mean Absolute Percentage Error (MAPE) : 22.5196\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -3.0263\n",
      "       Root Mean Squared Error (RMSE) : 39.8784\n",
      "            Mean Absolute Error (MAE) : 31.3726\n",
      "          Mean Percentage Error (MPE) : -7.9754\n",
      "Mean Absolute Percentage Error (MAPE) : 24.2895\n"
     ]
    }
   ],
   "source": [
    "from dmba import regressionSummary\n",
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model2.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d675ef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.7542813895208544\n",
      "R2 for testing dataset 0.7167250361030404\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = linear_model2.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model2.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9fed46f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>FARE</td>       <th>  R-squared:         </th> <td>   0.607</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.605</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   326.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>4.68e-128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:38:18</td>     <th>  Log-Likelihood:    </th> <td> -3370.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   638</td>      <th>  AIC:               </th> <td>   6748.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   634</td>      <th>  BIC:               </th> <td>   6766.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   44.7606</td> <td>    7.173</td> <td>    6.240</td> <td> 0.000</td> <td>   30.674</td> <td>   58.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DISTANCE</th>     <td>    0.0903</td> <td>    0.003</td> <td>   29.233</td> <td> 0.000</td> <td>    0.084</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HI</th>           <td>    0.0096</td> <td>    0.001</td> <td>    8.209</td> <td> 0.000</td> <td>    0.007</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VACATION_Yes</th> <td>  -54.2033</td> <td>    4.334</td> <td>  -12.507</td> <td> 0.000</td> <td>  -62.714</td> <td>  -45.693</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.098</td> <th>  Durbin-Watson:     </th> <td>   1.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   8.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.011</td> <th>  Prob(JB):          </th> <td>  0.0120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.424</td> <th>  Cond. No.          </th> <td>1.86e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.86e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   FARE   R-squared:                       0.607\n",
       "Model:                            OLS   Adj. R-squared:                  0.605\n",
       "Method:                 Least Squares   F-statistic:                     326.2\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):          4.68e-128\n",
       "Time:                        11:38:18   Log-Likelihood:                -3370.2\n",
       "No. Observations:                 638   AIC:                             6748.\n",
       "Df Residuals:                     634   BIC:                             6766.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       44.7606      7.173      6.240      0.000      30.674      58.847\n",
       "DISTANCE         0.0903      0.003     29.233      0.000       0.084       0.096\n",
       "HI               0.0096      0.001      8.209      0.000       0.007       0.012\n",
       "VACATION_Yes   -54.2033      4.334    -12.507      0.000     -62.714     -45.693\n",
       "==============================================================================\n",
       "Omnibus:                       17.098   Durbin-Watson:                   1.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                8.841\n",
       "Skew:                           0.011   Prob(JB):                       0.0120\n",
       "Kurtosis:                       2.424   Cond. No.                     1.86e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.86e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Complex_Model1a = smf.ols('FARE ~ DISTANCE + HI + VACATION_Yes ', data = ADF).fit()\n",
    "Complex_Model1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dcff9960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 27.61369354246139\n",
      "coefficient [ 8.11977535e-02  9.24927343e-03 -4.77141023e+01 -1.85699992e+01\n",
      "  5.70476427e+01]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:',linear_model2.intercept_) # Printing the interecept for linear regression\n",
    "print('coefficient',linear_model2.coef_ )    # Printing the coefficient for linear regression\n",
    "\n",
    "#'DISTANCE','HI', 'VACATION_Yes','SLOT_Free', 'SW_No'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "45509522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form Dataset 1(A)=> FARE = [81.76468303] + [[0.08189359]] * DISTANCE\n",
      "\n",
      "Model Form Dataset 1(B)=> FARE = 27.61369354246139 + 0.0811977535 * DISTANCE + 0.00924927343 * HI - 47.7141023 * VACATION_Yes - 18.5699992 * SLOT_Free + 57.0476427 * SW_No\n"
     ]
    }
   ],
   "source": [
    "#Different model forms based on features.\n",
    "print ('Model Form Dataset 1(A)=>','FARE =', linear_model1.intercept_, '+', linear_model1.coef_,'* DISTANCE' )\n",
    "print()\n",
    "print ('Model Form Dataset 1(B)=>','FARE =', linear_model2.intercept_, '+',8.11977535e-02 ,'* DISTANCE','+', 9.24927343e-03,'* HI', '-', 4.77141023e+01, '* VACATION_Yes', '-', 1.85699992e+01, '* SLOT_Free', '+', 5.70476427e+01, '* SW_No')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f3687",
   "metadata": {},
   "source": [
    "# Take note of any differences in model performance from 1. to 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa86da7",
   "metadata": {},
   "source": [
    "Comparing model 1 & 2, I can say that there is there is an increase in R-squared value, which I think is good. ALong with that we can see that MAPE value for Model 2 is reduced which is better, as less the error beter the model.\n",
    "\n",
    "Performcance of model 2 is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bbd63",
   "metadata": {},
   "source": [
    "# Do you notice any major changes in the magnitudes of your parameter estimates? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542f073",
   "metadata": {},
   "source": [
    "Considering the feature \"DISTANCE\", we can see there is not much difference between the magnitudes of the parameter estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaad0e5",
   "metadata": {},
   "source": [
    "# Pick one parameter estimate and, in words, describe what it means?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea080d",
   "metadata": {},
   "source": [
    "Parameter estimates means, how a parameter affects or influences 1 unit change in the predictor contribution, so if we consider 'DISTANCE', it contributes or influences 0.0811 part of 1 unit of dependent variable or whatenver we are predicting in this case that is FARE. \n",
    "\n",
    "In simple terms if Fare increase Distance with have 0.0811 of contribution in the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "34351dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV,LassoCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923391ac",
   "metadata": {},
   "source": [
    "# Question 3 - Applying LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4ce8f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUPON', 'NEW', 'HI', 'S_INCOME', 'E_INCOME', 'S_POP', 'E_POP',\n",
       "       'DISTANCE', 'PAX', 'FARE', 'SLOT_Controlled', 'SLOT_Free',\n",
       "       'GATE_Constrained', 'GATE_Free', 'VACATION_No', 'VACATION_Yes', 'SW_No',\n",
       "       'SW_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8fcb42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_metrics(X_train,X_test,y_train,y_test,model):\n",
    "    names=['R2','MAE','MAPE','SSE'] \n",
    "    \n",
    "    # Training Metrics\n",
    "    y_hat = model.predict(X_train)\n",
    "    \n",
    "    # Create R2\n",
    "    r2 = r2_score(y_train,y_hat).round(3)\n",
    "    \n",
    "    # Create MAE\n",
    "    mae = mean_absolute_error(y_train,y_hat).round(3)\n",
    "    \n",
    "    # Create MAPE\n",
    "    mape = mean_absolute_percentage_error(y_train,y_hat).round(3)*100\n",
    "    \n",
    "    # Create MSE\n",
    "    mse = (mean_squared_error(y_train,y_hat)*len(y_train)).round(3)\n",
    "    \n",
    "    train_metrics = [r2, mae, mape,mse]\n",
    "    train_metrics = pd.DataFrame({'Train':train_metrics},index=names)\n",
    "    \n",
    "    # Testing Metrics\n",
    "    y_hat = model.predict(X_test)\n",
    "    test_metrics = [r2_score(y_test,y_hat).round(3),\n",
    "                    mean_absolute_error(y_test,y_hat).round(3),\n",
    "                    mean_absolute_percentage_error(y_test,y_hat).round(3)*100,\n",
    "                    (mean_squared_error(y_test,y_hat)*len(y_test)).round(3)\n",
    "                   ]\n",
    "    test_metrics = pd.DataFrame({'Test':test_metrics},index=names)\n",
    "    \n",
    "    all_metrics = train_metrics.merge(test_metrics,left_index=True,right_index=True)\n",
    "    \n",
    "    print(pd.DataFrame({'Predictor':X_train.columns, 'coefficent':model.coef_.round(3)}))\n",
    "    print('\\n')\n",
    "    print(all_metrics)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9c32701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Predictor  coefficent\n",
      "0             COUPON       0.000\n",
      "1                NEW      -1.232\n",
      "2                 HI       0.007\n",
      "3           S_INCOME       0.001\n",
      "4           E_INCOME       0.001\n",
      "5              S_POP       0.000\n",
      "6              E_POP       0.000\n",
      "7           DISTANCE       0.075\n",
      "8                PAX      -0.001\n",
      "9    SLOT_Controlled      14.990\n",
      "10         SLOT_Free      -0.000\n",
      "11  GATE_Constrained      19.569\n",
      "12         GATE_Free      -0.000\n",
      "13       VACATION_No      35.904\n",
      "14      VACATION_Yes      -0.000\n",
      "15             SW_No      40.043\n",
      "16            SW_Yes      -0.000\n",
      "\n",
      "\n",
      "           Train        Test\n",
      "R2         0.781       0.794\n",
      "MAE       27.459      28.062\n",
      "MAPE      20.500      20.800\n",
      "SSE   595428.012  198752.624\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagbhid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors = ['COUPON', 'NEW', 'HI', 'S_INCOME', 'E_INCOME', 'S_POP', 'E_POP',\n",
    "       'DISTANCE', 'PAX', 'SLOT_Controlled', 'SLOT_Free',\n",
    "       'GATE_Constrained', 'GATE_Free', 'VACATION_No', 'VACATION_Yes', 'SW_No',\n",
    "       'SW_Yes'\n",
    "             ]\n",
    "X = ADF[predictors]\n",
    "y = ADF['FARE']\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=.25,random_state=1)\n",
    "\n",
    "r_alphas = [0.04,0.06,0.08,0.085,0.09,0.099,.1,0.11,0.2,0.25]\n",
    "\n",
    "model = LassoCV(alphas=r_alphas,normalize=True)\n",
    "model.fit(Xtrain,ytrain)\n",
    "\n",
    "train_test_metrics(Xtrain,Xtest,ytrain,ytest,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "89b3eef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Alpha Selection:  0.04\n"
     ]
    }
   ],
   "source": [
    "print('LassoCV Alpha Selection: ',model.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d2a12a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept for lasso -82.20940279580753\n",
      "coefficients [ 0.00000000e+00 -1.23236746e+00  7.27934817e-03  7.95671504e-04\n",
      "  1.45894034e-03  3.06047256e-06  3.42093731e-06  7.49706955e-02\n",
      " -6.96035868e-04  1.49902829e+01 -3.27108365e-15  1.95691100e+01\n",
      " -1.82523746e-14  3.59036910e+01 -0.00000000e+00  4.00428351e+01\n",
      " -1.77088224e-15]\n"
     ]
    }
   ],
   "source": [
    "print('intercept for lasso', model.intercept_) # Printing the interecept for linear regression\n",
    "print('coefficients', model.coef_ )   # Printing the coefficients for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "90aaf27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 1=> FARE = [81.76468303] + [[0.08189359]] * DISTANCE\n",
      "\n",
      "Model Form 2=> FARE = 27.61369354246139 + 0.0811977535 * DISTANCE + 0.00924927343 * HI - 47.7141023 * VACATION_Yes - 18.5699992 * SLOT_Free + 57.0476427 * SW_No\n",
      "\n",
      "Model Form 3=> FARE = -82.20940279580753 - 1.232 * NEW + 0.075 * DISTANCE - 14.99 * SLOT_Controlled - 19.569 * GATE_Constrained + 35.904 * VACATION_No + 40.043 * SW_No\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE) for model 1 : 38.0777\n",
      "Mean Absolute Percentage Error (MAPE) for model 2 : 24.2895\n",
      "Mean Absolute Percentage Error (MAPE) for model 3 :  20.800\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 1=>','FARE =', linear_model1.intercept_, '+', linear_model1.coef_,'* DISTANCE' )\n",
    "print()\n",
    "print ('Model Form 2=>','FARE =', linear_model2.intercept_, '+',8.11977535e-02 ,'* DISTANCE','+', 9.24927343e-03,'* HI', '-', 4.77141023e+01, '* VACATION_Yes', '-', 1.85699992e+01, '* SLOT_Free', '+', 5.70476427e+01, '* SW_No')\n",
    "print()\n",
    "print ('Model Form 3=>','FARE =', model.intercept_, '-',1.232 ,'* NEW','+', 0.075,'* DISTANCE', '-',14.990, '* SLOT_Controlled', '-', 19.569, '* GATE_Constrained', '+', 35.904,'* VACATION_No', '+', 40.043, '* SW_No')\n",
    "\n",
    "print()\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 1 : 38.0777\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 2 : 24.2895\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 3 :  20.800\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0333b3",
   "metadata": {},
   "source": [
    "# DATASET 2 - Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0f35989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagbhid\\AppData\\Local\\Temp\\ipykernel_30508\\1299147145.py:3: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CATMEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO  LSTAT  MEDV  CATMEDV  \n",
       "0       15.3   4.98  24.0        0  \n",
       "1       17.8   9.14  21.6        0  \n",
       "2       17.8   4.03  34.7        1  \n",
       "3       18.7   2.94  33.4        1  \n",
       "4       18.7   5.33  36.2        1  \n",
       "..       ...    ...   ...      ...  \n",
       "501     21.0   9.67  22.4        0  \n",
       "502     21.0   9.08  20.6        0  \n",
       "503     21.0   5.64  23.9        0  \n",
       "504     21.0   6.48  22.0        0  \n",
       "505     21.0   7.88  11.9        0  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDF=pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\BostonHousing.csv')\n",
    "# BDF.columns= BDF.columns.str.lower()\n",
    "BDF.columns = BDF.columns.str.replace('. ', '')\n",
    "BDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4b633791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATMEDV    1.000000\n",
       "MEDV       0.789789\n",
       "RM         0.641265\n",
       "ZN         0.365296\n",
       "DIS        0.118887\n",
       "CHAS       0.108631\n",
       "CRIM      -0.151987\n",
       "AGE       -0.191196\n",
       "RAD       -0.197924\n",
       "NOX       -0.232502\n",
       "TAX       -0.273687\n",
       "INDUS     -0.366276\n",
       "PTRATIO   -0.443425\n",
       "LSTAT     -0.469911\n",
       "Name: CATMEDV, dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDFcorr_matrix = BDF.corr()\n",
    "BDFcorr_matrix[\"CATMEDV\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9183fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "LSTAT=%{x}<br>MEDV=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4.98,
          9.14,
          4.03,
          2.94,
          5.33,
          5.21,
          12.43,
          19.15,
          29.93,
          17.1,
          20.45,
          13.27,
          15.71,
          8.26,
          10.26,
          8.47,
          6.58,
          14.67,
          11.69,
          11.28,
          21.02,
          13.83,
          18.72,
          19.88,
          16.3,
          16.51,
          14.81,
          17.28,
          12.8,
          11.98,
          22.6,
          13.04,
          27.71,
          18.35,
          20.34,
          9.68,
          11.41,
          8.77,
          10.13,
          4.32,
          1.98,
          4.84,
          5.81,
          7.44,
          9.55,
          10.21,
          14.15,
          18.8,
          30.81,
          16.2,
          13.45,
          9.43,
          5.28,
          8.43,
          14.8,
          4.81,
          5.77,
          3.95,
          6.86,
          9.22,
          13.15,
          14.44,
          6.73,
          9.5,
          8.05,
          4.67,
          10.24,
          8.1,
          13.09,
          8.79,
          6.72,
          9.88,
          5.52,
          7.54,
          6.78,
          8.94,
          11.97,
          10.27,
          12.34,
          9.1,
          5.29,
          7.22,
          6.72,
          7.51,
          9.62,
          6.53,
          12.86,
          8.44,
          5.5,
          5.7,
          8.81,
          8.2,
          8.16,
          6.21,
          10.59,
          6.65,
          11.34,
          4.21,
          3.57,
          6.19,
          9.42,
          7.67,
          10.63,
          13.44,
          12.33,
          16.47,
          18.66,
          14.09,
          12.27,
          15.55,
          13,
          10.16,
          16.21,
          17.09,
          10.45,
          15.76,
          12.04,
          10.3,
          15.37,
          13.61,
          14.37,
          14.27,
          17.93,
          25.41,
          17.58,
          14.81,
          27.26,
          17.19,
          15.39,
          18.34,
          12.6,
          12.26,
          11.12,
          15.03,
          17.31,
          16.96,
          16.9,
          14.59,
          21.32,
          18.46,
          24.16,
          34.41,
          26.82,
          26.42,
          29.29,
          27.8,
          16.65,
          29.53,
          28.32,
          21.45,
          14.1,
          13.28,
          12.12,
          15.79,
          15.12,
          15.02,
          16.14,
          4.59,
          6.43,
          7.39,
          5.5,
          1.73,
          1.92,
          3.32,
          11.64,
          9.81,
          3.7,
          12.14,
          11.1,
          11.32,
          14.43,
          12.03,
          14.69,
          9.04,
          9.64,
          5.33,
          10.11,
          6.29,
          6.92,
          5.04,
          7.56,
          9.45,
          4.82,
          5.68,
          13.98,
          13.15,
          4.45,
          6.68,
          4.56,
          5.39,
          5.1,
          4.69,
          2.87,
          5.03,
          4.38,
          2.97,
          4.08,
          8.61,
          6.62,
          4.56,
          4.45,
          7.43,
          3.11,
          3.81,
          2.88,
          10.87,
          10.97,
          18.06,
          14.66,
          23.09,
          17.27,
          23.98,
          16.03,
          9.38,
          29.55,
          9.47,
          13.51,
          9.69,
          17.92,
          10.5,
          9.71,
          21.46,
          9.93,
          7.6,
          4.14,
          4.63,
          3.13,
          6.36,
          3.92,
          3.76,
          11.65,
          5.25,
          2.47,
          3.95,
          8.05,
          10.88,
          9.54,
          4.73,
          6.36,
          7.37,
          11.38,
          12.4,
          11.22,
          5.19,
          12.5,
          18.46,
          9.16,
          10.15,
          9.52,
          6.56,
          5.9,
          3.59,
          3.53,
          3.54,
          6.57,
          9.25,
          3.11,
          5.12,
          7.79,
          6.9,
          9.59,
          7.26,
          5.91,
          11.25,
          8.1,
          10.45,
          14.79,
          7.44,
          3.16,
          13.65,
          13,
          6.59,
          7.73,
          6.58,
          3.53,
          2.98,
          6.05,
          4.16,
          7.19,
          4.85,
          3.76,
          4.59,
          3.01,
          3.16,
          7.85,
          8.23,
          12.93,
          7.14,
          7.6,
          9.51,
          3.33,
          3.56,
          4.7,
          8.58,
          10.4,
          6.27,
          7.39,
          15.84,
          4.97,
          4.74,
          6.07,
          9.5,
          8.67,
          4.86,
          6.93,
          8.93,
          6.47,
          7.53,
          4.54,
          9.97,
          12.64,
          5.98,
          11.72,
          7.9,
          9.28,
          11.5,
          18.33,
          15.94,
          10.36,
          12.73,
          7.2,
          6.87,
          7.7,
          11.74,
          6.12,
          5.08,
          6.15,
          12.79,
          9.97,
          7.34,
          9.09,
          12.43,
          7.83,
          5.68,
          6.75,
          8.01,
          9.8,
          10.56,
          8.51,
          9.74,
          9.29,
          5.49,
          8.65,
          7.18,
          4.61,
          10.53,
          12.67,
          6.36,
          5.99,
          5.89,
          5.98,
          5.49,
          7.79,
          4.5,
          8.05,
          5.57,
          17.6,
          13.27,
          11.48,
          12.67,
          7.79,
          14.19,
          10.19,
          14.64,
          5.29,
          7.12,
          14,
          13.33,
          3.26,
          3.73,
          2.96,
          9.53,
          8.88,
          34.77,
          37.97,
          13.44,
          23.24,
          21.24,
          23.69,
          21.78,
          17.21,
          21.08,
          23.6,
          24.56,
          30.63,
          30.81,
          28.28,
          31.99,
          30.62,
          20.85,
          17.11,
          18.76,
          25.68,
          15.17,
          16.35,
          17.12,
          19.37,
          19.92,
          30.59,
          29.97,
          26.77,
          20.32,
          20.31,
          19.77,
          27.38,
          22.98,
          23.34,
          12.13,
          26.4,
          19.78,
          10.11,
          21.22,
          34.37,
          20.08,
          36.98,
          29.05,
          25.79,
          26.64,
          20.62,
          22.74,
          15.02,
          15.7,
          14.1,
          23.29,
          17.16,
          24.39,
          15.69,
          14.52,
          21.52,
          24.08,
          17.64,
          19.69,
          12.03,
          16.22,
          15.17,
          23.27,
          18.05,
          26.45,
          34.02,
          22.88,
          22.11,
          19.52,
          16.59,
          18.85,
          23.79,
          23.98,
          17.79,
          16.44,
          18.13,
          19.31,
          17.44,
          17.73,
          17.27,
          16.74,
          18.71,
          18.13,
          19.01,
          16.94,
          16.23,
          14.7,
          16.42,
          14.65,
          13.99,
          10.29,
          13.22,
          14.13,
          17.15,
          21.32,
          18.13,
          14.76,
          16.29,
          12.87,
          14.36,
          11.66,
          18.14,
          24.1,
          18.68,
          24.91,
          18.03,
          13.11,
          10.74,
          7.74,
          7.01,
          10.42,
          13.34,
          10.58,
          14.98,
          11.45,
          18.06,
          23.97,
          29.68,
          18.07,
          13.35,
          12.01,
          13.59,
          17.6,
          21.14,
          14.1,
          12.92,
          15.1,
          14.33,
          9.67,
          9.08,
          5.64,
          6.48,
          7.88
         ],
         "xaxis": "x",
         "y": [
          24,
          21.6,
          34.7,
          33.4,
          36.2,
          28.7,
          22.9,
          27.1,
          16.5,
          18.9,
          15,
          18.9,
          21.7,
          20.4,
          18.2,
          19.9,
          23.1,
          17.5,
          20.2,
          18.2,
          13.6,
          19.6,
          15.2,
          14.5,
          15.6,
          13.9,
          16.6,
          14.8,
          18.4,
          21,
          12.7,
          14.5,
          13.2,
          13.1,
          13.5,
          18.9,
          20,
          21,
          24.7,
          30.8,
          34.9,
          26.6,
          25.3,
          24.7,
          21.2,
          19.3,
          20,
          16.6,
          14.4,
          19.4,
          19.7,
          20.5,
          25,
          23.4,
          18.9,
          35.4,
          24.7,
          31.6,
          23.3,
          19.6,
          18.7,
          16,
          22.2,
          25,
          33,
          23.5,
          19.4,
          22,
          17.4,
          20.9,
          24.2,
          21.7,
          22.8,
          23.4,
          24.1,
          21.4,
          20,
          20.8,
          21.2,
          20.3,
          28,
          23.9,
          24.8,
          22.9,
          23.9,
          26.6,
          22.5,
          22.2,
          23.6,
          28.7,
          22.6,
          22,
          22.9,
          25,
          20.6,
          28.4,
          21.4,
          38.7,
          43.8,
          33.2,
          27.5,
          26.5,
          18.6,
          19.3,
          20.1,
          19.5,
          19.5,
          20.4,
          19.8,
          19.4,
          21.7,
          22.8,
          18.8,
          18.7,
          18.5,
          18.3,
          21.2,
          19.2,
          20.4,
          19.3,
          22,
          20.3,
          20.5,
          17.3,
          18.8,
          21.4,
          15.7,
          16.2,
          18,
          14.3,
          19.2,
          19.6,
          23,
          18.4,
          15.6,
          18.1,
          17.4,
          17.1,
          13.3,
          17.8,
          14,
          14.4,
          13.4,
          15.6,
          11.8,
          13.8,
          15.6,
          14.6,
          17.8,
          15.4,
          21.5,
          19.6,
          15.3,
          19.4,
          17,
          15.6,
          13.1,
          41.3,
          24.3,
          23.3,
          27,
          50,
          50,
          50,
          22.7,
          25,
          50,
          23.8,
          23.8,
          22.3,
          17.4,
          19.1,
          23.1,
          23.6,
          22.6,
          29.4,
          23.2,
          24.6,
          29.9,
          37.2,
          39.8,
          36.2,
          37.9,
          32.5,
          26.4,
          29.6,
          50,
          32,
          29.8,
          34.9,
          37,
          30.5,
          36.4,
          31.1,
          29.1,
          50,
          33.3,
          30.3,
          34.6,
          34.9,
          32.9,
          24.1,
          42.3,
          48.5,
          50,
          22.6,
          24.4,
          22.5,
          24.4,
          20,
          21.7,
          19.3,
          22.4,
          28.1,
          23.7,
          25,
          23.3,
          28.7,
          21.5,
          23,
          26.7,
          21.7,
          27.5,
          30.1,
          44.8,
          50,
          37.6,
          31.6,
          46.7,
          31.5,
          24.3,
          31.7,
          41.7,
          48.3,
          29,
          24,
          25.1,
          31.5,
          23.7,
          23.3,
          22,
          20.1,
          22.2,
          23.7,
          17.6,
          18.5,
          24.3,
          20.5,
          24.5,
          26.2,
          24.4,
          24.8,
          29.6,
          42.8,
          21.9,
          20.9,
          44,
          50,
          36,
          30.1,
          33.8,
          43.1,
          48.8,
          31,
          36.5,
          22.8,
          30.7,
          50,
          43.5,
          20.7,
          21.1,
          25.2,
          24.4,
          35.2,
          32.4,
          32,
          33.2,
          33.1,
          29.1,
          35.1,
          45.4,
          35.4,
          46,
          50,
          32.2,
          22,
          20.1,
          23.2,
          22.3,
          24.8,
          28.5,
          37.3,
          27.9,
          23.9,
          21.7,
          28.6,
          27.1,
          20.3,
          22.5,
          29,
          24.8,
          22,
          26.4,
          33.1,
          36.1,
          28.4,
          33.4,
          28.2,
          22.8,
          20.3,
          16.1,
          22.1,
          19.4,
          21.6,
          23.8,
          16.2,
          17.8,
          19.8,
          23.1,
          21,
          23.8,
          23.1,
          20.4,
          18.5,
          25,
          24.6,
          23,
          22.2,
          19.3,
          22.6,
          19.8,
          17.1,
          19.4,
          22.2,
          20.7,
          21.1,
          19.5,
          18.5,
          20.6,
          19,
          18.7,
          32.7,
          16.5,
          23.9,
          31.2,
          17.5,
          17.2,
          23.1,
          24.5,
          26.6,
          22.9,
          24.1,
          18.6,
          30.1,
          18.2,
          20.6,
          17.8,
          21.7,
          22.7,
          22.6,
          25,
          19.9,
          20.8,
          16.8,
          21.9,
          27.5,
          21.9,
          23.1,
          50,
          50,
          50,
          50,
          50,
          13.8,
          13.8,
          15,
          13.9,
          13.3,
          13.1,
          10.2,
          10.4,
          10.9,
          11.3,
          12.3,
          8.8,
          7.2,
          10.5,
          7.4,
          10.2,
          11.5,
          15.1,
          23.2,
          9.7,
          13.8,
          12.7,
          13.1,
          12.5,
          8.5,
          5,
          6.3,
          5.6,
          7.2,
          12.1,
          8.3,
          8.5,
          5,
          11.9,
          27.9,
          17.2,
          27.5,
          15,
          17.2,
          17.9,
          16.3,
          7,
          7.2,
          7.5,
          10.4,
          8.8,
          8.4,
          16.7,
          14.2,
          20.8,
          13.4,
          11.7,
          8.3,
          10.2,
          10.9,
          11,
          9.5,
          14.5,
          14.1,
          16.1,
          14.3,
          11.7,
          13.4,
          9.6,
          8.7,
          8.4,
          12.8,
          10.5,
          17.1,
          18.4,
          15.4,
          10.8,
          11.8,
          14.9,
          12.6,
          14.1,
          13,
          13.4,
          15.2,
          16.1,
          17.8,
          14.9,
          14.1,
          12.7,
          13.5,
          14.9,
          20,
          16.4,
          17.7,
          19.5,
          20.2,
          21.4,
          19.9,
          19,
          19.1,
          19.1,
          20.1,
          19.9,
          19.6,
          23.2,
          29.8,
          13.8,
          13.3,
          16.7,
          12,
          14.6,
          21.4,
          23,
          23.7,
          25,
          21.8,
          20.6,
          21.2,
          19.1,
          20.6,
          15.2,
          7,
          8.1,
          13.6,
          20.1,
          21.8,
          24.5,
          23.1,
          19.7,
          18.3,
          21.2,
          17.5,
          16.8,
          22.4,
          20.6,
          23.9,
          22,
          11.9
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>OLS trendline</b><br>MEDV = -0.950049 * LSTAT + 34.5538<br>R<sup>2</sup>=0.544146<br><br>LSTAT=%{x}<br>MEDV=%{y} <b>(trend)</b><extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.73,
          1.92,
          1.98,
          2.47,
          2.87,
          2.88,
          2.94,
          2.96,
          2.97,
          2.98,
          3.01,
          3.11,
          3.11,
          3.13,
          3.16,
          3.16,
          3.26,
          3.32,
          3.33,
          3.53,
          3.53,
          3.54,
          3.56,
          3.57,
          3.59,
          3.7,
          3.73,
          3.76,
          3.76,
          3.81,
          3.92,
          3.95,
          3.95,
          4.03,
          4.08,
          4.14,
          4.16,
          4.21,
          4.32,
          4.38,
          4.45,
          4.45,
          4.5,
          4.54,
          4.56,
          4.56,
          4.59,
          4.59,
          4.61,
          4.63,
          4.67,
          4.69,
          4.7,
          4.73,
          4.74,
          4.81,
          4.82,
          4.84,
          4.85,
          4.86,
          4.97,
          4.98,
          5.03,
          5.04,
          5.08,
          5.1,
          5.12,
          5.19,
          5.21,
          5.25,
          5.28,
          5.29,
          5.29,
          5.33,
          5.33,
          5.39,
          5.49,
          5.49,
          5.5,
          5.5,
          5.52,
          5.57,
          5.64,
          5.68,
          5.68,
          5.7,
          5.77,
          5.81,
          5.89,
          5.9,
          5.91,
          5.98,
          5.98,
          5.99,
          6.05,
          6.07,
          6.12,
          6.15,
          6.19,
          6.21,
          6.27,
          6.29,
          6.36,
          6.36,
          6.36,
          6.43,
          6.47,
          6.48,
          6.53,
          6.56,
          6.57,
          6.58,
          6.58,
          6.59,
          6.62,
          6.65,
          6.68,
          6.72,
          6.72,
          6.73,
          6.75,
          6.78,
          6.86,
          6.87,
          6.9,
          6.92,
          6.93,
          7.01,
          7.12,
          7.14,
          7.18,
          7.19,
          7.2,
          7.22,
          7.26,
          7.34,
          7.37,
          7.39,
          7.39,
          7.43,
          7.44,
          7.44,
          7.51,
          7.53,
          7.54,
          7.56,
          7.6,
          7.6,
          7.67,
          7.7,
          7.73,
          7.74,
          7.79,
          7.79,
          7.79,
          7.83,
          7.85,
          7.88,
          7.9,
          8.01,
          8.05,
          8.05,
          8.05,
          8.1,
          8.1,
          8.16,
          8.2,
          8.23,
          8.26,
          8.43,
          8.44,
          8.47,
          8.51,
          8.58,
          8.61,
          8.65,
          8.67,
          8.77,
          8.79,
          8.81,
          8.88,
          8.93,
          8.94,
          9.04,
          9.08,
          9.09,
          9.1,
          9.14,
          9.16,
          9.22,
          9.25,
          9.28,
          9.29,
          9.38,
          9.42,
          9.43,
          9.45,
          9.47,
          9.5,
          9.5,
          9.51,
          9.52,
          9.53,
          9.54,
          9.55,
          9.59,
          9.62,
          9.64,
          9.67,
          9.68,
          9.69,
          9.71,
          9.74,
          9.8,
          9.81,
          9.88,
          9.93,
          9.97,
          9.97,
          10.11,
          10.11,
          10.13,
          10.15,
          10.16,
          10.19,
          10.21,
          10.24,
          10.26,
          10.27,
          10.29,
          10.3,
          10.36,
          10.4,
          10.42,
          10.45,
          10.45,
          10.5,
          10.53,
          10.56,
          10.58,
          10.59,
          10.63,
          10.74,
          10.87,
          10.88,
          10.97,
          11.1,
          11.12,
          11.22,
          11.25,
          11.28,
          11.32,
          11.34,
          11.38,
          11.41,
          11.45,
          11.48,
          11.5,
          11.64,
          11.65,
          11.66,
          11.69,
          11.72,
          11.74,
          11.97,
          11.98,
          12.01,
          12.03,
          12.03,
          12.04,
          12.12,
          12.13,
          12.14,
          12.26,
          12.27,
          12.33,
          12.34,
          12.4,
          12.43,
          12.43,
          12.5,
          12.6,
          12.64,
          12.67,
          12.67,
          12.73,
          12.79,
          12.8,
          12.86,
          12.87,
          12.92,
          12.93,
          13,
          13,
          13.04,
          13.09,
          13.11,
          13.15,
          13.15,
          13.22,
          13.27,
          13.27,
          13.28,
          13.33,
          13.34,
          13.35,
          13.44,
          13.44,
          13.45,
          13.51,
          13.59,
          13.61,
          13.65,
          13.83,
          13.98,
          13.99,
          14,
          14.09,
          14.1,
          14.1,
          14.1,
          14.13,
          14.15,
          14.19,
          14.27,
          14.33,
          14.36,
          14.37,
          14.43,
          14.44,
          14.52,
          14.59,
          14.64,
          14.65,
          14.66,
          14.67,
          14.69,
          14.7,
          14.76,
          14.79,
          14.8,
          14.81,
          14.81,
          14.98,
          15.02,
          15.02,
          15.03,
          15.1,
          15.12,
          15.17,
          15.17,
          15.37,
          15.39,
          15.55,
          15.69,
          15.7,
          15.71,
          15.76,
          15.79,
          15.84,
          15.94,
          16.03,
          16.14,
          16.2,
          16.21,
          16.22,
          16.23,
          16.29,
          16.3,
          16.35,
          16.42,
          16.44,
          16.47,
          16.51,
          16.59,
          16.65,
          16.74,
          16.9,
          16.94,
          16.96,
          17.09,
          17.1,
          17.11,
          17.12,
          17.15,
          17.16,
          17.19,
          17.21,
          17.27,
          17.27,
          17.28,
          17.31,
          17.44,
          17.58,
          17.6,
          17.6,
          17.64,
          17.73,
          17.79,
          17.92,
          17.93,
          18.03,
          18.05,
          18.06,
          18.06,
          18.07,
          18.13,
          18.13,
          18.13,
          18.14,
          18.33,
          18.34,
          18.35,
          18.46,
          18.46,
          18.66,
          18.68,
          18.71,
          18.72,
          18.76,
          18.8,
          18.85,
          19.01,
          19.15,
          19.31,
          19.37,
          19.52,
          19.69,
          19.77,
          19.78,
          19.88,
          19.92,
          20.08,
          20.31,
          20.32,
          20.34,
          20.45,
          20.62,
          20.85,
          21.02,
          21.08,
          21.14,
          21.22,
          21.24,
          21.32,
          21.32,
          21.45,
          21.46,
          21.52,
          21.78,
          22.11,
          22.6,
          22.74,
          22.88,
          22.98,
          23.09,
          23.24,
          23.27,
          23.29,
          23.34,
          23.6,
          23.69,
          23.79,
          23.97,
          23.98,
          23.98,
          24.08,
          24.1,
          24.16,
          24.39,
          24.56,
          24.91,
          25.41,
          25.68,
          25.79,
          26.4,
          26.42,
          26.45,
          26.64,
          26.77,
          26.82,
          27.26,
          27.38,
          27.71,
          27.8,
          28.28,
          28.32,
          29.05,
          29.29,
          29.53,
          29.55,
          29.68,
          29.93,
          29.97,
          30.59,
          30.62,
          30.63,
          30.81,
          30.81,
          31.99,
          34.02,
          34.37,
          34.41,
          34.77,
          36.98,
          37.97
         ],
         "xaxis": "x",
         "y": [
          32.91025549738176,
          32.729746120167746,
          32.67274315894227,
          32.207218975600846,
          31.82719923409765,
          31.817698740560072,
          31.760695779334593,
          31.741694792259434,
          31.732194298721854,
          31.722693805184274,
          31.69419232457153,
          31.599187389195734,
          31.599187389195734,
          31.580186402120574,
          31.551684921507835,
          31.551684921507835,
          31.456679986132034,
          31.399677024906556,
          31.390176531368976,
          31.200166660617377,
          31.200166660617377,
          31.190666167079797,
          31.171665180004638,
          31.162164686467058,
          31.1431636993919,
          31.038658270478518,
          31.01015678986578,
          30.98165530925304,
          30.98165530925304,
          30.93415284156514,
          30.82964741265176,
          30.80114593203902,
          30.80114593203902,
          30.725141983738382,
          30.677639516050483,
          30.620636554825005,
          30.60163556774984,
          30.554133100061943,
          30.449627671148562,
          30.392624709923084,
          30.326121255160025,
          30.326121255160025,
          30.278618787472126,
          30.240616813321807,
          30.221615826246648,
          30.221615826246648,
          30.19311434563391,
          30.19311434563391,
          30.174113358558746,
          30.155112371483586,
          30.117110397333267,
          30.098109410258107,
          30.088608916720528,
          30.060107436107785,
          30.050606942570205,
          29.984103487807147,
          29.974602994269567,
          29.955602007194408,
          29.946101513656828,
          29.936601020119248,
          29.83209559120587,
          29.82259509766829,
          29.77509262998039,
          29.76559213644281,
          29.72759016229249,
          29.70858917521733,
          29.68958818814217,
          29.62308473337911,
          29.60408374630395,
          29.56608177215363,
          29.53758029154089,
          29.52807979800331,
          29.52807979800331,
          29.490077823852992,
          29.490077823852992,
          29.433074862627514,
          29.338069927251713,
          29.338069927251713,
          29.328569433714133,
          29.328569433714133,
          29.309568446638973,
          29.262065978951075,
          29.195562524188016,
          29.157560550037694,
          29.157560550037694,
          29.138559562962534,
          29.072056108199476,
          29.034054134049157,
          28.95805018574852,
          28.948549692210936,
          28.939049198673356,
          28.872545743910297,
          28.872545743910297,
          28.863045250372718,
          28.80604228914724,
          28.787041302072076,
          28.739538834384177,
          28.711037353771438,
          28.67303537962112,
          28.65403439254596,
          28.59703143132048,
          28.57803044424532,
          28.51152698948226,
          28.51152698948226,
          28.51152698948226,
          28.4450235347192,
          28.407021560568882,
          28.397521067031303,
          28.3500185993434,
          28.32151711873066,
          28.31201662519308,
          28.3025161316555,
          28.3025161316555,
          28.29301563811792,
          28.264514157505182,
          28.236012676892443,
          28.207511196279704,
          28.169509222129385,
          28.169509222129385,
          28.160008728591805,
          28.141007741516646,
          28.112506260903906,
          28.036502312603265,
          28.027001819065685,
          27.998500338452946,
          27.979499351377786,
          27.969998857840206,
          27.893994909539565,
          27.789489480626187,
          27.770488493551028,
          27.73248651940071,
          27.72298602586313,
          27.71348553232555,
          27.69448454525039,
          27.65648257110007,
          27.58047862279943,
          27.55197714218669,
          27.53297615511153,
          27.53297615511153,
          27.49497418096121,
          27.485473687423628,
          27.485473687423628,
          27.41897023266057,
          27.39996924558541,
          27.39046875204783,
          27.37146776497267,
          27.333465790822352,
          27.333465790822352,
          27.266962336059294,
          27.23846085544655,
          27.20995937483381,
          27.200458881296232,
          27.152956413608333,
          27.152956413608333,
          27.152956413608333,
          27.114954439458014,
          27.095953452382854,
          27.06745197177011,
          27.048450984694952,
          26.943945555781575,
          26.905943581631256,
          26.905943581631256,
          26.905943581631256,
          26.858441113943357,
          26.858441113943357,
          26.801438152717875,
          26.763436178567556,
          26.734934697954817,
          26.706433217342077,
          26.544924827203218,
          26.535424333665638,
          26.5069228530529,
          26.46892087890258,
          26.40241742413952,
          26.373915943526782,
          26.33591396937646,
          26.3169129823013,
          26.2219080469255,
          26.20290705985034,
          26.18390607277518,
          26.11740261801212,
          26.069900150324223,
          26.060399656786643,
          25.965394721410846,
          25.927392747260523,
          25.917892253722943,
          25.908391760185363,
          25.87038978603504,
          25.85138879895988,
          25.794385837734403,
          25.765884357121664,
          25.737382876508924,
          25.727882382971345,
          25.642377941133127,
          25.604375966982808,
          25.594875473445228,
          25.57587448637007,
          25.556873499294905,
          25.528372018682166,
          25.528372018682166,
          25.51887152514459,
          25.50937103160701,
          25.49987053806943,
          25.49037004453185,
          25.480869550994267,
          25.44286757684395,
          25.41436609623121,
          25.395365109156046,
          25.366863628543307,
          25.357363135005727,
          25.347862641468147,
          25.328861654392988,
          25.30036017378025,
          25.24335721255477,
          25.23385671901719,
          25.16735326425413,
          25.119850796566233,
          25.08184882241591,
          25.08184882241591,
          24.94884191288979,
          24.94884191288979,
          24.92984092581463,
          24.91083993873947,
          24.90133944520189,
          24.872837964589152,
          24.853836977513993,
          24.825335496901253,
          24.806334509826094,
          24.796834016288514,
          24.777833029213355,
          24.768332535675775,
          24.711329574450296,
          24.673327600299974,
          24.654326613224814,
          24.625825132612075,
          24.625825132612075,
          24.578322664924176,
          24.549821184311437,
          24.521319703698694,
          24.502318716623535,
          24.492818223085955,
          24.454816248935636,
          24.35031082002226,
          24.22680440403372,
          24.21730391049614,
          24.131799468657917,
          24.00829305266938,
          23.98929206559422,
          23.894287130218423,
          23.865785649605684,
          23.837284168992944,
          23.799282194842622,
          23.780281207767462,
          23.74227923361714,
          23.7137777530044,
          23.67577577885408,
          23.647274298241342,
          23.628273311166183,
          23.495266401640066,
          23.485765908102486,
          23.476265414564907,
          23.447763933952167,
          23.419262453339424,
          23.400261466264265,
          23.181750114899927,
          23.172249621362347,
          23.143748140749608,
          23.12474715367445,
          23.12474715367445,
          23.11524666013687,
          23.03924271183623,
          23.029742218298647,
          23.020241724761068,
          22.90623580231011,
          22.89673530877253,
          22.83973234754705,
          22.83023185400947,
          22.77322889278399,
          22.74472741217125,
          22.74472741217125,
          22.678223957408193,
          22.583219022032395,
          22.545217047882073,
          22.516715567269333,
          22.516715567269333,
          22.45971260604385,
          22.402709644818373,
          22.393209151280793,
          22.336206190055314,
          22.326705696517735,
          22.279203228829836,
          22.269702735292256,
          22.203199280529198,
          22.203199280529198,
          22.16519730637888,
          22.117694838690976,
          22.098693851615817,
          22.060691877465494,
          22.060691877465494,
          21.994188422702436,
          21.946685955014537,
          21.946685955014537,
          21.937185461476957,
          21.88968299378906,
          21.88018250025148,
          21.8706820067139,
          21.78517756487568,
          21.78517756487568,
          21.7756770713381,
          21.718674110112623,
          21.64267016181198,
          21.623669174736822,
          21.5856672005865,
          21.414658316910064,
          21.272150913846364,
          21.262650420308784,
          21.253149926771204,
          21.167645484932983,
          21.158144991395403,
          21.158144991395403,
          21.158144991395403,
          21.129643510782664,
          21.110642523707504,
          21.072640549557185,
          20.996636601256547,
          20.93963364003107,
          20.91113215941833,
          20.90163166588075,
          20.844628704655268,
          20.835128211117688,
          20.75912426281705,
          20.692620808053988,
          20.64511834036609,
          20.63561784682851,
          20.62611735329093,
          20.61661685975335,
          20.59761587267819,
          20.58811537914061,
          20.531112417915132,
          20.502610937302393,
          20.49311044376481,
          20.48360995022723,
          20.48360995022723,
          20.32210156008837,
          20.28409958593805,
          20.28409958593805,
          20.27459909240047,
          20.208095637637413,
          20.189094650562254,
          20.141592182874355,
          20.141592182874355,
          19.951582312122756,
          19.932581325047593,
          19.780573428446317,
          19.6475665189202,
          19.63806602538262,
          19.628565531845037,
          19.58106306415714,
          19.5525615835444,
          19.5050591158565,
          19.4100541804807,
          19.32454973864248,
          19.2200443097291,
          19.163041348503626,
          19.153540854966042,
          19.144040361428466,
          19.134539867890883,
          19.077536906665404,
          19.06803641312782,
          19.020533945439922,
          18.954030490676864,
          18.935029503601704,
          18.906528022988965,
          18.868526048838646,
          18.792522100538008,
          18.73551913931253,
          18.650014697474308,
          18.49800680087303,
          18.460004826722706,
          18.441003839647546,
          18.31749742365901,
          18.30799693012143,
          18.29849643658385,
          18.28899594304627,
          18.26049446243353,
          18.25099396889595,
          18.22249248828321,
          18.20349150120805,
          18.14648853998257,
          18.14648853998257,
          18.13698804644499,
          18.10848656583225,
          17.98498014984371,
          17.851973240317594,
          17.83297225324243,
          17.83297225324243,
          17.794970279092112,
          17.709465837253894,
          17.652462876028416,
          17.528956460039876,
          17.519455966502296,
          17.424451031126498,
          17.40545004405134,
          17.39594955051376,
          17.39594955051376,
          17.38644905697618,
          17.3294460957507,
          17.3294460957507,
          17.3294460957507,
          17.319945602213117,
          17.139436224999102,
          17.129935731461522,
          17.12043523792394,
          17.01592980901056,
          17.01592980901056,
          16.825919938258963,
          16.806918951183803,
          16.778417470571064,
          16.768916977033484,
          16.73091500288316,
          16.692913028732843,
          16.645410561044944,
          16.493402664443664,
          16.360395754917548,
          16.208387858316268,
          16.15138489709079,
          16.00887749402709,
          15.84736910388823,
          15.771365155587592,
          15.761864662050012,
          15.666859726674215,
          15.628857752523892,
          15.476849855922616,
          15.258338504558278,
          15.248838011020695,
          15.229837023945539,
          15.125331595032158,
          14.963823204893298,
          14.74531185352896,
          14.583803463390105,
          14.526800502164626,
          14.469797540939144,
          14.393793592638506,
          14.374792605563346,
          14.298788657262705,
          14.298788657262705,
          14.175282241274168,
          14.165781747736585,
          14.108778786511106,
          13.861765954534029,
          13.548249667793893,
          13.082725484452475,
          12.949718574926358,
          12.816711665400238,
          12.721706730024437,
          12.61720130111106,
          12.474693898047363,
          12.44619241743462,
          12.42719143035946,
          12.379688962671562,
          12.132676130694481,
          12.047171688856263,
          11.952166753480466,
          11.781157869804026,
          11.771657376266447,
          11.771657376266447,
          11.67665244089065,
          11.657651453815486,
          11.600648492590008,
          11.38213714122567,
          11.220628751086814,
          10.888111477271515,
          10.41308680039252,
          10.156573474877863,
          10.052068045964482,
          9.47253794017211,
          9.453536953096947,
          9.425035472484208,
          9.244526095270189,
          9.121019679281652,
          9.07351721159375,
          8.655495495940233,
          8.541489573489276,
          8.227973286749137,
          8.142468844910919,
          7.68644515510708,
          7.648443180956761,
          6.954907152713428,
          6.72689530781151,
          6.498883462909593,
          6.479882475834433,
          6.356376059845896,
          6.118863721406395,
          6.080861747256076,
          5.491831147926121,
          5.463329667313381,
          5.453829173775802,
          5.282820290099366,
          5.282820290099366,
          4.161762052664933,
          2.233161864536207,
          1.9006445907209155,
          1.8626426165705965,
          1.520624849217711,
          -0.5789842225874438,
          -1.519533082807854
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 500,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "LSTAT"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "MEDV"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"00ab42b8-c327-4093-84cb-7f16dbd6d9d3\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"00ab42b8-c327-4093-84cb-7f16dbd6d9d3\")) {                    Plotly.newPlot(                        \"00ab42b8-c327-4093-84cb-7f16dbd6d9d3\",                        [{\"hovertemplate\":\"LSTAT=%{x}<br>MEDV=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[4.98,9.14,4.03,2.94,5.33,5.21,12.43,19.15,29.93,17.1,20.45,13.27,15.71,8.26,10.26,8.47,6.58,14.67,11.69,11.28,21.02,13.83,18.72,19.88,16.3,16.51,14.81,17.28,12.8,11.98,22.6,13.04,27.71,18.35,20.34,9.68,11.41,8.77,10.13,4.32,1.98,4.84,5.81,7.44,9.55,10.21,14.15,18.8,30.81,16.2,13.45,9.43,5.28,8.43,14.8,4.81,5.77,3.95,6.86,9.22,13.15,14.44,6.73,9.5,8.05,4.67,10.24,8.1,13.09,8.79,6.72,9.88,5.52,7.54,6.78,8.94,11.97,10.27,12.34,9.1,5.29,7.22,6.72,7.51,9.62,6.53,12.86,8.44,5.5,5.7,8.81,8.2,8.16,6.21,10.59,6.65,11.34,4.21,3.57,6.19,9.42,7.67,10.63,13.44,12.33,16.47,18.66,14.09,12.27,15.55,13.0,10.16,16.21,17.09,10.45,15.76,12.04,10.3,15.37,13.61,14.37,14.27,17.93,25.41,17.58,14.81,27.26,17.19,15.39,18.34,12.6,12.26,11.12,15.03,17.31,16.96,16.9,14.59,21.32,18.46,24.16,34.41,26.82,26.42,29.29,27.8,16.65,29.53,28.32,21.45,14.1,13.28,12.12,15.79,15.12,15.02,16.14,4.59,6.43,7.39,5.5,1.73,1.92,3.32,11.64,9.81,3.7,12.14,11.1,11.32,14.43,12.03,14.69,9.04,9.64,5.33,10.11,6.29,6.92,5.04,7.56,9.45,4.82,5.68,13.98,13.15,4.45,6.68,4.56,5.39,5.1,4.69,2.87,5.03,4.38,2.97,4.08,8.61,6.62,4.56,4.45,7.43,3.11,3.81,2.88,10.87,10.97,18.06,14.66,23.09,17.27,23.98,16.03,9.38,29.55,9.47,13.51,9.69,17.92,10.5,9.71,21.46,9.93,7.6,4.14,4.63,3.13,6.36,3.92,3.76,11.65,5.25,2.47,3.95,8.05,10.88,9.54,4.73,6.36,7.37,11.38,12.4,11.22,5.19,12.5,18.46,9.16,10.15,9.52,6.56,5.9,3.59,3.53,3.54,6.57,9.25,3.11,5.12,7.79,6.9,9.59,7.26,5.91,11.25,8.1,10.45,14.79,7.44,3.16,13.65,13.0,6.59,7.73,6.58,3.53,2.98,6.05,4.16,7.19,4.85,3.76,4.59,3.01,3.16,7.85,8.23,12.93,7.14,7.6,9.51,3.33,3.56,4.7,8.58,10.4,6.27,7.39,15.84,4.97,4.74,6.07,9.5,8.67,4.86,6.93,8.93,6.47,7.53,4.54,9.97,12.64,5.98,11.72,7.9,9.28,11.5,18.33,15.94,10.36,12.73,7.2,6.87,7.7,11.74,6.12,5.08,6.15,12.79,9.97,7.34,9.09,12.43,7.83,5.68,6.75,8.01,9.8,10.56,8.51,9.74,9.29,5.49,8.65,7.18,4.61,10.53,12.67,6.36,5.99,5.89,5.98,5.49,7.79,4.5,8.05,5.57,17.6,13.27,11.48,12.67,7.79,14.19,10.19,14.64,5.29,7.12,14.0,13.33,3.26,3.73,2.96,9.53,8.88,34.77,37.97,13.44,23.24,21.24,23.69,21.78,17.21,21.08,23.6,24.56,30.63,30.81,28.28,31.99,30.62,20.85,17.11,18.76,25.68,15.17,16.35,17.12,19.37,19.92,30.59,29.97,26.77,20.32,20.31,19.77,27.38,22.98,23.34,12.13,26.4,19.78,10.11,21.22,34.37,20.08,36.98,29.05,25.79,26.64,20.62,22.74,15.02,15.7,14.1,23.29,17.16,24.39,15.69,14.52,21.52,24.08,17.64,19.69,12.03,16.22,15.17,23.27,18.05,26.45,34.02,22.88,22.11,19.52,16.59,18.85,23.79,23.98,17.79,16.44,18.13,19.31,17.44,17.73,17.27,16.74,18.71,18.13,19.01,16.94,16.23,14.7,16.42,14.65,13.99,10.29,13.22,14.13,17.15,21.32,18.13,14.76,16.29,12.87,14.36,11.66,18.14,24.1,18.68,24.91,18.03,13.11,10.74,7.74,7.01,10.42,13.34,10.58,14.98,11.45,18.06,23.97,29.68,18.07,13.35,12.01,13.59,17.6,21.14,14.1,12.92,15.1,14.33,9.67,9.08,5.64,6.48,7.88],\"xaxis\":\"x\",\"y\":[24.0,21.6,34.7,33.4,36.2,28.7,22.9,27.1,16.5,18.9,15.0,18.9,21.7,20.4,18.2,19.9,23.1,17.5,20.2,18.2,13.6,19.6,15.2,14.5,15.6,13.9,16.6,14.8,18.4,21.0,12.7,14.5,13.2,13.1,13.5,18.9,20.0,21.0,24.7,30.8,34.9,26.6,25.3,24.7,21.2,19.3,20.0,16.6,14.4,19.4,19.7,20.5,25.0,23.4,18.9,35.4,24.7,31.6,23.3,19.6,18.7,16.0,22.2,25.0,33.0,23.5,19.4,22.0,17.4,20.9,24.2,21.7,22.8,23.4,24.1,21.4,20.0,20.8,21.2,20.3,28.0,23.9,24.8,22.9,23.9,26.6,22.5,22.2,23.6,28.7,22.6,22.0,22.9,25.0,20.6,28.4,21.4,38.7,43.8,33.2,27.5,26.5,18.6,19.3,20.1,19.5,19.5,20.4,19.8,19.4,21.7,22.8,18.8,18.7,18.5,18.3,21.2,19.2,20.4,19.3,22.0,20.3,20.5,17.3,18.8,21.4,15.7,16.2,18.0,14.3,19.2,19.6,23.0,18.4,15.6,18.1,17.4,17.1,13.3,17.8,14.0,14.4,13.4,15.6,11.8,13.8,15.6,14.6,17.8,15.4,21.5,19.6,15.3,19.4,17.0,15.6,13.1,41.3,24.3,23.3,27.0,50.0,50.0,50.0,22.7,25.0,50.0,23.8,23.8,22.3,17.4,19.1,23.1,23.6,22.6,29.4,23.2,24.6,29.9,37.2,39.8,36.2,37.9,32.5,26.4,29.6,50.0,32.0,29.8,34.9,37.0,30.5,36.4,31.1,29.1,50.0,33.3,30.3,34.6,34.9,32.9,24.1,42.3,48.5,50.0,22.6,24.4,22.5,24.4,20.0,21.7,19.3,22.4,28.1,23.7,25.0,23.3,28.7,21.5,23.0,26.7,21.7,27.5,30.1,44.8,50.0,37.6,31.6,46.7,31.5,24.3,31.7,41.7,48.3,29.0,24.0,25.1,31.5,23.7,23.3,22.0,20.1,22.2,23.7,17.6,18.5,24.3,20.5,24.5,26.2,24.4,24.8,29.6,42.8,21.9,20.9,44.0,50.0,36.0,30.1,33.8,43.1,48.8,31.0,36.5,22.8,30.7,50.0,43.5,20.7,21.1,25.2,24.4,35.2,32.4,32.0,33.2,33.1,29.1,35.1,45.4,35.4,46.0,50.0,32.2,22.0,20.1,23.2,22.3,24.8,28.5,37.3,27.9,23.9,21.7,28.6,27.1,20.3,22.5,29.0,24.8,22.0,26.4,33.1,36.1,28.4,33.4,28.2,22.8,20.3,16.1,22.1,19.4,21.6,23.8,16.2,17.8,19.8,23.1,21.0,23.8,23.1,20.4,18.5,25.0,24.6,23.0,22.2,19.3,22.6,19.8,17.1,19.4,22.2,20.7,21.1,19.5,18.5,20.6,19.0,18.7,32.7,16.5,23.9,31.2,17.5,17.2,23.1,24.5,26.6,22.9,24.1,18.6,30.1,18.2,20.6,17.8,21.7,22.7,22.6,25.0,19.9,20.8,16.8,21.9,27.5,21.9,23.1,50.0,50.0,50.0,50.0,50.0,13.8,13.8,15.0,13.9,13.3,13.1,10.2,10.4,10.9,11.3,12.3,8.8,7.2,10.5,7.4,10.2,11.5,15.1,23.2,9.7,13.8,12.7,13.1,12.5,8.5,5.0,6.3,5.6,7.2,12.1,8.3,8.5,5.0,11.9,27.9,17.2,27.5,15.0,17.2,17.9,16.3,7.0,7.2,7.5,10.4,8.8,8.4,16.7,14.2,20.8,13.4,11.7,8.3,10.2,10.9,11.0,9.5,14.5,14.1,16.1,14.3,11.7,13.4,9.6,8.7,8.4,12.8,10.5,17.1,18.4,15.4,10.8,11.8,14.9,12.6,14.1,13.0,13.4,15.2,16.1,17.8,14.9,14.1,12.7,13.5,14.9,20.0,16.4,17.7,19.5,20.2,21.4,19.9,19.0,19.1,19.1,20.1,19.9,19.6,23.2,29.8,13.8,13.3,16.7,12.0,14.6,21.4,23.0,23.7,25.0,21.8,20.6,21.2,19.1,20.6,15.2,7.0,8.1,13.6,20.1,21.8,24.5,23.1,19.7,18.3,21.2,17.5,16.8,22.4,20.6,23.9,22.0,11.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"<b>OLS trendline</b><br>MEDV = -0.950049 * LSTAT + 34.5538<br>R<sup>2</sup>=0.544146<br><br>LSTAT=%{x}<br>MEDV=%{y} <b>(trend)</b><extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[1.73,1.92,1.98,2.47,2.87,2.88,2.94,2.96,2.97,2.98,3.01,3.11,3.11,3.13,3.16,3.16,3.26,3.32,3.33,3.53,3.53,3.54,3.56,3.57,3.59,3.7,3.73,3.76,3.76,3.81,3.92,3.95,3.95,4.03,4.08,4.14,4.16,4.21,4.32,4.38,4.45,4.45,4.5,4.54,4.56,4.56,4.59,4.59,4.61,4.63,4.67,4.69,4.7,4.73,4.74,4.81,4.82,4.84,4.85,4.86,4.97,4.98,5.03,5.04,5.08,5.1,5.12,5.19,5.21,5.25,5.28,5.29,5.29,5.33,5.33,5.39,5.49,5.49,5.5,5.5,5.52,5.57,5.64,5.68,5.68,5.7,5.77,5.81,5.89,5.9,5.91,5.98,5.98,5.99,6.05,6.07,6.12,6.15,6.19,6.21,6.27,6.29,6.36,6.36,6.36,6.43,6.47,6.48,6.53,6.56,6.57,6.58,6.58,6.59,6.62,6.65,6.68,6.72,6.72,6.73,6.75,6.78,6.86,6.87,6.9,6.92,6.93,7.01,7.12,7.14,7.18,7.19,7.2,7.22,7.26,7.34,7.37,7.39,7.39,7.43,7.44,7.44,7.51,7.53,7.54,7.56,7.6,7.6,7.67,7.7,7.73,7.74,7.79,7.79,7.79,7.83,7.85,7.88,7.9,8.01,8.05,8.05,8.05,8.1,8.1,8.16,8.2,8.23,8.26,8.43,8.44,8.47,8.51,8.58,8.61,8.65,8.67,8.77,8.79,8.81,8.88,8.93,8.94,9.04,9.08,9.09,9.1,9.14,9.16,9.22,9.25,9.28,9.29,9.38,9.42,9.43,9.45,9.47,9.5,9.5,9.51,9.52,9.53,9.54,9.55,9.59,9.62,9.64,9.67,9.68,9.69,9.71,9.74,9.8,9.81,9.88,9.93,9.97,9.97,10.11,10.11,10.13,10.15,10.16,10.19,10.21,10.24,10.26,10.27,10.29,10.3,10.36,10.4,10.42,10.45,10.45,10.5,10.53,10.56,10.58,10.59,10.63,10.74,10.87,10.88,10.97,11.1,11.12,11.22,11.25,11.28,11.32,11.34,11.38,11.41,11.45,11.48,11.5,11.64,11.65,11.66,11.69,11.72,11.74,11.97,11.98,12.01,12.03,12.03,12.04,12.12,12.13,12.14,12.26,12.27,12.33,12.34,12.4,12.43,12.43,12.5,12.6,12.64,12.67,12.67,12.73,12.79,12.8,12.86,12.87,12.92,12.93,13.0,13.0,13.04,13.09,13.11,13.15,13.15,13.22,13.27,13.27,13.28,13.33,13.34,13.35,13.44,13.44,13.45,13.51,13.59,13.61,13.65,13.83,13.98,13.99,14.0,14.09,14.1,14.1,14.1,14.13,14.15,14.19,14.27,14.33,14.36,14.37,14.43,14.44,14.52,14.59,14.64,14.65,14.66,14.67,14.69,14.7,14.76,14.79,14.8,14.81,14.81,14.98,15.02,15.02,15.03,15.1,15.12,15.17,15.17,15.37,15.39,15.55,15.69,15.7,15.71,15.76,15.79,15.84,15.94,16.03,16.14,16.2,16.21,16.22,16.23,16.29,16.3,16.35,16.42,16.44,16.47,16.51,16.59,16.65,16.74,16.9,16.94,16.96,17.09,17.1,17.11,17.12,17.15,17.16,17.19,17.21,17.27,17.27,17.28,17.31,17.44,17.58,17.6,17.6,17.64,17.73,17.79,17.92,17.93,18.03,18.05,18.06,18.06,18.07,18.13,18.13,18.13,18.14,18.33,18.34,18.35,18.46,18.46,18.66,18.68,18.71,18.72,18.76,18.8,18.85,19.01,19.15,19.31,19.37,19.52,19.69,19.77,19.78,19.88,19.92,20.08,20.31,20.32,20.34,20.45,20.62,20.85,21.02,21.08,21.14,21.22,21.24,21.32,21.32,21.45,21.46,21.52,21.78,22.11,22.6,22.74,22.88,22.98,23.09,23.24,23.27,23.29,23.34,23.6,23.69,23.79,23.97,23.98,23.98,24.08,24.1,24.16,24.39,24.56,24.91,25.41,25.68,25.79,26.4,26.42,26.45,26.64,26.77,26.82,27.26,27.38,27.71,27.8,28.28,28.32,29.05,29.29,29.53,29.55,29.68,29.93,29.97,30.59,30.62,30.63,30.81,30.81,31.99,34.02,34.37,34.41,34.77,36.98,37.97],\"xaxis\":\"x\",\"y\":[32.91025549738176,32.729746120167746,32.67274315894227,32.207218975600846,31.82719923409765,31.817698740560072,31.760695779334593,31.741694792259434,31.732194298721854,31.722693805184274,31.69419232457153,31.599187389195734,31.599187389195734,31.580186402120574,31.551684921507835,31.551684921507835,31.456679986132034,31.399677024906556,31.390176531368976,31.200166660617377,31.200166660617377,31.190666167079797,31.171665180004638,31.162164686467058,31.1431636993919,31.038658270478518,31.01015678986578,30.98165530925304,30.98165530925304,30.93415284156514,30.82964741265176,30.80114593203902,30.80114593203902,30.725141983738382,30.677639516050483,30.620636554825005,30.60163556774984,30.554133100061943,30.449627671148562,30.392624709923084,30.326121255160025,30.326121255160025,30.278618787472126,30.240616813321807,30.221615826246648,30.221615826246648,30.19311434563391,30.19311434563391,30.174113358558746,30.155112371483586,30.117110397333267,30.098109410258107,30.088608916720528,30.060107436107785,30.050606942570205,29.984103487807147,29.974602994269567,29.955602007194408,29.946101513656828,29.936601020119248,29.83209559120587,29.82259509766829,29.77509262998039,29.76559213644281,29.72759016229249,29.70858917521733,29.68958818814217,29.62308473337911,29.60408374630395,29.56608177215363,29.53758029154089,29.52807979800331,29.52807979800331,29.490077823852992,29.490077823852992,29.433074862627514,29.338069927251713,29.338069927251713,29.328569433714133,29.328569433714133,29.309568446638973,29.262065978951075,29.195562524188016,29.157560550037694,29.157560550037694,29.138559562962534,29.072056108199476,29.034054134049157,28.95805018574852,28.948549692210936,28.939049198673356,28.872545743910297,28.872545743910297,28.863045250372718,28.80604228914724,28.787041302072076,28.739538834384177,28.711037353771438,28.67303537962112,28.65403439254596,28.59703143132048,28.57803044424532,28.51152698948226,28.51152698948226,28.51152698948226,28.4450235347192,28.407021560568882,28.397521067031303,28.3500185993434,28.32151711873066,28.31201662519308,28.3025161316555,28.3025161316555,28.29301563811792,28.264514157505182,28.236012676892443,28.207511196279704,28.169509222129385,28.169509222129385,28.160008728591805,28.141007741516646,28.112506260903906,28.036502312603265,28.027001819065685,27.998500338452946,27.979499351377786,27.969998857840206,27.893994909539565,27.789489480626187,27.770488493551028,27.73248651940071,27.72298602586313,27.71348553232555,27.69448454525039,27.65648257110007,27.58047862279943,27.55197714218669,27.53297615511153,27.53297615511153,27.49497418096121,27.485473687423628,27.485473687423628,27.41897023266057,27.39996924558541,27.39046875204783,27.37146776497267,27.333465790822352,27.333465790822352,27.266962336059294,27.23846085544655,27.20995937483381,27.200458881296232,27.152956413608333,27.152956413608333,27.152956413608333,27.114954439458014,27.095953452382854,27.06745197177011,27.048450984694952,26.943945555781575,26.905943581631256,26.905943581631256,26.905943581631256,26.858441113943357,26.858441113943357,26.801438152717875,26.763436178567556,26.734934697954817,26.706433217342077,26.544924827203218,26.535424333665638,26.5069228530529,26.46892087890258,26.40241742413952,26.373915943526782,26.33591396937646,26.3169129823013,26.2219080469255,26.20290705985034,26.18390607277518,26.11740261801212,26.069900150324223,26.060399656786643,25.965394721410846,25.927392747260523,25.917892253722943,25.908391760185363,25.87038978603504,25.85138879895988,25.794385837734403,25.765884357121664,25.737382876508924,25.727882382971345,25.642377941133127,25.604375966982808,25.594875473445228,25.57587448637007,25.556873499294905,25.528372018682166,25.528372018682166,25.51887152514459,25.50937103160701,25.49987053806943,25.49037004453185,25.480869550994267,25.44286757684395,25.41436609623121,25.395365109156046,25.366863628543307,25.357363135005727,25.347862641468147,25.328861654392988,25.30036017378025,25.24335721255477,25.23385671901719,25.16735326425413,25.119850796566233,25.08184882241591,25.08184882241591,24.94884191288979,24.94884191288979,24.92984092581463,24.91083993873947,24.90133944520189,24.872837964589152,24.853836977513993,24.825335496901253,24.806334509826094,24.796834016288514,24.777833029213355,24.768332535675775,24.711329574450296,24.673327600299974,24.654326613224814,24.625825132612075,24.625825132612075,24.578322664924176,24.549821184311437,24.521319703698694,24.502318716623535,24.492818223085955,24.454816248935636,24.35031082002226,24.22680440403372,24.21730391049614,24.131799468657917,24.00829305266938,23.98929206559422,23.894287130218423,23.865785649605684,23.837284168992944,23.799282194842622,23.780281207767462,23.74227923361714,23.7137777530044,23.67577577885408,23.647274298241342,23.628273311166183,23.495266401640066,23.485765908102486,23.476265414564907,23.447763933952167,23.419262453339424,23.400261466264265,23.181750114899927,23.172249621362347,23.143748140749608,23.12474715367445,23.12474715367445,23.11524666013687,23.03924271183623,23.029742218298647,23.020241724761068,22.90623580231011,22.89673530877253,22.83973234754705,22.83023185400947,22.77322889278399,22.74472741217125,22.74472741217125,22.678223957408193,22.583219022032395,22.545217047882073,22.516715567269333,22.516715567269333,22.45971260604385,22.402709644818373,22.393209151280793,22.336206190055314,22.326705696517735,22.279203228829836,22.269702735292256,22.203199280529198,22.203199280529198,22.16519730637888,22.117694838690976,22.098693851615817,22.060691877465494,22.060691877465494,21.994188422702436,21.946685955014537,21.946685955014537,21.937185461476957,21.88968299378906,21.88018250025148,21.8706820067139,21.78517756487568,21.78517756487568,21.7756770713381,21.718674110112623,21.64267016181198,21.623669174736822,21.5856672005865,21.414658316910064,21.272150913846364,21.262650420308784,21.253149926771204,21.167645484932983,21.158144991395403,21.158144991395403,21.158144991395403,21.129643510782664,21.110642523707504,21.072640549557185,20.996636601256547,20.93963364003107,20.91113215941833,20.90163166588075,20.844628704655268,20.835128211117688,20.75912426281705,20.692620808053988,20.64511834036609,20.63561784682851,20.62611735329093,20.61661685975335,20.59761587267819,20.58811537914061,20.531112417915132,20.502610937302393,20.49311044376481,20.48360995022723,20.48360995022723,20.32210156008837,20.28409958593805,20.28409958593805,20.27459909240047,20.208095637637413,20.189094650562254,20.141592182874355,20.141592182874355,19.951582312122756,19.932581325047593,19.780573428446317,19.6475665189202,19.63806602538262,19.628565531845037,19.58106306415714,19.5525615835444,19.5050591158565,19.4100541804807,19.32454973864248,19.2200443097291,19.163041348503626,19.153540854966042,19.144040361428466,19.134539867890883,19.077536906665404,19.06803641312782,19.020533945439922,18.954030490676864,18.935029503601704,18.906528022988965,18.868526048838646,18.792522100538008,18.73551913931253,18.650014697474308,18.49800680087303,18.460004826722706,18.441003839647546,18.31749742365901,18.30799693012143,18.29849643658385,18.28899594304627,18.26049446243353,18.25099396889595,18.22249248828321,18.20349150120805,18.14648853998257,18.14648853998257,18.13698804644499,18.10848656583225,17.98498014984371,17.851973240317594,17.83297225324243,17.83297225324243,17.794970279092112,17.709465837253894,17.652462876028416,17.528956460039876,17.519455966502296,17.424451031126498,17.40545004405134,17.39594955051376,17.39594955051376,17.38644905697618,17.3294460957507,17.3294460957507,17.3294460957507,17.319945602213117,17.139436224999102,17.129935731461522,17.12043523792394,17.01592980901056,17.01592980901056,16.825919938258963,16.806918951183803,16.778417470571064,16.768916977033484,16.73091500288316,16.692913028732843,16.645410561044944,16.493402664443664,16.360395754917548,16.208387858316268,16.15138489709079,16.00887749402709,15.84736910388823,15.771365155587592,15.761864662050012,15.666859726674215,15.628857752523892,15.476849855922616,15.258338504558278,15.248838011020695,15.229837023945539,15.125331595032158,14.963823204893298,14.74531185352896,14.583803463390105,14.526800502164626,14.469797540939144,14.393793592638506,14.374792605563346,14.298788657262705,14.298788657262705,14.175282241274168,14.165781747736585,14.108778786511106,13.861765954534029,13.548249667793893,13.082725484452475,12.949718574926358,12.816711665400238,12.721706730024437,12.61720130111106,12.474693898047363,12.44619241743462,12.42719143035946,12.379688962671562,12.132676130694481,12.047171688856263,11.952166753480466,11.781157869804026,11.771657376266447,11.771657376266447,11.67665244089065,11.657651453815486,11.600648492590008,11.38213714122567,11.220628751086814,10.888111477271515,10.41308680039252,10.156573474877863,10.052068045964482,9.47253794017211,9.453536953096947,9.425035472484208,9.244526095270189,9.121019679281652,9.07351721159375,8.655495495940233,8.541489573489276,8.227973286749137,8.142468844910919,7.68644515510708,7.648443180956761,6.954907152713428,6.72689530781151,6.498883462909593,6.479882475834433,6.356376059845896,6.118863721406395,6.080861747256076,5.491831147926121,5.463329667313381,5.453829173775802,5.282820290099366,5.282820290099366,4.161762052664933,2.233161864536207,1.9006445907209155,1.8626426165705965,1.520624849217711,-0.5789842225874438,-1.519533082807854],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"LSTAT\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"MEDV\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('00ab42b8-c327-4093-84cb-7f16dbd6d9d3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(BDF, \n",
    "                 x=\"LSTAT\", \n",
    "                 y=\"MEDV\", \n",
    "                 height=500,\n",
    "                 trendline='ols',\n",
    "                 template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c2c9f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2a = BDF[['LSTAT']].values\n",
    "y2a = BDF['MEDV'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "262c3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2a, y2a, test_size=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a534a1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model3=LinearRegression()\n",
    "linear_model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "414a3dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 6.2158\n",
      "            Mean Absolute Error (MAE) : 4.5483\n",
      "          Mean Percentage Error (MPE) : -5.7269\n",
      "Mean Absolute Percentage Error (MAPE) : 22.1874\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.2139\n",
      "       Root Mean Squared Error (RMSE) : 6.1676\n",
      "            Mean Absolute Error (MAE) : 4.4298\n",
      "          Mean Percentage Error (MPE) : -5.8581\n",
      "Mean Absolute Percentage Error (MAPE) : 19.2462\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model3.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model3.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e9ffcf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.5483569257040284\n",
      "R2 for testing dataset 0.5307275781842369\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = linear_model3.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model3.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7beed6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2aa = BDF['LSTAT']\n",
    "y2aa = BDF['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a9ebb2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2aa, y2aa, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3a508da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "63c662dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   457.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>4.70e-67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:47:10</td>     <th>  Log-Likelihood:    </th> <td> -1230.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   379</td>      <th>  AIC:               </th> <td>   2464.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   377</td>      <th>  BIC:               </th> <td>   2472.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   34.5786</td> <td>    0.648</td> <td>   53.365</td> <td> 0.000</td> <td>   33.304</td> <td>   35.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th> <td>   -0.9478</td> <td>    0.044</td> <td>  -21.395</td> <td> 0.000</td> <td>   -1.035</td> <td>   -0.861</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>104.605</td> <th>  Durbin-Watson:     </th> <td>   1.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 219.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.444</td>  <th>  Prob(JB):          </th> <td>1.86e-48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.362</td>  <th>  Cond. No.          </th> <td>    29.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.548\n",
       "Model:                            OLS   Adj. R-squared:                  0.547\n",
       "Method:                 Least Squares   F-statistic:                     457.7\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):           4.70e-67\n",
       "Time:                        11:47:10   Log-Likelihood:                -1230.2\n",
       "No. Observations:                 379   AIC:                             2464.\n",
       "Df Residuals:                     377   BIC:                             2472.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         34.5786      0.648     53.365      0.000      33.304      35.853\n",
       "LSTAT         -0.9478      0.044    -21.395      0.000      -1.035      -0.861\n",
       "==============================================================================\n",
       "Omnibus:                      104.605   Durbin-Watson:                   1.819\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              219.803\n",
       "Skew:                           1.444   Prob(JB):                     1.86e-48\n",
       "Kurtosis:                       5.362   Cond. No.                         29.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for checking the p-values checking OLS summary\n",
    "linear_model2aa=sm.OLS(y_train,X_train).fit()\n",
    "linear_model2aa.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "92fdaeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 34.57857704438267\n",
      "coefficient [-0.94776211]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', linear_model3.intercept_) # Printing the interecept for linear regression)\n",
    "print('coefficient', linear_model3.coef_ ) # Printing the coefficient for linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f905f0fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 1 => MEDV = 34.57857704438267 + [-0.94776211] * LSTAT\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 1 =>','MEDV =', linear_model3.intercept_, '+', linear_model3.coef_, '* LSTAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fa04a",
   "metadata": {},
   "source": [
    "# Does your model under or overfit the data?  How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71d1f4",
   "metadata": {},
   "source": [
    "No I don't the model overfits or underfits as there is not much diference in the MAPE value of Training and\n",
    "Testing datasets as we calculated above. I think model is working fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a3a4e",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "# Create a slightly more complicated predictive model of the target variable.  In particular, add 1-3 more variables that you think have potential to improve your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b64ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BDF=pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\BostonHousing.csv')\n",
    "\n",
    "X2b = BDF.drop(columns=['MEDV'])\n",
    "y2b = BDF['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1af5ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2b, y2b, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ced0e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    3.4s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    3.4s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 1/5 -- score: 0.6012431653338002[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 2/5 -- score: 0.7750075455445586[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 3/5 -- score: 0.7842855238090033[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 4/5 -- score: 0.7921859487802674[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 5/5 -- score: 0.7955164034189278"
     ]
    }
   ],
   "source": [
    "Forward_Selection = SFS(linear_model3,\n",
    "                        k_features=(1,5),\n",
    "                        forward=True,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring=\"r2\",\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d2d02580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 12/1 -- score: 0.8136321373418337[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 11/1 -- score: 0.8152317292377482[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 10/1 -- score: 0.8155785109165967[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 9/1 -- score: 0.8142551955271825[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 8/1 -- score: 0.8137309457919036[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 7/1 -- score: 0.8089247246270788[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 6/1 -- score: 0.8028580340869785[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 5/1 -- score: 0.7950752964143482[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 4/1 -- score: 0.784480923905664[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 3/1 -- score: 0.780899231897102[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 2/1 -- score: 0.7750075455445586[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 11:48:25] Features: 1/1 -- score: 0.6012431653338002"
     ]
    }
   ],
   "source": [
    "Backward_Selection = SFS(linear_model3,\n",
    "                        k_features=(1,6),\n",
    "                        forward=False,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring='r2',\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aeb108b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for backward selected features 0.8028580340869785\n",
      "\n",
      "Backard selected features ('CHAS', 'NOX', 'DIS', 'PTRATIO', 'LSTAT', 'CAT. MEDV')\n",
      "\n",
      "Score for forward selected features 0.7955164034189278\n",
      "\n",
      "Forward selected features ('CRIM', 'CHAS', 'DIS', 'LSTAT', 'CAT. MEDV')\n"
     ]
    }
   ],
   "source": [
    "print('Score for backward selected features',Backward_Selection.k_score_)\n",
    "print()\n",
    "print('Backard selected features',Backward_Selection.k_feature_names_)\n",
    "print()\n",
    "print('Score for forward selected features',Forward_Selection.k_score_)\n",
    "print()\n",
    "print('Forward selected features',Forward_Selection.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d23a9964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 2288/2288"
     ]
    }
   ],
   "source": [
    "# from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "Exhaustive_Selection = EFS(linear_model3,\n",
    "                           min_features= 3,\n",
    "                           max_features= 5,\n",
    "                           scoring='r2',\n",
    "                           n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cceaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exhaustive_Selection.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cdeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Exhaustive_Selection.best_feature_names_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0bbb8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2c = BDF[['CHAS', 'DIS', 'LSTAT']].values\n",
    "y2c = BDF['MEDV'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8448f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2c, y2c, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "daf8c107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model4=LinearRegression()\n",
    "linear_model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b883d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0000\n",
      "       Root Mean Squared Error (RMSE) : 5.9710\n",
      "            Mean Absolute Error (MAE) : 4.4046\n",
      "          Mean Percentage Error (MPE) : -5.5054\n",
      "Mean Absolute Percentage Error (MAPE) : 21.9328\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.1964\n",
      "       Root Mean Squared Error (RMSE) : 6.0441\n",
      "            Mean Absolute Error (MAE) : 4.3228\n",
      "          Mean Percentage Error (MPE) : -5.9882\n",
      "Mean Absolute Percentage Error (MAPE) : 18.8359\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model4.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model4.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "13866559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.5832265220350934\n",
      "R2 for testing dataset 0.5493349750990879\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = linear_model4.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model4.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "25d7b3d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>3.99e-93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:48:53</td>     <th>  Log-Likelihood:    </th> <td> -1623.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3254.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   502</td>      <th>  BIC:               </th> <td>   3271.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   37.4851</td> <td>    1.014</td> <td>   36.983</td> <td> 0.000</td> <td>   35.494</td> <td>   39.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    4.3020</td> <td>    1.065</td> <td>    4.039</td> <td> 0.000</td> <td>    2.209</td> <td>    6.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -0.5900</td> <td>    0.148</td> <td>   -3.991</td> <td> 0.000</td> <td>   -0.881</td> <td>   -0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -1.0283</td> <td>    0.043</td> <td>  -23.668</td> <td> 0.000</td> <td>   -1.114</td> <td>   -0.943</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>111.240</td> <th>  Durbin-Watson:     </th> <td>   1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 205.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.253</td>  <th>  Prob(JB):          </th> <td>2.34e-45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.861</td>  <th>  Cond. No.          </th> <td>    64.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.576\n",
       "Model:                            OLS   Adj. R-squared:                  0.573\n",
       "Method:                 Least Squares   F-statistic:                     227.3\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):           3.99e-93\n",
       "Time:                        11:48:53   Log-Likelihood:                -1623.2\n",
       "No. Observations:                 506   AIC:                             3254.\n",
       "Df Residuals:                     502   BIC:                             3271.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     37.4851      1.014     36.983      0.000      35.494      39.476\n",
       "CHAS           4.3020      1.065      4.039      0.000       2.209       6.395\n",
       "DIS           -0.5900      0.148     -3.991      0.000      -0.881      -0.300\n",
       "LSTAT         -1.0283      0.043    -23.668      0.000      -1.114      -0.943\n",
       "==============================================================================\n",
       "Omnibus:                      111.240   Durbin-Watson:                   1.031\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              205.531\n",
       "Skew:                           1.253   Prob(JB):                     2.34e-45\n",
       "Kurtosis:                       4.861   Cond. No.                         64.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Complex_Model2ab = smf.ols('MEDV ~ CHAS + DIS + LSTAT', data = BDF).fit()\n",
    "Complex_Model2ab.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0cadc91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept =  36.69290310118993\n",
      "coefficients [ 5.10748966 -0.49192686 -0.99558541]\n"
     ]
    }
   ],
   "source": [
    "print('intercept = ', linear_model4.intercept_) # Printing the interecept for linear regression\n",
    "print('coefficients', linear_model4.coef_ )   # Printing the coefficients for linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bcb70d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 2=> MEDV = 36.69290310118993 + 5.10748966 * CHAS - 0.49192686 * DIS - 0.99558541 * LSTAT\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 2=>','MEDV =', linear_model4.intercept_, '+',5.10748966 ,'* CHAS','-', 0.49192686,'* DIS', '-', 0.99558541, '* LSTAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930507c8",
   "metadata": {},
   "source": [
    "# Take note of any differences in model performance from 1. to 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60564e26",
   "metadata": {},
   "source": [
    "MAPE for Model 2 is less than MAPE for model 1, Model 2 performs better than one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448ec0b",
   "metadata": {},
   "source": [
    "# Do you notice any major changes in the magnitudes of your parameter estimates?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46669b70",
   "metadata": {},
   "source": [
    "Considering LSTAT feature there is not much difference in the change in the magnitudes, for model 1-0.94776211 & model 2 -0.99558541"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43665068",
   "metadata": {},
   "source": [
    "# Pick one parameter estimate and, in words, describe what it means?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a605654",
   "metadata": {},
   "source": [
    "Considering LSTAT here it is negatively correlated to the MEDV value, so LSTAT influences inversly on the MEDV values, as LSTAT increses MEDV value decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa49d88",
   "metadata": {},
   "source": [
    "# Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a632cf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'LSTAT', 'MEDV', 'CAT. MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f93e14a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  CAT. MEDV  \n",
       "0   4.98  24.0          0  \n",
       "1   9.14  21.6          0  \n",
       "2   4.03  34.7          1  \n",
       "3   2.94  33.4          1  \n",
       "4   5.33  36.2          1  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c19df349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predictor  coefficent\n",
      "0      CRIM      -0.009\n",
      "1        ZN       0.000\n",
      "2     INDUS      -0.000\n",
      "3       NOX      -0.000\n",
      "4        RM       3.058\n",
      "5       AGE      -0.000\n",
      "6       DIS      -0.000\n",
      "7       TAX      -0.000\n",
      "8   PTRATIO      -0.695\n",
      "9     LSTAT      -0.545\n",
      "\n",
      "\n",
      "          Train      Test\n",
      "R2        0.644     0.684\n",
      "MAE       3.627     4.254\n",
      "MAPE     18.500    20.500\n",
      "SSE   10711.928  3974.969\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagbhid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# considering only necessary variables.\n",
    "predictors = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX',\n",
    "       'PTRATIO', 'LSTAT'\n",
    "             ]\n",
    "X = BDF[predictors]\n",
    "y = BDF['MEDV']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.25,random_state=1)\n",
    "\n",
    "r_alphas = [0.04,0.06,0.08,0.085,0.09,0.099,.1,0.11,0.2,0.25]\n",
    "\n",
    "model = LassoCV(alphas=r_alphas,normalize=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "train_test_metrics(X_train,X_test,y_train,y_test,model2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a1c1d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Alpha Selection:  0.04\n"
     ]
    }
   ],
   "source": [
    "print('LassoCV Alpha Selection: ',model.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b8b8b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 1=> MEDV = 34.57857704438267 + [-0.94776211] * LSTAT\n",
      "\n",
      "Model Form 2=> FARE = 36.69290310118993 + 5.10748966 * CHAS - 0.49192686 * DIS - 0.99558541 * LSTAT\n",
      "\n",
      "Model Form 3=> FARE = 23.13832084677211 - 3.058 * RM + 0.075 * DISTANCE - 0.695 * PTRATIO - 0.545 * LSTAT\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE) for model 1 : 19.2462\n",
      "Mean Absolute Percentage Error (MAPE) for model 2 : 18.8359\n",
      "Mean Absolute Percentage Error (MAPE) for model 3 :  20.500\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 1=>','MEDV =', linear_model3.intercept_, '+', linear_model3.coef_,'* LSTAT' )\n",
    "print()\n",
    "print ('Model Form 2=>','FARE =', linear_model4.intercept_, '+', 5.10748966 ,'* CHAS','-', 0.49192686,'* DIS', '-', 0.99558541, '* LSTAT',)\n",
    "print()\n",
    "print ('Model Form 3=>','FARE =', model.intercept_, '-',3.058 ,'* RM','+', 0.075,'* DISTANCE', '-',0.695, '* PTRATIO', '-', 0.545, '* LSTAT')\n",
    "\n",
    "print()\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 1 : 19.2462\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 2 : 18.8359\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 3 :  20.500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ad4f9",
   "metadata": {},
   "source": [
    "# DATASET 3 - Toyota Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "97f9f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_Beige</th>\n",
       "      <th>Color_Black</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Grey</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Silver</th>\n",
       "      <th>Color_Violet</th>\n",
       "      <th>Color_White</th>\n",
       "      <th>Color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1438</td>\n",
       "      <td>7500</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>1998</td>\n",
       "      <td>20544</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1439</td>\n",
       "      <td>10845</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>1998</td>\n",
       "      <td>19000</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1440</td>\n",
       "      <td>8500</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>1998</td>\n",
       "      <td>17016</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1441</td>\n",
       "      <td>7250</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>1998</td>\n",
       "      <td>16916</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1442</td>\n",
       "      <td>6950</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Price  Age_08_04  Mfg_Month  Mfg_Year     KM   HP  Met_Color  \\\n",
       "0        1  13500         23         10      2002  46986   90          1   \n",
       "1        2  13750         23         10      2002  72937   90          1   \n",
       "2        3  13950         24          9      2002  41711   90          1   \n",
       "3        4  14950         26          7      2002  48000   90          0   \n",
       "4        5  13750         30          3      2002  38500   90          0   \n",
       "...    ...    ...        ...        ...       ...    ...  ...        ...   \n",
       "1431  1438   7500         69         12      1998  20544   86          1   \n",
       "1432  1439  10845         72          9      1998  19000   86          0   \n",
       "1433  1440   8500         71         10      1998  17016   86          0   \n",
       "1434  1441   7250         70         11      1998  16916   86          1   \n",
       "1435  1442   6950         76          5      1998      1  110          0   \n",
       "\n",
       "      Automatic    CC  ...  Color_Beige  Color_Black  Color_Blue  Color_Green  \\\n",
       "0             0  2000  ...            0            0           1            0   \n",
       "1             0  2000  ...            0            0           0            0   \n",
       "2             0  2000  ...            0            0           1            0   \n",
       "3             0  2000  ...            0            1           0            0   \n",
       "4             0  2000  ...            0            1           0            0   \n",
       "...         ...   ...  ...          ...          ...         ...          ...   \n",
       "1431          0  1300  ...            0            0           1            0   \n",
       "1432          0  1300  ...            0            0           0            0   \n",
       "1433          0  1300  ...            0            0           1            0   \n",
       "1434          0  1300  ...            0            0           0            0   \n",
       "1435          0  1600  ...            0            0           0            1   \n",
       "\n",
       "      Color_Grey  Color_Red  Color_Silver  Color_Violet  Color_White  \\\n",
       "0              0          0             0             0            0   \n",
       "1              0          0             1             0            0   \n",
       "2              0          0             0             0            0   \n",
       "3              0          0             0             0            0   \n",
       "4              0          0             0             0            0   \n",
       "...          ...        ...           ...           ...          ...   \n",
       "1431           0          0             0             0            0   \n",
       "1432           1          0             0             0            0   \n",
       "1433           0          0             0             0            0   \n",
       "1434           1          0             0             0            0   \n",
       "1435           0          0             0             0            0   \n",
       "\n",
       "      Color_Yellow  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1431             0  \n",
       "1432             0  \n",
       "1433             0  \n",
       "1434             0  \n",
       "1435             0  \n",
       "\n",
       "[1436 rows x 49 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDF=pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\ToyotaCorolla.csv')\n",
    "TDF = TDF.drop(columns=['Model'])\n",
    "TDF = pd.get_dummies(TDF, columns = ['Fuel_Type', 'Color'])\n",
    "TDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "906bafd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price                1.000000\n",
       "Mfg_Year             0.885159\n",
       "Boardcomputer        0.601292\n",
       "Automatic_airco      0.588262\n",
       "Weight               0.581198\n",
       "CD_Player            0.481374\n",
       "Airco                0.429259\n",
       "Powered_Windows      0.356518\n",
       "Central_Lock         0.343458\n",
       "HP                   0.314990\n",
       "ABS                  0.306138\n",
       "Airbag_2             0.248974\n",
       "Mistlamps            0.222083\n",
       "Quarterly_Tax        0.219197\n",
       "Mfr_Guarantee        0.197802\n",
       "Doors                0.185326\n",
       "Color_Grey           0.169947\n",
       "Sport_Model          0.164121\n",
       "Guarantee_Period     0.146627\n",
       "CC                   0.126389\n",
       "Met_Color            0.108905\n",
       "Metallic_Rim         0.108564\n",
       "Backseat_Divider     0.102569\n",
       "Airbag_1             0.093588\n",
       "Power_Steering       0.064275\n",
       "Gears                0.063104\n",
       "Fuel_Type_Diesel     0.054084\n",
       "Parking_Assistant    0.044375\n",
       "Color_Black          0.034896\n",
       "Automatic            0.033081\n",
       "Color_Silver         0.028562\n",
       "BOVAG_Guarantee      0.028133\n",
       "Color_Yellow         0.022726\n",
       "Color_Blue           0.014431\n",
       "Color_Violet        -0.016848\n",
       "Mfg_Month           -0.018138\n",
       "Color_Beige         -0.022684\n",
       "Fuel_Type_Petrol    -0.038516\n",
       "Fuel_Type_CNG       -0.039536\n",
       "Radio               -0.041887\n",
       "Radio_cassette      -0.043179\n",
       "Color_White         -0.103360\n",
       "Color_Red           -0.103803\n",
       "Color_Green         -0.104963\n",
       "Tow_Bar             -0.172369\n",
       "KM                  -0.569960\n",
       "Id                  -0.738250\n",
       "Age_08_04           -0.876590\n",
       "Cylinders                 NaN\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choosing the variable with highest correlation - \"Age_08_04\"\n",
    "TDFcorr_matrix = TDF.corr()\n",
    "TDFcorr_matrix[\"Price\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "41d83b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Age_08_04=%{x}<br>Price=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          23,
          23,
          24,
          26,
          30,
          32,
          27,
          30,
          27,
          23,
          25,
          22,
          25,
          31,
          32,
          28,
          30,
          24,
          24,
          30,
          30,
          29,
          28,
          28,
          29,
          25,
          27,
          29,
          28,
          30,
          29,
          22,
          27,
          26,
          22,
          26,
          25,
          23,
          32,
          27,
          22,
          27,
          22,
          27,
          22,
          23,
          27,
          22,
          22,
          31,
          22,
          30,
          26,
          27,
          25,
          32,
          28,
          26,
          23,
          30,
          22,
          27,
          31,
          30,
          27,
          26,
          28,
          22,
          22,
          25,
          28,
          32,
          28,
          23,
          28,
          23,
          31,
          27,
          29,
          30,
          25,
          29,
          25,
          31,
          25,
          28,
          30,
          20,
          19,
          19,
          20,
          20,
          16,
          20,
          20,
          17,
          19,
          19,
          11,
          18,
          20,
          19,
          13,
          11,
          11,
          19,
          14,
          17,
          20,
          4,
          4,
          4,
          8,
          8,
          7,
          8,
          8,
          7,
          20,
          17,
          13,
          19,
          14,
          20,
          17,
          16,
          20,
          20,
          17,
          13,
          20,
          20,
          19,
          13,
          20,
          19,
          19,
          13,
          11,
          20,
          20,
          19,
          13,
          16,
          15,
          16,
          20,
          13,
          19,
          14,
          20,
          19,
          10,
          12,
          13,
          15,
          16,
          11,
          17,
          16,
          16,
          17,
          9,
          14,
          11,
          14,
          14,
          14,
          12,
          9,
          9,
          8,
          8,
          8,
          8,
          8,
          8,
          7,
          8,
          6,
          7,
          7,
          2,
          2,
          1,
          1,
          43,
          38,
          40,
          43,
          40,
          44,
          44,
          40,
          41,
          37,
          44,
          39,
          42,
          39,
          44,
          40,
          42,
          35,
          43,
          44,
          40,
          43,
          41,
          37,
          41,
          40,
          34,
          40,
          33,
          33,
          33,
          41,
          44,
          38,
          43,
          44,
          40,
          44,
          35,
          38,
          35,
          34,
          42,
          36,
          44,
          33,
          42,
          41,
          41,
          38,
          44,
          35,
          44,
          40,
          38,
          38,
          43,
          33,
          33,
          39,
          42,
          39,
          43,
          42,
          33,
          43,
          43,
          42,
          39,
          42,
          38,
          44,
          44,
          33,
          41,
          39,
          41,
          40,
          39,
          38,
          44,
          34,
          40,
          39,
          33,
          38,
          35,
          34,
          43,
          41,
          39,
          39,
          43,
          38,
          35,
          40,
          39,
          40,
          41,
          39,
          40,
          37,
          44,
          43,
          36,
          39,
          35,
          33,
          42,
          38,
          44,
          40,
          35,
          39,
          37,
          41,
          43,
          39,
          44,
          41,
          44,
          42,
          37,
          42,
          40,
          44,
          42,
          39,
          43,
          41,
          44,
          38,
          42,
          44,
          40,
          36,
          37,
          44,
          39,
          41,
          42,
          33,
          35,
          43,
          41,
          35,
          38,
          40,
          34,
          35,
          33,
          41,
          43,
          42,
          41,
          44,
          42,
          41,
          33,
          41,
          40,
          38,
          43,
          33,
          39,
          42,
          38,
          38,
          43,
          39,
          39,
          33,
          43,
          41,
          39,
          35,
          41,
          40,
          38,
          41,
          35,
          41,
          37,
          44,
          39,
          35,
          40,
          33,
          40,
          38,
          39,
          43,
          53,
          51,
          53,
          54,
          45,
          55,
          54,
          51,
          53,
          48,
          48,
          54,
          55,
          52,
          49,
          56,
          50,
          48,
          53,
          47,
          55,
          54,
          53,
          54,
          56,
          49,
          52,
          54,
          51,
          47,
          50,
          54,
          50,
          52,
          48,
          51,
          49,
          55,
          51,
          54,
          55,
          55,
          49,
          53,
          53,
          48,
          52,
          45,
          49,
          54,
          50,
          50,
          50,
          50,
          54,
          49,
          49,
          53,
          47,
          48,
          55,
          49,
          54,
          50,
          46,
          54,
          48,
          50,
          55,
          49,
          56,
          49,
          50,
          47,
          49,
          52,
          50,
          53,
          54,
          54,
          50,
          53,
          55,
          49,
          46,
          47,
          49,
          55,
          46,
          56,
          52,
          54,
          50,
          56,
          52,
          56,
          48,
          54,
          54,
          53,
          54,
          54,
          48,
          55,
          54,
          56,
          54,
          50,
          50,
          54,
          56,
          53,
          47,
          54,
          51,
          51,
          54,
          52,
          54,
          55,
          56,
          53,
          51,
          47,
          53,
          55,
          48,
          54,
          53,
          55,
          50,
          46,
          52,
          51,
          51,
          49,
          56,
          55,
          55,
          56,
          48,
          50,
          54,
          51,
          53,
          49,
          51,
          52,
          48,
          54,
          56,
          54,
          48,
          54,
          54,
          52,
          53,
          50,
          56,
          54,
          56,
          52,
          47,
          54,
          52,
          50,
          50,
          47,
          56,
          55,
          56,
          48,
          49,
          52,
          49,
          50,
          49,
          50,
          47,
          54,
          47,
          50,
          54,
          54,
          47,
          51,
          56,
          54,
          55,
          48,
          52,
          49,
          45,
          52,
          56,
          48,
          49,
          51,
          46,
          56,
          55,
          46,
          49,
          52,
          56,
          46,
          55,
          50,
          55,
          52,
          48,
          55,
          48,
          53,
          47,
          50,
          50,
          56,
          50,
          51,
          48,
          50,
          47,
          50,
          52,
          58,
          68,
          68,
          59,
          62,
          65,
          67,
          68,
          67,
          59,
          64,
          64,
          67,
          62,
          59,
          64,
          65,
          68,
          60,
          59,
          61,
          67,
          64,
          58,
          65,
          64,
          60,
          59,
          67,
          67,
          66,
          62,
          68,
          61,
          59,
          64,
          66,
          68,
          68,
          68,
          57,
          64,
          68,
          65,
          68,
          64,
          58,
          60,
          68,
          63,
          64,
          65,
          59,
          67,
          59,
          68,
          66,
          62,
          65,
          61,
          68,
          62,
          63,
          68,
          67,
          64,
          58,
          59,
          62,
          68,
          67,
          68,
          58,
          63,
          63,
          68,
          57,
          61,
          68,
          57,
          63,
          68,
          61,
          65,
          67,
          59,
          65,
          64,
          61,
          61,
          65,
          66,
          67,
          60,
          67,
          61,
          68,
          65,
          66,
          63,
          65,
          65,
          68,
          62,
          67,
          61,
          65,
          68,
          64,
          65,
          58,
          68,
          62,
          60,
          64,
          63,
          68,
          63,
          62,
          57,
          61,
          62,
          65,
          59,
          59,
          59,
          68,
          65,
          62,
          60,
          68,
          65,
          62,
          68,
          62,
          67,
          68,
          64,
          62,
          58,
          61,
          65,
          68,
          66,
          65,
          61,
          66,
          61,
          57,
          65,
          59,
          68,
          62,
          65,
          68,
          65,
          62,
          60,
          65,
          67,
          67,
          59,
          60,
          61,
          57,
          59,
          68,
          64,
          65,
          61,
          67,
          68,
          65,
          63,
          68,
          68,
          66,
          61,
          67,
          59,
          65,
          61,
          62,
          67,
          68,
          65,
          62,
          66,
          68,
          68,
          63,
          60,
          62,
          60,
          68,
          64,
          65,
          67,
          61,
          64,
          64,
          64,
          58,
          58,
          67,
          63,
          64,
          57,
          59,
          65,
          62,
          60,
          63,
          58,
          67,
          62,
          60,
          59,
          64,
          65,
          67,
          68,
          68,
          58,
          67,
          68,
          58,
          63,
          63,
          63,
          65,
          65,
          67,
          68,
          67,
          59,
          65,
          68,
          68,
          61,
          62,
          65,
          61,
          63,
          67,
          65,
          59,
          68,
          60,
          64,
          68,
          57,
          62,
          68,
          60,
          62,
          65,
          63,
          65,
          67,
          60,
          68,
          66,
          58,
          66,
          65,
          61,
          65,
          62,
          67,
          68,
          65,
          68,
          66,
          58,
          60,
          62,
          57,
          68,
          68,
          65,
          58,
          62,
          59,
          62,
          61,
          59,
          60,
          68,
          57,
          65,
          59,
          61,
          67,
          66,
          65,
          62,
          65,
          63,
          63,
          65,
          61,
          65,
          68,
          65,
          66,
          65,
          60,
          64,
          66,
          67,
          58,
          62,
          68,
          63,
          65,
          62,
          61,
          63,
          63,
          67,
          63,
          59,
          62,
          67,
          63,
          57,
          61,
          58,
          60,
          65,
          65,
          57,
          63,
          68,
          67,
          60,
          61,
          61,
          57,
          58,
          57,
          62,
          65,
          68,
          68,
          64,
          67,
          57,
          60,
          66,
          61,
          58,
          58,
          61,
          65,
          61,
          66,
          59,
          61,
          62,
          65,
          67,
          62,
          61,
          63,
          62,
          63,
          68,
          66,
          58,
          60,
          65,
          59,
          63,
          65,
          65,
          57,
          57,
          65,
          66,
          63,
          61,
          63,
          61,
          68,
          59,
          60,
          58,
          68,
          57,
          64,
          68,
          67,
          63,
          64,
          57,
          60,
          66,
          66,
          62,
          61,
          68,
          61,
          60,
          62,
          59,
          60,
          63,
          66,
          65,
          65,
          62,
          65,
          68,
          57,
          64,
          58,
          68,
          57,
          65,
          59,
          65,
          60,
          57,
          68,
          58,
          68,
          60,
          60,
          57,
          68,
          62,
          62,
          58,
          66,
          59,
          63,
          62,
          67,
          66,
          73,
          79,
          78,
          79,
          74,
          77,
          69,
          80,
          76,
          76,
          78,
          70,
          73,
          78,
          77,
          77,
          71,
          78,
          80,
          78,
          74,
          73,
          69,
          73,
          78,
          69,
          76,
          70,
          71,
          75,
          69,
          75,
          77,
          80,
          71,
          79,
          74,
          80,
          76,
          71,
          73,
          79,
          77,
          74,
          78,
          77,
          80,
          73,
          71,
          72,
          77,
          76,
          75,
          74,
          70,
          76,
          74,
          72,
          75,
          74,
          80,
          77,
          74,
          77,
          71,
          76,
          74,
          71,
          78,
          73,
          76,
          71,
          78,
          77,
          73,
          74,
          72,
          73,
          80,
          76,
          80,
          72,
          80,
          75,
          78,
          71,
          73,
          75,
          74,
          71,
          72,
          72,
          77,
          80,
          76,
          74,
          74,
          73,
          80,
          75,
          77,
          75,
          74,
          75,
          74,
          74,
          79,
          78,
          80,
          75,
          80,
          73,
          79,
          69,
          72,
          79,
          71,
          77,
          80,
          78,
          73,
          73,
          69,
          74,
          78,
          74,
          78,
          79,
          78,
          79,
          80,
          80,
          80,
          79,
          72,
          79,
          77,
          80,
          80,
          80,
          72,
          70,
          78,
          75,
          71,
          78,
          77,
          78,
          77,
          70,
          78,
          74,
          79,
          76,
          75,
          69,
          74,
          72,
          73,
          75,
          78,
          75,
          73,
          72,
          70,
          78,
          73,
          80,
          72,
          80,
          79,
          80,
          70,
          80,
          70,
          73,
          70,
          73,
          79,
          76,
          73,
          74,
          80,
          78,
          77,
          75,
          80,
          76,
          71,
          69,
          71,
          71,
          78,
          78,
          75,
          77,
          80,
          71,
          79,
          76,
          70,
          77,
          78,
          69,
          74,
          78,
          77,
          71,
          72,
          77,
          78,
          75,
          76,
          73,
          80,
          71,
          72,
          77,
          72,
          78,
          79,
          78,
          71,
          73,
          69,
          69,
          78,
          80,
          69,
          75,
          80,
          80,
          75,
          79,
          71,
          75,
          78,
          75,
          80,
          76,
          70,
          77,
          79,
          78,
          71,
          78,
          78,
          78,
          77,
          77,
          80,
          80,
          79,
          79,
          78,
          72,
          76,
          80,
          77,
          80,
          73,
          77,
          76,
          80,
          75,
          75,
          78,
          73,
          79,
          74,
          76,
          70,
          75,
          76,
          78,
          70,
          69,
          80,
          79,
          80,
          74,
          80,
          80,
          78,
          80,
          79,
          71,
          75,
          77,
          75,
          71,
          80,
          79,
          75,
          80,
          80,
          77,
          80,
          77,
          77,
          74,
          77,
          75,
          70,
          79,
          70,
          76,
          70,
          72,
          80,
          79,
          69,
          77,
          76,
          76,
          80,
          73,
          71,
          70,
          69,
          74,
          75,
          80,
          80,
          70,
          80,
          78,
          75,
          76,
          75,
          69,
          80,
          73,
          73,
          79,
          74,
          79,
          77,
          69,
          76,
          77,
          80,
          69,
          78,
          75,
          69,
          73,
          70,
          79,
          69,
          80,
          76,
          77,
          71,
          75,
          74,
          70,
          71,
          78,
          73,
          77,
          76,
          70,
          69,
          80,
          75,
          78,
          76,
          69,
          74,
          80,
          72,
          79,
          79,
          73,
          75,
          76,
          78,
          78,
          80,
          73,
          80,
          78,
          71,
          72,
          78,
          80,
          69,
          72,
          71,
          70,
          76
         ],
         "xaxis": "x",
         "y": [
          13500,
          13750,
          13950,
          14950,
          13750,
          12950,
          16900,
          18600,
          21500,
          12950,
          20950,
          19950,
          19600,
          21500,
          22500,
          22000,
          22750,
          17950,
          16750,
          16950,
          15950,
          16950,
          15950,
          16950,
          16250,
          15950,
          17495,
          15750,
          16950,
          17950,
          12950,
          15750,
          15950,
          14950,
          15500,
          15750,
          15950,
          14950,
          15750,
          14750,
          13950,
          16750,
          13950,
          16950,
          16950,
          19000,
          17950,
          15800,
          17950,
          21950,
          17950,
          15750,
          20500,
          21950,
          15500,
          13250,
          15250,
          15250,
          18950,
          15999,
          14950,
          16500,
          18750,
          17950,
          17950,
          16950,
          18950,
          14950,
          22250,
          15950,
          15950,
          12995,
          18950,
          15750,
          19950,
          16950,
          18750,
          18450,
          16895,
          14900,
          18950,
          17250,
          15450,
          17950,
          16650,
          17450,
          14900,
          17950,
          15950,
          21950,
          16450,
          22250,
          19950,
          15950,
          18900,
          19950,
          15950,
          15950,
          18750,
          17450,
          18990,
          16250,
          18500,
          18500,
          19450,
          16950,
          18800,
          17450,
          17950,
          32500,
          31000,
          31275,
          24950,
          24950,
          22950,
          24990,
          21950,
          17900,
          19250,
          22250,
          18950,
          19950,
          16350,
          18950,
          16950,
          21750,
          15950,
          16500,
          17950,
          15850,
          16250,
          15950,
          16250,
          15950,
          16500,
          16500,
          18450,
          16250,
          23000,
          19900,
          16450,
          23950,
          19950,
          18500,
          18950,
          16450,
          20500,
          24500,
          19450,
          20950,
          17200,
          19950,
          18450,
          19500,
          21750,
          16868,
          19500,
          18900,
          19750,
          19750,
          18950,
          20750,
          19600,
          19500,
          17650,
          19950,
          19950,
          20950,
          20500,
          17795,
          18245,
          23750,
          19500,
          18950,
          21950,
          19950,
          18950,
          19950,
          21950,
          22500,
          18500,
          18700,
          21125,
          21500,
          17795,
          18245,
          6950,
          9500,
          11950,
          7750,
          11950,
          4350,
          4750,
          11750,
          13250,
          11950,
          11900,
          14750,
          9950,
          11950,
          11495,
          11250,
          10500,
          10450,
          12950,
          11500,
          12500,
          10950,
          11450,
          11950,
          13250,
          14750,
          11790,
          11450,
          13500,
          10950,
          13500,
          10950,
          10950,
          12950,
          11950,
          12450,
          11950,
          14950,
          12450,
          12950,
          11950,
          11690,
          12450,
          12750,
          11925,
          12950,
          11950,
          12900,
          11900,
          11650,
          10950,
          13950,
          13950,
          11950,
          10950,
          12450,
          11950,
          13500,
          11690,
          13500,
          11950,
          12900,
          13500,
          11750,
          11750,
          10850,
          11750,
          14950,
          9940,
          12900,
          13500,
          11750,
          11950,
          13450,
          11950,
          12495,
          13500,
          12750,
          12000,
          11950,
          12495,
          12450,
          14750,
          10950,
          13500,
          12950,
          13500,
          13450,
          13500,
          11480,
          13450,
          11495,
          12750,
          14990,
          12950,
          12950,
          12850,
          13950,
          11950,
          12950,
          11700,
          9950,
          11895,
          12950,
          12500,
          13875,
          10500,
          12295,
          13950,
          10950,
          12950,
          12850,
          13995,
          13750,
          12750,
          12500,
          13950,
          11500,
          13950,
          11895,
          9950,
          13500,
          11450,
          12450,
          12950,
          13995,
          11750,
          11650,
          9950,
          13950,
          12950,
          10950,
          9900,
          11950,
          11990,
          10750,
          13950,
          11250,
          12950,
          11950,
          10950,
          12950,
          12950,
          11695,
          11000,
          13950,
          11950,
          11750,
          12400,
          12500,
          12900,
          12200,
          12750,
          11950,
          11900,
          11950,
          14950,
          11950,
          12950,
          14950,
          13450,
          13750,
          12950,
          12750,
          11895,
          9950,
          12450,
          12500,
          14950,
          13750,
          12695,
          14990,
          12750,
          14350,
          12950,
          11500,
          11950,
          13450,
          12900,
          10500,
          10950,
          11950,
          11450,
          13250,
          10250,
          13995,
          11950,
          13250,
          12950,
          11750,
          11500,
          13500,
          6500,
          6400,
          7000,
          7750,
          8900,
          8500,
          8950,
          9900,
          10250,
          9250,
          7750,
          9450,
          7750,
          8250,
          9950,
          4450,
          9950,
          9000,
          9950,
          12450,
          10500,
          10750,
          8950,
          10500,
          5150,
          10950,
          9450,
          9950,
          10950,
          11900,
          9950,
          11950,
          7900,
          10950,
          8950,
          11950,
          10900,
          9950,
          9950,
          10950,
          8950,
          8950,
          10500,
          8950,
          9250,
          11500,
          9750,
          9950,
          11450,
          12500,
          10500,
          12950,
          12200,
          10950,
          10950,
          11290,
          10750,
          10895,
          11500,
          9750,
          10250,
          12500,
          11950,
          10750,
          11450,
          11950,
          11750,
          10950,
          11950,
          10995,
          11450,
          8900,
          10500,
          11750,
          11450,
          12000,
          11950,
          9850,
          10950,
          10950,
          8695,
          10990,
          9500,
          11950,
          10750,
          8750,
          8750,
          11450,
          9950,
          11950,
          13950,
          11250,
          10900,
          9750,
          9950,
          11950,
          10450,
          8950,
          10250,
          9930,
          10500,
          11950,
          11500,
          11500,
          11450,
          9900,
          9500,
          10500,
          10750,
          8950,
          12000,
          9940,
          10950,
          10750,
          9799,
          11750,
          11950,
          11250,
          11750,
          10950,
          11250,
          9950,
          9700,
          11950,
          9900,
          9990,
          9475,
          11500,
          11950,
          11500,
          10500,
          10900,
          11700,
          11900,
          13950,
          10950,
          10500,
          10750,
          11950,
          10000,
          10495,
          11450,
          9400,
          11950,
          9650,
          18950,
          11450,
          10250,
          11450,
          9950,
          10500,
          13750,
          9950,
          10250,
          10850,
          11895,
          12950,
          11950,
          10750,
          9550,
          10950,
          11750,
          10950,
          12450,
          10500,
          10900,
          12950,
          10950,
          12500,
          9950,
          10750,
          12500,
          10450,
          10750,
          12950,
          10995,
          11950,
          11250,
          11950,
          13750,
          11000,
          13500,
          10950,
          10750,
          8950,
          12950,
          9750,
          10900,
          10995,
          10750,
          10950,
          13000,
          12950,
          11500,
          10950,
          11710,
          9980,
          12250,
          11500,
          11950,
          11500,
          11900,
          11930,
          10500,
          8950,
          10450,
          10500,
          12950,
          9950,
          12900,
          9950,
          9950,
          10950,
          10950,
          9950,
          10950,
          10800,
          10500,
          10450,
          10600,
          10450,
          12950,
          11250,
          7500,
          8950,
          6950,
          7900,
          5950,
          7500,
          7500,
          6900,
          5751,
          6950,
          7950,
          7750,
          7950,
          8250,
          6250,
          9500,
          6900,
          8450,
          7350,
          8950,
          6900,
          8950,
          8750,
          7950,
          8950,
          8950,
          8950,
          7950,
          7750,
          7500,
          8950,
          9800,
          9450,
          8950,
          8750,
          10500,
          7995,
          10450,
          9950,
          9950,
          8950,
          7950,
          10950,
          9950,
          8600,
          7250,
          6950,
          8000,
          9950,
          9450,
          7950,
          9450,
          9950,
          6950,
          8250,
          9950,
          8250,
          9950,
          10500,
          7950,
          9750,
          9250,
          9500,
          9950,
          7750,
          9500,
          9950,
          9750,
          9750,
          5950,
          8500,
          8495,
          9250,
          6900,
          8950,
          9500,
          9250,
          9895,
          9950,
          7950,
          8750,
          8250,
          8950,
          8950,
          8950,
          8950,
          9450,
          8950,
          9250,
          8750,
          9950,
          9950,
          9900,
          8950,
          8950,
          12250,
          9250,
          10250,
          8950,
          7999,
          9900,
          8250,
          10500,
          8450,
          9900,
          10500,
          8500,
          9500,
          9450,
          9900,
          8250,
          8750,
          9500,
          8450,
          8490,
          8750,
          9750,
          9950,
          8500,
          8450,
          7900,
          8750,
          7950,
          6900,
          8150,
          10995,
          8900,
          9500,
          8950,
          11500,
          10450,
          10500,
          9250,
          10950,
          10450,
          9250,
          8750,
          8750,
          9800,
          8250,
          10450,
          9750,
          8950,
          7450,
          8450,
          8250,
          10950,
          8950,
          8750,
          10450,
          10950,
          8450,
          9950,
          9950,
          8750,
          9950,
          9500,
          8250,
          10950,
          7950,
          8250,
          9895,
          9130,
          10950,
          10500,
          8900,
          9500,
          10950,
          7950,
          7950,
          7950,
          9500,
          10950,
          9750,
          9750,
          9450,
          8950,
          8950,
          8900,
          9950,
          8750,
          8950,
          8990,
          8950,
          8950,
          9950,
          9900,
          8950,
          8950,
          9500,
          7950,
          7750,
          8950,
          11950,
          8950,
          11950,
          8950,
          9950,
          8250,
          8995,
          9995,
          9250,
          10950,
          8900,
          9500,
          9950,
          7950,
          8250,
          9450,
          7950,
          9500,
          8950,
          10950,
          8950,
          9450,
          8000,
          9900,
          8950,
          10900,
          9450,
          8450,
          9500,
          10500,
          6950,
          9750,
          6950,
          9650,
          9950,
          9250,
          8950,
          9900,
          10995,
          10500,
          8950,
          9750,
          10950,
          9750,
          9950,
          10500,
          10400,
          8800,
          10500,
          9250,
          7800,
          9950,
          10750,
          10950,
          9950,
          9950,
          8100,
          9250,
          7800,
          9000,
          8950,
          8950,
          9950,
          8500,
          7995,
          8750,
          9750,
          10950,
          9750,
          8200,
          8950,
          9500,
          10950,
          9750,
          9950,
          10450,
          9850,
          9450,
          10295,
          9750,
          8950,
          9900,
          8750,
          9950,
          8500,
          9950,
          10950,
          9795,
          8750,
          8250,
          9950,
          9950,
          10500,
          9750,
          11250,
          8900,
          7950,
          11500,
          9450,
          7995,
          10995,
          8950,
          8250,
          8950,
          8950,
          9500,
          7500,
          8950,
          9950,
          9750,
          9450,
          9950,
          9750,
          8950,
          8250,
          7750,
          8950,
          9950,
          9450,
          12950,
          9950,
          10495,
          7950,
          10500,
          8950,
          9900,
          9995,
          9950,
          9950,
          8250,
          9950,
          8950,
          10950,
          9250,
          9950,
          9995,
          8750,
          10950,
          10350,
          9950,
          8950,
          10950,
          10950,
          8950,
          8900,
          10250,
          9450,
          9250,
          10500,
          7350,
          10250,
          10250,
          11500,
          8950,
          7750,
          9500,
          8450,
          8950,
          8400,
          9250,
          8900,
          8750,
          10950,
          8950,
          8950,
          8895,
          9390,
          8750,
          9750,
          9950,
          10950,
          9900,
          9500,
          9950,
          9950,
          10500,
          9950,
          10495,
          9500,
          8500,
          10450,
          8950,
          9900,
          8900,
          8745,
          8750,
          10750,
          9750,
          8850,
          7950,
          9450,
          9950,
          8250,
          9950,
          9995,
          9950,
          10495,
          7950,
          8950,
          9695,
          7750,
          9950,
          9950,
          9950,
          9900,
          10950,
          8950,
          8950,
          8250,
          10250,
          8750,
          9750,
          10950,
          10950,
          9750,
          8900,
          9500,
          9950,
          9950,
          8250,
          10450,
          10950,
          9250,
          8900,
          10900,
          9750,
          11950,
          7900,
          10900,
          10450,
          10950,
          9950,
          10750,
          9900,
          10750,
          10450,
          9450,
          10750,
          10950,
          10000,
          10500,
          12500,
          8950,
          10500,
          9245,
          10950,
          9500,
          10900,
          10950,
          9450,
          5900,
          6950,
          6000,
          5250,
          4400,
          6750,
          8500,
          6150,
          6950,
          5750,
          8750,
          6500,
          5950,
          6500,
          10500,
          8500,
          7950,
          5800,
          6750,
          6950,
          5740,
          6550,
          8950,
          6750,
          7950,
          7950,
          7450,
          7750,
          6450,
          7900,
          6900,
          5600,
          5950,
          6950,
          7950,
          8950,
          7950,
          9500,
          8600,
          5950,
          7750,
          7950,
          6950,
          7250,
          6500,
          7250,
          9250,
          8250,
          7250,
          5250,
          7900,
          6900,
          7900,
          7250,
          8450,
          7950,
          7950,
          6450,
          6650,
          7950,
          7250,
          7450,
          7950,
          7250,
          8250,
          8950,
          7750,
          8500,
          7750,
          5750,
          6900,
          6500,
          6500,
          7600,
          8950,
          7450,
          7350,
          7750,
          7460,
          9250,
          7250,
          6500,
          6800,
          8700,
          7500,
          7750,
          7950,
          9950,
          6640,
          8750,
          7750,
          5950,
          6750,
          6500,
          8750,
          7950,
          6750,
          7950,
          7950,
          8950,
          7750,
          6450,
          6900,
          8450,
          6750,
          8050,
          9500,
          7750,
          8500,
          7795,
          6490,
          7950,
          6425,
          8950,
          6950,
          8750,
          8450,
          7950,
          7950,
          8900,
          8950,
          8900,
          7950,
          6495,
          7250,
          9250,
          6650,
          6990,
          7750,
          6950,
          7250,
          9950,
          9250,
          7200,
          8250,
          8950,
          8250,
          6250,
          9900,
          7300,
          8950,
          6500,
          7950,
          7450,
          7950,
          8500,
          6950,
          7950,
          6750,
          8450,
          7500,
          8750,
          8750,
          8950,
          7450,
          9200,
          8950,
          7850,
          6950,
          7200,
          7450,
          6750,
          7500,
          7450,
          7950,
          7250,
          7950,
          8250,
          8250,
          6750,
          8750,
          8950,
          8500,
          8250,
          9450,
          7950,
          7900,
          8500,
          8250,
          8250,
          8950,
          7950,
          6950,
          7250,
          7750,
          8700,
          8950,
          6750,
          7500,
          7950,
          8950,
          7950,
          7450,
          5950,
          7750,
          6950,
          8750,
          8950,
          7495,
          7750,
          6950,
          7990,
          7250,
          6900,
          7750,
          7250,
          8950,
          8500,
          7950,
          6950,
          8000,
          7950,
          8500,
          7490,
          8250,
          9250,
          7950,
          9500,
          8950,
          8450,
          7995,
          8750,
          5950,
          8500,
          8950,
          8750,
          7600,
          7145,
          8450,
          5950,
          9000,
          7250,
          7400,
          8800,
          7750,
          7500,
          8450,
          7400,
          7500,
          8950,
          8950,
          7950,
          7950,
          7950,
          8950,
          7750,
          8250,
          7950,
          7750,
          8500,
          6950,
          7500,
          7750,
          5950,
          7500,
          8950,
          7950,
          6900,
          7450,
          8500,
          7500,
          8750,
          7500,
          9950,
          7950,
          9950,
          9250,
          9250,
          9950,
          5950,
          7995,
          8950,
          7450,
          8250,
          8500,
          8500,
          9400,
          7250,
          8950,
          9450,
          8500,
          6750,
          7400,
          8950,
          6900,
          7750,
          8950,
          6950,
          8495,
          10000,
          6999,
          8950,
          8500,
          8750,
          7499,
          9000,
          8950,
          6950,
          8500,
          8450,
          8950,
          8250,
          7950,
          7450,
          9000,
          7150,
          7750,
          5845,
          8500,
          8250,
          9450,
          6750,
          8400,
          7900,
          7950,
          8750,
          9900,
          6495,
          8250,
          6900,
          7500,
          7950,
          8250,
          8950,
          9750,
          8250,
          8900,
          8950,
          6750,
          7950,
          8600,
          7750,
          7800,
          8750,
          9500,
          7750,
          9950,
          7750,
          5950,
          10950,
          9450,
          8250,
          9750,
          7450,
          8750,
          8750,
          8500,
          8950,
          7500,
          7250,
          7450,
          8750,
          9800,
          7500,
          8950,
          8950,
          7450,
          8950,
          10500,
          7000,
          8500,
          7750,
          8950,
          8250,
          9250,
          7900,
          8500,
          7950,
          9950,
          8750,
          7500,
          6950,
          8950,
          8750,
          7750,
          8450,
          8150,
          8500,
          7600,
          7950,
          7750,
          7950,
          9950,
          8950,
          8450,
          8950,
          8450,
          7500,
          10845,
          8500,
          7250,
          6950
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>OLS trendline</b><br>Price = -170.934 * Age_08_04 + 20294.1<br>R<sup>2</sup>=0.768411<br><br>Age_08_04=%{x}<br>Price=%{y} <b>(trend)</b><extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          1,
          1,
          2,
          2,
          4,
          4,
          4,
          6,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          32,
          32,
          32,
          32,
          32,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          34,
          34,
          34,
          34,
          34,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          36,
          36,
          36,
          37,
          37,
          37,
          37,
          37,
          37,
          37,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          38,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          39,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          40,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          41,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          42,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          43,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          44,
          45,
          45,
          45,
          46,
          46,
          46,
          46,
          46,
          46,
          46,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          47,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          48,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          49,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          50,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          51,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          52,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          53,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          54,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          55,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          56,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          57,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          58,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          59,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          60,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          61,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          62,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          63,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          64,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          65,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          66,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          67,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          68,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          69,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          70,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          71,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          72,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          73,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          74,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          75,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          76,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          77,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          78,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          79,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80,
          80
         ],
         "xaxis": "x",
         "y": [
          20123.125063893487,
          20123.125063893487,
          19952.19147888194,
          19952.19147888194,
          19610.324308858846,
          19610.324308858846,
          19610.324308858846,
          19268.457138835754,
          19097.52355382421,
          19097.52355382421,
          19097.52355382421,
          19097.52355382421,
          19097.52355382421,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18926.589968812663,
          18755.656383801113,
          18755.656383801113,
          18755.656383801113,
          18584.722798789568,
          18413.78921377802,
          18413.78921377802,
          18413.78921377802,
          18413.78921377802,
          18413.78921377802,
          18413.78921377802,
          18242.855628766476,
          18242.855628766476,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          18071.92204375493,
          17900.988458743384,
          17900.988458743384,
          17900.988458743384,
          17900.988458743384,
          17900.988458743384,
          17900.988458743384,
          17900.988458743384,
          17730.054873731835,
          17730.054873731835,
          17559.12128872029,
          17559.12128872029,
          17559.12128872029,
          17559.12128872029,
          17559.12128872029,
          17559.12128872029,
          17559.12128872029,
          17388.187703708743,
          17388.187703708743,
          17388.187703708743,
          17388.187703708743,
          17388.187703708743,
          17388.187703708743,
          17388.187703708743,
          17217.254118697198,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          17046.32053368565,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16875.386948674102,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16533.51977865101,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16362.586193639465,
          16191.65260862792,
          16191.65260862792,
          16191.65260862792,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          16020.719023616373,
          15849.785438604826,
          15849.785438604826,
          15849.785438604826,
          15849.785438604826,
          15849.785438604826,
          15849.785438604826,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15678.851853593278,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15507.918268581732,
          15336.984683570186,
          15336.984683570186,
          15336.984683570186,
          15336.984683570186,
          15336.984683570186,
          15336.984683570186,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          15166.05109855864,
          14995.117513547095,
          14995.117513547095,
          14995.117513547095,
          14995.117513547095,
          14995.117513547095,
          14824.183928535547,
          14824.183928535547,
          14824.183928535547,
          14824.183928535547,
          14824.183928535547,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14653.250343524,
          14482.316758512454,
          14482.316758512454,
          14482.316758512454,
          14482.316758512454,
          14482.316758512454,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14311.383173500908,
          14140.449588489362,
          14140.449588489362,
          14140.449588489362,
          13969.516003477816,
          13969.516003477816,
          13969.516003477816,
          13969.516003477816,
          13969.516003477816,
          13969.516003477816,
          13969.516003477816,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13798.582418466269,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13627.648833454721,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13456.715248443175,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13285.78166343163,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          13114.848078420084,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12943.914493408536,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12772.98090839699,
          12602.047323385443,
          12602.047323385443,
          12602.047323385443,
          12431.113738373897,
          12431.113738373897,
          12431.113738373897,
          12431.113738373897,
          12431.113738373897,
          12431.113738373897,
          12431.113738373897,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12260.180153362351,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          12089.246568350805,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11918.312983339258,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11747.379398327712,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11576.445813316164,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11405.512228304618,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11234.578643293073,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          11063.645058281525,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10892.71147326998,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10721.777888258433,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10550.844303246886,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10379.91071823534,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10208.977133223794,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          10038.043548212247,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9867.1099632007,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9696.176378189155,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9525.242793177607,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9354.309208166062,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9183.375623154516,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          9012.442038142968,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8841.508453131422,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8670.574868119877,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8499.641283108329,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8328.707698096783,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          8157.774113085237,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7986.84052807369,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7815.906943062144,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7644.973358050598,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7474.0397730390505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7303.106188027505,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          7132.172603015959,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6961.239018004411,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6790.3054329928655,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318,
          6619.371847981318
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 500,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Age_08_04"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Price"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"0d73d773-4dc7-4cd3-afd1-2cd3377af8ef\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d73d773-4dc7-4cd3-afd1-2cd3377af8ef\")) {                    Plotly.newPlot(                        \"0d73d773-4dc7-4cd3-afd1-2cd3377af8ef\",                        [{\"hovertemplate\":\"Age_08_04=%{x}<br>Price=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"x\":[23,23,24,26,30,32,27,30,27,23,25,22,25,31,32,28,30,24,24,30,30,29,28,28,29,25,27,29,28,30,29,22,27,26,22,26,25,23,32,27,22,27,22,27,22,23,27,22,22,31,22,30,26,27,25,32,28,26,23,30,22,27,31,30,27,26,28,22,22,25,28,32,28,23,28,23,31,27,29,30,25,29,25,31,25,28,30,20,19,19,20,20,16,20,20,17,19,19,11,18,20,19,13,11,11,19,14,17,20,4,4,4,8,8,7,8,8,7,20,17,13,19,14,20,17,16,20,20,17,13,20,20,19,13,20,19,19,13,11,20,20,19,13,16,15,16,20,13,19,14,20,19,10,12,13,15,16,11,17,16,16,17,9,14,11,14,14,14,12,9,9,8,8,8,8,8,8,7,8,6,7,7,2,2,1,1,43,38,40,43,40,44,44,40,41,37,44,39,42,39,44,40,42,35,43,44,40,43,41,37,41,40,34,40,33,33,33,41,44,38,43,44,40,44,35,38,35,34,42,36,44,33,42,41,41,38,44,35,44,40,38,38,43,33,33,39,42,39,43,42,33,43,43,42,39,42,38,44,44,33,41,39,41,40,39,38,44,34,40,39,33,38,35,34,43,41,39,39,43,38,35,40,39,40,41,39,40,37,44,43,36,39,35,33,42,38,44,40,35,39,37,41,43,39,44,41,44,42,37,42,40,44,42,39,43,41,44,38,42,44,40,36,37,44,39,41,42,33,35,43,41,35,38,40,34,35,33,41,43,42,41,44,42,41,33,41,40,38,43,33,39,42,38,38,43,39,39,33,43,41,39,35,41,40,38,41,35,41,37,44,39,35,40,33,40,38,39,43,53,51,53,54,45,55,54,51,53,48,48,54,55,52,49,56,50,48,53,47,55,54,53,54,56,49,52,54,51,47,50,54,50,52,48,51,49,55,51,54,55,55,49,53,53,48,52,45,49,54,50,50,50,50,54,49,49,53,47,48,55,49,54,50,46,54,48,50,55,49,56,49,50,47,49,52,50,53,54,54,50,53,55,49,46,47,49,55,46,56,52,54,50,56,52,56,48,54,54,53,54,54,48,55,54,56,54,50,50,54,56,53,47,54,51,51,54,52,54,55,56,53,51,47,53,55,48,54,53,55,50,46,52,51,51,49,56,55,55,56,48,50,54,51,53,49,51,52,48,54,56,54,48,54,54,52,53,50,56,54,56,52,47,54,52,50,50,47,56,55,56,48,49,52,49,50,49,50,47,54,47,50,54,54,47,51,56,54,55,48,52,49,45,52,56,48,49,51,46,56,55,46,49,52,56,46,55,50,55,52,48,55,48,53,47,50,50,56,50,51,48,50,47,50,52,58,68,68,59,62,65,67,68,67,59,64,64,67,62,59,64,65,68,60,59,61,67,64,58,65,64,60,59,67,67,66,62,68,61,59,64,66,68,68,68,57,64,68,65,68,64,58,60,68,63,64,65,59,67,59,68,66,62,65,61,68,62,63,68,67,64,58,59,62,68,67,68,58,63,63,68,57,61,68,57,63,68,61,65,67,59,65,64,61,61,65,66,67,60,67,61,68,65,66,63,65,65,68,62,67,61,65,68,64,65,58,68,62,60,64,63,68,63,62,57,61,62,65,59,59,59,68,65,62,60,68,65,62,68,62,67,68,64,62,58,61,65,68,66,65,61,66,61,57,65,59,68,62,65,68,65,62,60,65,67,67,59,60,61,57,59,68,64,65,61,67,68,65,63,68,68,66,61,67,59,65,61,62,67,68,65,62,66,68,68,63,60,62,60,68,64,65,67,61,64,64,64,58,58,67,63,64,57,59,65,62,60,63,58,67,62,60,59,64,65,67,68,68,58,67,68,58,63,63,63,65,65,67,68,67,59,65,68,68,61,62,65,61,63,67,65,59,68,60,64,68,57,62,68,60,62,65,63,65,67,60,68,66,58,66,65,61,65,62,67,68,65,68,66,58,60,62,57,68,68,65,58,62,59,62,61,59,60,68,57,65,59,61,67,66,65,62,65,63,63,65,61,65,68,65,66,65,60,64,66,67,58,62,68,63,65,62,61,63,63,67,63,59,62,67,63,57,61,58,60,65,65,57,63,68,67,60,61,61,57,58,57,62,65,68,68,64,67,57,60,66,61,58,58,61,65,61,66,59,61,62,65,67,62,61,63,62,63,68,66,58,60,65,59,63,65,65,57,57,65,66,63,61,63,61,68,59,60,58,68,57,64,68,67,63,64,57,60,66,66,62,61,68,61,60,62,59,60,63,66,65,65,62,65,68,57,64,58,68,57,65,59,65,60,57,68,58,68,60,60,57,68,62,62,58,66,59,63,62,67,66,73,79,78,79,74,77,69,80,76,76,78,70,73,78,77,77,71,78,80,78,74,73,69,73,78,69,76,70,71,75,69,75,77,80,71,79,74,80,76,71,73,79,77,74,78,77,80,73,71,72,77,76,75,74,70,76,74,72,75,74,80,77,74,77,71,76,74,71,78,73,76,71,78,77,73,74,72,73,80,76,80,72,80,75,78,71,73,75,74,71,72,72,77,80,76,74,74,73,80,75,77,75,74,75,74,74,79,78,80,75,80,73,79,69,72,79,71,77,80,78,73,73,69,74,78,74,78,79,78,79,80,80,80,79,72,79,77,80,80,80,72,70,78,75,71,78,77,78,77,70,78,74,79,76,75,69,74,72,73,75,78,75,73,72,70,78,73,80,72,80,79,80,70,80,70,73,70,73,79,76,73,74,80,78,77,75,80,76,71,69,71,71,78,78,75,77,80,71,79,76,70,77,78,69,74,78,77,71,72,77,78,75,76,73,80,71,72,77,72,78,79,78,71,73,69,69,78,80,69,75,80,80,75,79,71,75,78,75,80,76,70,77,79,78,71,78,78,78,77,77,80,80,79,79,78,72,76,80,77,80,73,77,76,80,75,75,78,73,79,74,76,70,75,76,78,70,69,80,79,80,74,80,80,78,80,79,71,75,77,75,71,80,79,75,80,80,77,80,77,77,74,77,75,70,79,70,76,70,72,80,79,69,77,76,76,80,73,71,70,69,74,75,80,80,70,80,78,75,76,75,69,80,73,73,79,74,79,77,69,76,77,80,69,78,75,69,73,70,79,69,80,76,77,71,75,74,70,71,78,73,77,76,70,69,80,75,78,76,69,74,80,72,79,79,73,75,76,78,78,80,73,80,78,71,72,78,80,69,72,71,70,76],\"xaxis\":\"x\",\"y\":[13500,13750,13950,14950,13750,12950,16900,18600,21500,12950,20950,19950,19600,21500,22500,22000,22750,17950,16750,16950,15950,16950,15950,16950,16250,15950,17495,15750,16950,17950,12950,15750,15950,14950,15500,15750,15950,14950,15750,14750,13950,16750,13950,16950,16950,19000,17950,15800,17950,21950,17950,15750,20500,21950,15500,13250,15250,15250,18950,15999,14950,16500,18750,17950,17950,16950,18950,14950,22250,15950,15950,12995,18950,15750,19950,16950,18750,18450,16895,14900,18950,17250,15450,17950,16650,17450,14900,17950,15950,21950,16450,22250,19950,15950,18900,19950,15950,15950,18750,17450,18990,16250,18500,18500,19450,16950,18800,17450,17950,32500,31000,31275,24950,24950,22950,24990,21950,17900,19250,22250,18950,19950,16350,18950,16950,21750,15950,16500,17950,15850,16250,15950,16250,15950,16500,16500,18450,16250,23000,19900,16450,23950,19950,18500,18950,16450,20500,24500,19450,20950,17200,19950,18450,19500,21750,16868,19500,18900,19750,19750,18950,20750,19600,19500,17650,19950,19950,20950,20500,17795,18245,23750,19500,18950,21950,19950,18950,19950,21950,22500,18500,18700,21125,21500,17795,18245,6950,9500,11950,7750,11950,4350,4750,11750,13250,11950,11900,14750,9950,11950,11495,11250,10500,10450,12950,11500,12500,10950,11450,11950,13250,14750,11790,11450,13500,10950,13500,10950,10950,12950,11950,12450,11950,14950,12450,12950,11950,11690,12450,12750,11925,12950,11950,12900,11900,11650,10950,13950,13950,11950,10950,12450,11950,13500,11690,13500,11950,12900,13500,11750,11750,10850,11750,14950,9940,12900,13500,11750,11950,13450,11950,12495,13500,12750,12000,11950,12495,12450,14750,10950,13500,12950,13500,13450,13500,11480,13450,11495,12750,14990,12950,12950,12850,13950,11950,12950,11700,9950,11895,12950,12500,13875,10500,12295,13950,10950,12950,12850,13995,13750,12750,12500,13950,11500,13950,11895,9950,13500,11450,12450,12950,13995,11750,11650,9950,13950,12950,10950,9900,11950,11990,10750,13950,11250,12950,11950,10950,12950,12950,11695,11000,13950,11950,11750,12400,12500,12900,12200,12750,11950,11900,11950,14950,11950,12950,14950,13450,13750,12950,12750,11895,9950,12450,12500,14950,13750,12695,14990,12750,14350,12950,11500,11950,13450,12900,10500,10950,11950,11450,13250,10250,13995,11950,13250,12950,11750,11500,13500,6500,6400,7000,7750,8900,8500,8950,9900,10250,9250,7750,9450,7750,8250,9950,4450,9950,9000,9950,12450,10500,10750,8950,10500,5150,10950,9450,9950,10950,11900,9950,11950,7900,10950,8950,11950,10900,9950,9950,10950,8950,8950,10500,8950,9250,11500,9750,9950,11450,12500,10500,12950,12200,10950,10950,11290,10750,10895,11500,9750,10250,12500,11950,10750,11450,11950,11750,10950,11950,10995,11450,8900,10500,11750,11450,12000,11950,9850,10950,10950,8695,10990,9500,11950,10750,8750,8750,11450,9950,11950,13950,11250,10900,9750,9950,11950,10450,8950,10250,9930,10500,11950,11500,11500,11450,9900,9500,10500,10750,8950,12000,9940,10950,10750,9799,11750,11950,11250,11750,10950,11250,9950,9700,11950,9900,9990,9475,11500,11950,11500,10500,10900,11700,11900,13950,10950,10500,10750,11950,10000,10495,11450,9400,11950,9650,18950,11450,10250,11450,9950,10500,13750,9950,10250,10850,11895,12950,11950,10750,9550,10950,11750,10950,12450,10500,10900,12950,10950,12500,9950,10750,12500,10450,10750,12950,10995,11950,11250,11950,13750,11000,13500,10950,10750,8950,12950,9750,10900,10995,10750,10950,13000,12950,11500,10950,11710,9980,12250,11500,11950,11500,11900,11930,10500,8950,10450,10500,12950,9950,12900,9950,9950,10950,10950,9950,10950,10800,10500,10450,10600,10450,12950,11250,7500,8950,6950,7900,5950,7500,7500,6900,5751,6950,7950,7750,7950,8250,6250,9500,6900,8450,7350,8950,6900,8950,8750,7950,8950,8950,8950,7950,7750,7500,8950,9800,9450,8950,8750,10500,7995,10450,9950,9950,8950,7950,10950,9950,8600,7250,6950,8000,9950,9450,7950,9450,9950,6950,8250,9950,8250,9950,10500,7950,9750,9250,9500,9950,7750,9500,9950,9750,9750,5950,8500,8495,9250,6900,8950,9500,9250,9895,9950,7950,8750,8250,8950,8950,8950,8950,9450,8950,9250,8750,9950,9950,9900,8950,8950,12250,9250,10250,8950,7999,9900,8250,10500,8450,9900,10500,8500,9500,9450,9900,8250,8750,9500,8450,8490,8750,9750,9950,8500,8450,7900,8750,7950,6900,8150,10995,8900,9500,8950,11500,10450,10500,9250,10950,10450,9250,8750,8750,9800,8250,10450,9750,8950,7450,8450,8250,10950,8950,8750,10450,10950,8450,9950,9950,8750,9950,9500,8250,10950,7950,8250,9895,9130,10950,10500,8900,9500,10950,7950,7950,7950,9500,10950,9750,9750,9450,8950,8950,8900,9950,8750,8950,8990,8950,8950,9950,9900,8950,8950,9500,7950,7750,8950,11950,8950,11950,8950,9950,8250,8995,9995,9250,10950,8900,9500,9950,7950,8250,9450,7950,9500,8950,10950,8950,9450,8000,9900,8950,10900,9450,8450,9500,10500,6950,9750,6950,9650,9950,9250,8950,9900,10995,10500,8950,9750,10950,9750,9950,10500,10400,8800,10500,9250,7800,9950,10750,10950,9950,9950,8100,9250,7800,9000,8950,8950,9950,8500,7995,8750,9750,10950,9750,8200,8950,9500,10950,9750,9950,10450,9850,9450,10295,9750,8950,9900,8750,9950,8500,9950,10950,9795,8750,8250,9950,9950,10500,9750,11250,8900,7950,11500,9450,7995,10995,8950,8250,8950,8950,9500,7500,8950,9950,9750,9450,9950,9750,8950,8250,7750,8950,9950,9450,12950,9950,10495,7950,10500,8950,9900,9995,9950,9950,8250,9950,8950,10950,9250,9950,9995,8750,10950,10350,9950,8950,10950,10950,8950,8900,10250,9450,9250,10500,7350,10250,10250,11500,8950,7750,9500,8450,8950,8400,9250,8900,8750,10950,8950,8950,8895,9390,8750,9750,9950,10950,9900,9500,9950,9950,10500,9950,10495,9500,8500,10450,8950,9900,8900,8745,8750,10750,9750,8850,7950,9450,9950,8250,9950,9995,9950,10495,7950,8950,9695,7750,9950,9950,9950,9900,10950,8950,8950,8250,10250,8750,9750,10950,10950,9750,8900,9500,9950,9950,8250,10450,10950,9250,8900,10900,9750,11950,7900,10900,10450,10950,9950,10750,9900,10750,10450,9450,10750,10950,10000,10500,12500,8950,10500,9245,10950,9500,10900,10950,9450,5900,6950,6000,5250,4400,6750,8500,6150,6950,5750,8750,6500,5950,6500,10500,8500,7950,5800,6750,6950,5740,6550,8950,6750,7950,7950,7450,7750,6450,7900,6900,5600,5950,6950,7950,8950,7950,9500,8600,5950,7750,7950,6950,7250,6500,7250,9250,8250,7250,5250,7900,6900,7900,7250,8450,7950,7950,6450,6650,7950,7250,7450,7950,7250,8250,8950,7750,8500,7750,5750,6900,6500,6500,7600,8950,7450,7350,7750,7460,9250,7250,6500,6800,8700,7500,7750,7950,9950,6640,8750,7750,5950,6750,6500,8750,7950,6750,7950,7950,8950,7750,6450,6900,8450,6750,8050,9500,7750,8500,7795,6490,7950,6425,8950,6950,8750,8450,7950,7950,8900,8950,8900,7950,6495,7250,9250,6650,6990,7750,6950,7250,9950,9250,7200,8250,8950,8250,6250,9900,7300,8950,6500,7950,7450,7950,8500,6950,7950,6750,8450,7500,8750,8750,8950,7450,9200,8950,7850,6950,7200,7450,6750,7500,7450,7950,7250,7950,8250,8250,6750,8750,8950,8500,8250,9450,7950,7900,8500,8250,8250,8950,7950,6950,7250,7750,8700,8950,6750,7500,7950,8950,7950,7450,5950,7750,6950,8750,8950,7495,7750,6950,7990,7250,6900,7750,7250,8950,8500,7950,6950,8000,7950,8500,7490,8250,9250,7950,9500,8950,8450,7995,8750,5950,8500,8950,8750,7600,7145,8450,5950,9000,7250,7400,8800,7750,7500,8450,7400,7500,8950,8950,7950,7950,7950,8950,7750,8250,7950,7750,8500,6950,7500,7750,5950,7500,8950,7950,6900,7450,8500,7500,8750,7500,9950,7950,9950,9250,9250,9950,5950,7995,8950,7450,8250,8500,8500,9400,7250,8950,9450,8500,6750,7400,8950,6900,7750,8950,6950,8495,10000,6999,8950,8500,8750,7499,9000,8950,6950,8500,8450,8950,8250,7950,7450,9000,7150,7750,5845,8500,8250,9450,6750,8400,7900,7950,8750,9900,6495,8250,6900,7500,7950,8250,8950,9750,8250,8900,8950,6750,7950,8600,7750,7800,8750,9500,7750,9950,7750,5950,10950,9450,8250,9750,7450,8750,8750,8500,8950,7500,7250,7450,8750,9800,7500,8950,8950,7450,8950,10500,7000,8500,7750,8950,8250,9250,7900,8500,7950,9950,8750,7500,6950,8950,8750,7750,8450,8150,8500,7600,7950,7750,7950,9950,8950,8450,8950,8450,7500,10845,8500,7250,6950],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"<b>OLS trendline</b><br>Price = -170.934 * Age_08_04 + 20294.1<br>R<sup>2</sup>=0.768411<br><br>Age_08_04=%{x}<br>Price=%{y} <b>(trend)</b><extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[1,1,2,2,4,4,4,6,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,9,9,9,10,11,11,11,11,11,11,12,12,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,15,15,16,16,16,16,16,16,16,17,17,17,17,17,17,17,18,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80],\"xaxis\":\"x\",\"y\":[20123.125063893487,20123.125063893487,19952.19147888194,19952.19147888194,19610.324308858846,19610.324308858846,19610.324308858846,19268.457138835754,19097.52355382421,19097.52355382421,19097.52355382421,19097.52355382421,19097.52355382421,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18926.589968812663,18755.656383801113,18755.656383801113,18755.656383801113,18584.722798789568,18413.78921377802,18413.78921377802,18413.78921377802,18413.78921377802,18413.78921377802,18413.78921377802,18242.855628766476,18242.855628766476,18071.92204375493,18071.92204375493,18071.92204375493,18071.92204375493,18071.92204375493,18071.92204375493,18071.92204375493,18071.92204375493,17900.988458743384,17900.988458743384,17900.988458743384,17900.988458743384,17900.988458743384,17900.988458743384,17900.988458743384,17730.054873731835,17730.054873731835,17559.12128872029,17559.12128872029,17559.12128872029,17559.12128872029,17559.12128872029,17559.12128872029,17559.12128872029,17388.187703708743,17388.187703708743,17388.187703708743,17388.187703708743,17388.187703708743,17388.187703708743,17388.187703708743,17217.254118697198,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,17046.32053368565,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16875.386948674102,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16533.51977865101,16362.586193639465,16362.586193639465,16362.586193639465,16362.586193639465,16362.586193639465,16362.586193639465,16362.586193639465,16362.586193639465,16191.65260862792,16191.65260862792,16191.65260862792,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,16020.719023616373,15849.785438604826,15849.785438604826,15849.785438604826,15849.785438604826,15849.785438604826,15849.785438604826,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15678.851853593278,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15507.918268581732,15336.984683570186,15336.984683570186,15336.984683570186,15336.984683570186,15336.984683570186,15336.984683570186,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,15166.05109855864,14995.117513547095,14995.117513547095,14995.117513547095,14995.117513547095,14995.117513547095,14824.183928535547,14824.183928535547,14824.183928535547,14824.183928535547,14824.183928535547,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14653.250343524,14482.316758512454,14482.316758512454,14482.316758512454,14482.316758512454,14482.316758512454,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14311.383173500908,14140.449588489362,14140.449588489362,14140.449588489362,13969.516003477816,13969.516003477816,13969.516003477816,13969.516003477816,13969.516003477816,13969.516003477816,13969.516003477816,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13798.582418466269,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13627.648833454721,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13456.715248443175,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13285.78166343163,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,13114.848078420084,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12943.914493408536,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12772.98090839699,12602.047323385443,12602.047323385443,12602.047323385443,12431.113738373897,12431.113738373897,12431.113738373897,12431.113738373897,12431.113738373897,12431.113738373897,12431.113738373897,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12260.180153362351,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,12089.246568350805,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11918.312983339258,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11747.379398327712,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11576.445813316164,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11405.512228304618,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11234.578643293073,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,11063.645058281525,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10892.71147326998,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10721.777888258433,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10550.844303246886,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10379.91071823534,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10208.977133223794,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,10038.043548212247,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9867.1099632007,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9696.176378189155,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9525.242793177607,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9354.309208166062,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9183.375623154516,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,9012.442038142968,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8841.508453131422,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8670.574868119877,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8499.641283108329,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8328.707698096783,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,8157.774113085237,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7986.84052807369,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7815.906943062144,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7644.973358050598,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7474.0397730390505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7303.106188027505,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,7132.172603015959,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6961.239018004411,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6790.3054329928655,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318,6619.371847981318],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Age_08_04\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Price\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d73d773-4dc7-4cd3-afd1-2cd3377af8ef');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(TDF, \n",
    "                 x=\"Age_08_04\", \n",
    "                 y=\"Price\", \n",
    "                 height=500,\n",
    "                 trendline='ols',\n",
    "                 template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# showing negatively correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "adeba680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# TDF_norm = pd.DataFrame(scaler.fit_transform(TDF), columns=TDF.columns)\n",
    "# TDF_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c0873966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3a = TDF[['Age_08_04']].values\n",
    "y3a = TDF['Price'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "91f19f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3a, y3a, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d9a6fc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model3a=LinearRegression()\n",
    "linear_model3a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "39dda530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 1788.5342\n",
      "            Mean Absolute Error (MAE) : 1248.2930\n",
      "          Mean Percentage Error (MPE) : -2.0062\n",
      "Mean Absolute Percentage Error (MAPE) : 12.1768\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -178.4958\n",
      "       Root Mean Squared Error (RMSE) : 1641.5998\n",
      "            Mean Absolute Error (MAE) : 1257.1250\n",
      "          Mean Percentage Error (MPE) : -3.4237\n",
      "Mean Absolute Percentage Error (MAPE) : 12.2215\n"
     ]
    }
   ],
   "source": [
    "from dmba import regressionSummary\n",
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model3a.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model3a.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a6f6967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.7546807884728556\n",
      "R2 for testing dataset 0.7976711887725145\n"
     ]
    }
   ],
   "source": [
    "#R-squared values for train & test data set.\n",
    "\n",
    "y_pred_train = linear_model3a.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model3a.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "251e9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3aa = TDF['Age_08_04']\n",
    "y3aa = TDF['Price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "365e78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3aa, y3aa, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4944737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "99ede41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3516.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:57:54</td>     <th>  Log-Likelihood:    </th> <td> -9601.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1077</td>      <th>  AIC:               </th> <td>1.921e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1075</td>      <th>  BIC:               </th> <td>1.922e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td> 2.055e+04</td> <td>  174.599</td> <td>  117.722</td> <td> 0.000</td> <td> 2.02e+04</td> <td> 2.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age_08_04</th> <td> -174.4404</td> <td>    2.942</td> <td>  -59.296</td> <td> 0.000</td> <td> -180.213</td> <td> -168.668</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>293.592</td> <th>  Durbin-Watson:     </th> <td>   2.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2269.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.033</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.805</td>  <th>  Cond. No.          </th> <td>    189.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.766\n",
       "Model:                            OLS   Adj. R-squared:                  0.766\n",
       "Method:                 Least Squares   F-statistic:                     3516.\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        12:57:54   Log-Likelihood:                -9601.5\n",
       "No. Observations:                1077   AIC:                         1.921e+04\n",
       "Df Residuals:                    1075   BIC:                         1.922e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.055e+04    174.599    117.722      0.000    2.02e+04    2.09e+04\n",
       "Age_08_04   -174.4404      2.942    -59.296      0.000    -180.213    -168.668\n",
       "==============================================================================\n",
       "Omnibus:                      293.592   Durbin-Watson:                   2.026\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2269.570\n",
       "Skew:                           1.033   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.805   Cond. No.                         189.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for checking the p-values checking OLS summary\n",
    "linear_model3aa=sm.OLS(y_train,X_train).fit()\n",
    "linear_model3aa.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "94a170a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 20400.557220502684\n",
      "coefficient [-171.87956797]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', linear_model3a.intercept_) # Printing the interecept for linear regression)\n",
    "print('coefficient', linear_model3a.coef_ ) # Printing the coefficient for linear regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1fd6fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 1 => Price = 20400.557220502684 + [-171.87956797] * Age_08_04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Model Form 1 =>','Price =', linear_model3a.intercept_, '+', linear_model3a.coef_, '* Age_08_04')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92b87c",
   "metadata": {},
   "source": [
    "# Does your model under or overfit the data?  How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b53a58",
   "metadata": {},
   "source": [
    "Comparing the MAPE values for testing and training I can see that the model is working fine, i don't thinks it is overfiitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ee4d9",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "# Create a slightly more complicated predictive model of the target variable.  In particular, add 1-3 more variables that you think have potential to improve your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7f3847ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3b = TDF.drop(columns=['Price'])\n",
    "y3b = TDF['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bca4550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3b, y3b, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e3c47ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    3.2s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 1/5 -- score: 0.7691140193704991[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  47 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 2/5 -- score: 0.8232402914150987[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  46 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 3/5 -- score: 0.8454672054703453[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 4/5 -- score: 0.8626664612909245[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  44 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 5/5 -- score: 0.880655289736217"
     ]
    }
   ],
   "source": [
    "Forward_Selection = SFS(linear_model3a,\n",
    "                        k_features=(1,5),\n",
    "                        forward=True,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring=\"r2\",\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "05f0e596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:33] Features: 47/1 -- score: 0.9028779838983935[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  47 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:34] Features: 46/1 -- score: 0.9036448109641363[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  46 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:34] Features: 45/1 -- score: 0.9041446362626873[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:34] Features: 44/1 -- score: 0.9045838836586274[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  44 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:34] Features: 43/1 -- score: 0.9049975165697267[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  43 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:34] Features: 42/1 -- score: 0.9053058722955288[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  42 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 41/1 -- score: 0.9054839048614068[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  41 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 40/1 -- score: 0.9056465139072516[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 39/1 -- score: 0.9057993529561845[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  39 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 38/1 -- score: 0.9059293145796227[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 37/1 -- score: 0.9060021324113198[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  37 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 36/1 -- score: 0.9060707565370179[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:35] Features: 35/1 -- score: 0.9061401016291792[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  35 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 34/1 -- score: 0.9061555869369752[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 33/1 -- score: 0.9061559122945992[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  33 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 32/1 -- score: 0.9063351005175051[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 31/1 -- score: 0.906492041887409[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 30/1 -- score: 0.9065229165503285[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 29/1 -- score: 0.906534596142045[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 28/1 -- score: 0.9065386621407951[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 27/1 -- score: 0.9065386621408159[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 26/1 -- score: 0.9065386621407997[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:36] Features: 25/1 -- score: 0.9068796431727015[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 24/1 -- score: 0.9068796431727042[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 23/1 -- score: 0.9068339890849961[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 22/1 -- score: 0.9067592342016286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  22 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 21/1 -- score: 0.9064471449049576[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  21 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 20/1 -- score: 0.9060746833751449[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 19/1 -- score: 0.9056311605492604[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  19 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 18/1 -- score: 0.9053347750126836[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 17/1 -- score: 0.9050387569633658[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 16/1 -- score: 0.9046805348521282[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 15/1 -- score: 0.9042006750268994[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 14/1 -- score: 0.903459707516784[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 13/1 -- score: 0.9027490487572148[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 12/1 -- score: 0.9020735392132776[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 11/1 -- score: 0.9004312475348322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 10/1 -- score: 0.8976694989827841[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 9/1 -- score: 0.8949337260349457[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:37] Features: 8/1 -- score: 0.8903949609420916[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 7/1 -- score: 0.8862990762515643[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 6/1 -- score: 0.8826614634555601[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 5/1 -- score: 0.8822416904509801[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 4/1 -- score: 0.8733750734245438[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 3/1 -- score: 0.8491531245204061[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 2/1 -- score: 0.810446128161683[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:38] Features: 1/1 -- score: 0.7691140193704991"
     ]
    }
   ],
   "source": [
    "Backward_Selection = SFS(linear_model3a,\n",
    "                        k_features=(1,6),\n",
    "                        forward=False,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring='r2',\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "064372dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for backward selected features 0.8826614634555601\n",
      "\n",
      "Backard selected features ('Mfg_Year', 'KM', 'HP', 'CC', 'Weight', 'Automatic_airco')\n",
      "\n",
      "Score for forward selected features 0.880655289736217\n",
      "\n",
      "Forward selected features ('Id', 'Mfg_Year', 'HP', 'Weight', 'Automatic_airco')\n"
     ]
    }
   ],
   "source": [
    "print('Score for backward selected features',Backward_Selection.k_score_)\n",
    "print()\n",
    "print('Backard selected features',Backward_Selection.k_feature_names_)\n",
    "print()\n",
    "print('Score for forward selected features',Forward_Selection.k_score_)\n",
    "print()\n",
    "print('Forward selected features',Forward_Selection.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d8fd0e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Price', 'Age_08_04', 'Mfg_Month', 'Mfg_Year', 'KM', 'HP',\n",
       "       'Met_Color', 'Automatic', 'CC', 'Doors', 'Cylinders', 'Gears',\n",
       "       'Quarterly_Tax', 'Weight', 'Mfr_Guarantee', 'BOVAG_Guarantee',\n",
       "       'Guarantee_Period', 'ABS', 'Airbag_1', 'Airbag_2', 'Airco',\n",
       "       'Automatic_airco', 'Boardcomputer', 'CD_Player', 'Central_Lock',\n",
       "       'Powered_Windows', 'Power_Steering', 'Radio', 'Mistlamps',\n",
       "       'Sport_Model', 'Backseat_Divider', 'Metallic_Rim', 'Radio_cassette',\n",
       "       'Parking_Assistant', 'Tow_Bar', 'Fuel_Type_CNG', 'Fuel_Type_Diesel',\n",
       "       'Fuel_Type_Petrol', 'Color_Beige', 'Color_Black', 'Color_Blue',\n",
       "       'Color_Green', 'Color_Grey', 'Color_Red', 'Color_Silver',\n",
       "       'Color_Violet', 'Color_White', 'Color_Yellow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "22f467a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing columns with Yes-No\n",
    "TDF = pd.read_csv(r'C:\\Users\\anagbhid\\Documents\\CourseWork_Q1\\CIS508_Coursework\\HandsOn3CIS_508\\ToyotaCorolla.csv')\n",
    "TDF = TDF.drop(columns=['Model'])\n",
    "TDF = pd.get_dummies(TDF, columns = ['Fuel_Type', 'Color'])\n",
    "TDF = TDF.drop(columns=['Id', 'Mfg_Month', 'Mfg_Year','Quarterly_Tax','Automatic_airco', 'Automatic_airco','ABS', 'Airbag_1', 'Airbag_2','Boardcomputer', 'CD_Player', 'Central_Lock',\n",
    "       'Powered_Windows', 'Power_Steering', 'Radio', 'Mistlamps',\n",
    "       'Sport_Model', 'Backseat_Divider', 'Metallic_Rim', 'Radio_cassette',\n",
    "       'Parking_Assistant', 'Tow_Bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aa18c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3b = TDF.drop(columns=['Price'])\n",
    "y3b = TDF['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8bf543d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3b, y3b, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7217da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:51] Features: 1/5 -- score: 0.7524693730736042[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:51] Features: 2/5 -- score: 0.7953942981084413[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:51] Features: 3/5 -- score: 0.8378650735737473[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:51] Features: 4/5 -- score: 0.8557341396779197[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:51] Features: 5/5 -- score: 0.8588123494805006"
     ]
    }
   ],
   "source": [
    "Forward_Selection = SFS(linear_model3a,\n",
    "                        k_features=(1,5),\n",
    "                        forward=True,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring=\"r2\",\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "56539f18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 26/1 -- score: 0.8700931864131791[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 25/1 -- score: 0.8706369279636853[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  25 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 24/1 -- score: 0.8709496098316942[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 23/1 -- score: 0.8709496098316942[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  23 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 22/1 -- score: 0.8710453725205973[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  22 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:53] Features: 21/1 -- score: 0.8712031602227801[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  21 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 20/1 -- score: 0.8714371058285169[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 19/1 -- score: 0.8714890332264555[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  19 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 18/1 -- score: 0.8714890332264555[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 17/1 -- score: 0.8714890332264554[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 16/1 -- score: 0.8713015269306263[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 15/1 -- score: 0.8710214645130939[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 14/1 -- score: 0.8705120334402509[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 13/1 -- score: 0.8699960721385647[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 12/1 -- score: 0.8697224244147744[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 11/1 -- score: 0.8688746012164422[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 10/1 -- score: 0.8678321591383439[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 9/1 -- score: 0.8656882126395935[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 8/1 -- score: 0.8644170124486068[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 7/1 -- score: 0.8629759985122597[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 6/1 -- score: 0.860756625097977[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 5/1 -- score: 0.8588123494805006[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 4/1 -- score: 0.8557341396779197[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 3/1 -- score: 0.8378650735737473[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 2/1 -- score: 0.7953942981084413[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-11-03 12:59:54] Features: 1/1 -- score: 0.7524693730736042"
     ]
    }
   ],
   "source": [
    "Backward_Selection = SFS(linear_model3a,\n",
    "                        k_features=(1,6),\n",
    "                        forward=False,\n",
    "                        floating=False,\n",
    "                        verbose=2,\n",
    "                        scoring='r2',\n",
    "                        n_jobs=-1,\n",
    "                       cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score for backward selected features',Backward_Selection.k_score_)\n",
    "print()\n",
    "print('Backard selected features',Backward_Selection.k_feature_names_)\n",
    "print()\n",
    "print('Score for forward selected features',Forward_Selection.k_score_)\n",
    "print()\n",
    "print('Forward selected features',Forward_Selection.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef302df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "# Exhaustive_Selection = EFS(linear_model3a,\n",
    "#                            min_features= 3,\n",
    "#                            max_features= 5,\n",
    "#                            scoring='r2',\n",
    "#                            n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive_Selection.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "30fe5be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CRIM', 'CHAS', 'DIS', 'LSTAT', 'CAT. MEDV')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exhaustive_Selection.best_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "76f5b073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>[0.7349323689326035, 0.761324938607378, 0.7043...</td>\n",
       "      <td>0.752469</td>\n",
       "      <td>(Age_08_04,)</td>\n",
       "      <td>0.038216</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.014867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 9)</td>\n",
       "      <td>[0.7956436929415582, 0.787270788055537, 0.7456...</td>\n",
       "      <td>0.795394</td>\n",
       "      <td>(Age_08_04, Weight)</td>\n",
       "      <td>0.037301</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.014511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1, 9)</td>\n",
       "      <td>[0.8552431427246281, 0.821287671646128, 0.7986...</td>\n",
       "      <td>0.837865</td>\n",
       "      <td>(Age_08_04, KM, Weight)</td>\n",
       "      <td>0.031648</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>0.012312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 2, 9)</td>\n",
       "      <td>[0.8591903620338608, 0.8306046098225779, 0.840...</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>(Age_08_04, KM, HP, Weight)</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.009149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 1, 2, 5, 9)</td>\n",
       "      <td>[0.8685218034303288, 0.8098226298380534, 0.849...</td>\n",
       "      <td>0.858812</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight)</td>\n",
       "      <td>0.035465</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>0.013797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_idx                                          cv_scores  \\\n",
       "1             (0,)  [0.7349323689326035, 0.761324938607378, 0.7043...   \n",
       "2           (0, 9)  [0.7956436929415582, 0.787270788055537, 0.7456...   \n",
       "3        (0, 1, 9)  [0.8552431427246281, 0.821287671646128, 0.7986...   \n",
       "4     (0, 1, 2, 9)  [0.8591903620338608, 0.8306046098225779, 0.840...   \n",
       "5  (0, 1, 2, 5, 9)  [0.8685218034303288, 0.8098226298380534, 0.849...   \n",
       "\n",
       "  avg_score                    feature_names  ci_bound   std_dev   std_err  \n",
       "1  0.752469                     (Age_08_04,)  0.038216  0.029734  0.014867  \n",
       "2  0.795394              (Age_08_04, Weight)  0.037301  0.029022  0.014511  \n",
       "3  0.837865          (Age_08_04, KM, Weight)  0.031648  0.024623  0.012312  \n",
       "4  0.855734      (Age_08_04, KM, HP, Weight)  0.023517  0.018297  0.009149  \n",
       "5  0.858812  (Age_08_04, KM, HP, CC, Weight)  0.035465  0.027593  0.013797  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(Forward_Selection.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "90e27226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.8863244170752315, 0.827205071966563, 0.8733...</td>\n",
       "      <td>0.868367</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, Automatic, CC, ...</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>0.010613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[0.8844535636409472, 0.8395809178729241, 0.872...</td>\n",
       "      <td>0.870093</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, Automatic, CC, ...</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>0.007927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[0.8854663010005633, 0.8407705055712051, 0.872...</td>\n",
       "      <td>0.870637</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.020021</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8868613940392011, 0.8414614409460225, 0.872...</td>\n",
       "      <td>0.87095</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8868613940392011, 0.8414614409460224, 0.872...</td>\n",
       "      <td>0.87095</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8873092387575998, 0.8414739656024214, 0.872...</td>\n",
       "      <td>0.871045</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.02009</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.007815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8870230958096587, 0.842110169737685, 0.8725...</td>\n",
       "      <td>0.871203</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.015349</td>\n",
       "      <td>0.007674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8868814591467499, 0.8422885101750054, 0.872...</td>\n",
       "      <td>0.871437</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019689</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.007659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.8868897681822827, 0.8422730867222792, 0.872...</td>\n",
       "      <td>0.871489</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 16, ...</td>\n",
       "      <td>[0.8868897681822828, 0.8422730867222792, 0.872...</td>\n",
       "      <td>0.871489</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(0, 1, 2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 18,...</td>\n",
       "      <td>[0.8868897681822828, 0.8422730867222792, 0.872...</td>\n",
       "      <td>0.871489</td>\n",
       "      <td>(Age_08_04, KM, HP, Met_Color, CC, Weight, Mfr...</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...</td>\n",
       "      <td>[0.886937132806211, 0.8417821568561511, 0.8718...</td>\n",
       "      <td>0.871302</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.019985</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>0.007774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...</td>\n",
       "      <td>[0.8871785041347496, 0.8405364753290783, 0.871...</td>\n",
       "      <td>0.871021</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>0.00804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...</td>\n",
       "      <td>[0.8874442225315381, 0.8395216213237058, 0.871...</td>\n",
       "      <td>0.870512</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.008177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19)</td>\n",
       "      <td>[0.8855293842188675, 0.8376251689853649, 0.872...</td>\n",
       "      <td>0.869996</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.008371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18)</td>\n",
       "      <td>[0.8849922882828418, 0.8369635400356246, 0.873...</td>\n",
       "      <td>0.869722</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.008425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16)</td>\n",
       "      <td>[0.8833822096838134, 0.8356489539445545, 0.869...</td>\n",
       "      <td>0.868875</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.008596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0, 1, 2, 5, 9, 11, 12, 13, 14, 16)</td>\n",
       "      <td>[0.8818206831050115, 0.833604845082666, 0.8685...</td>\n",
       "      <td>0.867832</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...</td>\n",
       "      <td>0.02274</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.008846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0, 1, 2, 5, 9, 11, 12, 13, 14)</td>\n",
       "      <td>[0.8773516006399763, 0.8231064203982692, 0.862...</td>\n",
       "      <td>0.865688</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...</td>\n",
       "      <td>0.029044</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.011299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0, 1, 2, 5, 9, 11, 12, 13)</td>\n",
       "      <td>[0.8739608483788806, 0.8225777547049642, 0.858...</td>\n",
       "      <td>0.864417</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...</td>\n",
       "      <td>0.02946</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.011461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0, 1, 2, 5, 9, 11, 12)</td>\n",
       "      <td>[0.8711717821151814, 0.8200765860514128, 0.852...</td>\n",
       "      <td>0.862976</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.012367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 1, 2, 5, 9, 11)</td>\n",
       "      <td>[0.8692647883836426, 0.816441119930167, 0.8502...</td>\n",
       "      <td>0.860757</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight, BOVAG_Guarantee)</td>\n",
       "      <td>0.032665</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.012707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 1, 2, 5, 9)</td>\n",
       "      <td>[0.8685218034303288, 0.8098226298380534, 0.849...</td>\n",
       "      <td>0.858812</td>\n",
       "      <td>(Age_08_04, KM, HP, CC, Weight)</td>\n",
       "      <td>0.035465</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>0.013797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 2, 9)</td>\n",
       "      <td>[0.8591903620338608, 0.8306046098225779, 0.840...</td>\n",
       "      <td>0.855734</td>\n",
       "      <td>(Age_08_04, KM, HP, Weight)</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.009149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1, 9)</td>\n",
       "      <td>[0.8552431427246281, 0.821287671646128, 0.7986...</td>\n",
       "      <td>0.837865</td>\n",
       "      <td>(Age_08_04, KM, Weight)</td>\n",
       "      <td>0.031648</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>0.012312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 9)</td>\n",
       "      <td>[0.7956436929415582, 0.787270788055537, 0.7456...</td>\n",
       "      <td>0.795394</td>\n",
       "      <td>(Age_08_04, Weight)</td>\n",
       "      <td>0.037301</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.014511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>[0.7349323689326035, 0.761324938607378, 0.7043...</td>\n",
       "      <td>0.752469</td>\n",
       "      <td>(Age_08_04,)</td>\n",
       "      <td>0.038216</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.014867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_idx  \\\n",
       "27  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "26  (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "25  (0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "24  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "23  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "22  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "21  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "20  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "19  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "18  (0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 16, ...   \n",
       "17  (0, 1, 2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 18,...   \n",
       "16  (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...   \n",
       "15  (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...   \n",
       "14  (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19...   \n",
       "13    (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18, 19)   \n",
       "12        (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16, 18)   \n",
       "11            (0, 1, 2, 5, 9, 10, 11, 12, 13, 14, 16)   \n",
       "10                (0, 1, 2, 5, 9, 11, 12, 13, 14, 16)   \n",
       "9                     (0, 1, 2, 5, 9, 11, 12, 13, 14)   \n",
       "8                         (0, 1, 2, 5, 9, 11, 12, 13)   \n",
       "7                             (0, 1, 2, 5, 9, 11, 12)   \n",
       "6                                 (0, 1, 2, 5, 9, 11)   \n",
       "5                                     (0, 1, 2, 5, 9)   \n",
       "4                                        (0, 1, 2, 9)   \n",
       "3                                           (0, 1, 9)   \n",
       "2                                              (0, 9)   \n",
       "1                                                (0,)   \n",
       "\n",
       "                                            cv_scores avg_score  \\\n",
       "27  [0.8863244170752315, 0.827205071966563, 0.8733...  0.868367   \n",
       "26  [0.8844535636409472, 0.8395809178729241, 0.872...  0.870093   \n",
       "25  [0.8854663010005633, 0.8407705055712051, 0.872...  0.870637   \n",
       "24  [0.8868613940392011, 0.8414614409460225, 0.872...   0.87095   \n",
       "23  [0.8868613940392011, 0.8414614409460224, 0.872...   0.87095   \n",
       "22  [0.8873092387575998, 0.8414739656024214, 0.872...  0.871045   \n",
       "21  [0.8870230958096587, 0.842110169737685, 0.8725...  0.871203   \n",
       "20  [0.8868814591467499, 0.8422885101750054, 0.872...  0.871437   \n",
       "19  [0.8868897681822827, 0.8422730867222792, 0.872...  0.871489   \n",
       "18  [0.8868897681822828, 0.8422730867222792, 0.872...  0.871489   \n",
       "17  [0.8868897681822828, 0.8422730867222792, 0.872...  0.871489   \n",
       "16  [0.886937132806211, 0.8417821568561511, 0.8718...  0.871302   \n",
       "15  [0.8871785041347496, 0.8405364753290783, 0.871...  0.871021   \n",
       "14  [0.8874442225315381, 0.8395216213237058, 0.871...  0.870512   \n",
       "13  [0.8855293842188675, 0.8376251689853649, 0.872...  0.869996   \n",
       "12  [0.8849922882828418, 0.8369635400356246, 0.873...  0.869722   \n",
       "11  [0.8833822096838134, 0.8356489539445545, 0.869...  0.868875   \n",
       "10  [0.8818206831050115, 0.833604845082666, 0.8685...  0.867832   \n",
       "9   [0.8773516006399763, 0.8231064203982692, 0.862...  0.865688   \n",
       "8   [0.8739608483788806, 0.8225777547049642, 0.858...  0.864417   \n",
       "7   [0.8711717821151814, 0.8200765860514128, 0.852...  0.862976   \n",
       "6   [0.8692647883836426, 0.816441119930167, 0.8502...  0.860757   \n",
       "5   [0.8685218034303288, 0.8098226298380534, 0.849...  0.858812   \n",
       "4   [0.8591903620338608, 0.8306046098225779, 0.840...  0.855734   \n",
       "3   [0.8552431427246281, 0.821287671646128, 0.7986...  0.837865   \n",
       "2   [0.7956436929415582, 0.787270788055537, 0.7456...  0.795394   \n",
       "1   [0.7349323689326035, 0.761324938607378, 0.7043...  0.752469   \n",
       "\n",
       "                                        feature_names  ci_bound   std_dev  \\\n",
       "27  (Age_08_04, KM, HP, Met_Color, Automatic, CC, ...  0.027283  0.021227   \n",
       "26  (Age_08_04, KM, HP, Met_Color, Automatic, CC, ...  0.020377  0.015854   \n",
       "25  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.020021  0.015577   \n",
       "24  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019975  0.015541   \n",
       "23  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019975  0.015541   \n",
       "22  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...   0.02009  0.015631   \n",
       "21  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019728  0.015349   \n",
       "20  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019689  0.015318   \n",
       "19  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019733  0.015353   \n",
       "18  (Age_08_04, KM, HP, Met_Color, CC, Cylinders, ...  0.019733  0.015353   \n",
       "17  (Age_08_04, KM, HP, Met_Color, CC, Weight, Mfr...  0.019733  0.015353   \n",
       "16  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.019985  0.015549   \n",
       "15  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.020668   0.01608   \n",
       "14  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.021021  0.016355   \n",
       "13  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.021519  0.016742   \n",
       "12  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.021657   0.01685   \n",
       "11  (Age_08_04, KM, HP, CC, Weight, Mfr_Guarantee,...  0.022096  0.017192   \n",
       "10  (Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...   0.02274  0.017692   \n",
       "9   (Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...  0.029044  0.022597   \n",
       "8   (Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...   0.02946  0.022921   \n",
       "7   (Age_08_04, KM, HP, CC, Weight, BOVAG_Guarante...  0.031791  0.024735   \n",
       "6    (Age_08_04, KM, HP, CC, Weight, BOVAG_Guarantee)  0.032665  0.025415   \n",
       "5                     (Age_08_04, KM, HP, CC, Weight)  0.035465  0.027593   \n",
       "4                         (Age_08_04, KM, HP, Weight)  0.023517  0.018297   \n",
       "3                             (Age_08_04, KM, Weight)  0.031648  0.024623   \n",
       "2                                 (Age_08_04, Weight)  0.037301  0.029022   \n",
       "1                                        (Age_08_04,)  0.038216  0.029734   \n",
       "\n",
       "     std_err  \n",
       "27  0.010613  \n",
       "26  0.007927  \n",
       "25  0.007788  \n",
       "24  0.007771  \n",
       "23  0.007771  \n",
       "22  0.007815  \n",
       "21  0.007674  \n",
       "20  0.007659  \n",
       "19  0.007676  \n",
       "18  0.007676  \n",
       "17  0.007676  \n",
       "16  0.007774  \n",
       "15   0.00804  \n",
       "14  0.008177  \n",
       "13  0.008371  \n",
       "12  0.008425  \n",
       "11  0.008596  \n",
       "10  0.008846  \n",
       "9   0.011299  \n",
       "8   0.011461  \n",
       "7   0.012367  \n",
       "6   0.012707  \n",
       "5   0.013797  \n",
       "4   0.009149  \n",
       "3   0.012312  \n",
       "2   0.014511  \n",
       "1   0.014867  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(Backward_Selection.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "cc7f5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3b = TDF[['Age_08_04', 'KM', 'Weight']].values\n",
    "y3b = TDF['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9c0803e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3b, y3b, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a97a64cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model3b=LinearRegression()\n",
    "linear_model3b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c4e25141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 1431.4843\n",
      "            Mean Absolute Error (MAE) : 1025.7794\n",
      "          Mean Percentage Error (MPE) : -1.3714\n",
      "Mean Absolute Percentage Error (MAPE) : 10.2303\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -250.3315\n",
      "       Root Mean Squared Error (RMSE) : 1381.9256\n",
      "            Mean Absolute Error (MAE) : 987.3214\n",
      "          Mean Percentage Error (MPE) : -3.1253\n",
      "Mean Absolute Percentage Error (MAPE) : 9.9057\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "# Training Performance\n",
    "regressionSummary(y_train, linear_model3b.predict(X_train))\n",
    "\n",
    "# Test Performance\n",
    "regressionSummary(y_test, linear_model3b.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cf4a9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for training dataset 0.852073868009046\n",
      "R2 for testing dataset 0.8267851083974975\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = linear_model3b.predict(X_train)\n",
    "R2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = linear_model3b.predict(X_test)\n",
    "R2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('R2 for training dataset',R2_train)\n",
    "print('R2 for testing dataset',R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d52afb2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2665.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:00:47</td>     <th>  Log-Likelihood:    </th> <td> -12454.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1436</td>      <th>  AIC:               </th> <td>2.492e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1432</td>      <th>  BIC:               </th> <td>2.494e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>-1880.3356</td> <td>  962.718</td> <td>   -1.953</td> <td> 0.051</td> <td>-3768.825</td> <td>    8.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age_08_04</th> <td> -120.2212</td> <td>    2.742</td> <td>  -43.841</td> <td> 0.000</td> <td> -125.600</td> <td> -114.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KM</th>        <td>   -0.0242</td> <td>    0.001</td> <td>  -20.142</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weight</th>    <td>   19.5760</td> <td>    0.836</td> <td>   23.409</td> <td> 0.000</td> <td>   17.936</td> <td>   21.216</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>221.061</td> <th>  Durbin-Watson:     </th> <td>   1.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2197.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.373</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.013</td>  <th>  Cond. No.          </th> <td>2.01e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.01e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.848\n",
       "Model:                            OLS   Adj. R-squared:                  0.848\n",
       "Method:                 Least Squares   F-statistic:                     2665.\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        13:00:47   Log-Likelihood:                -12454.\n",
       "No. Observations:                1436   AIC:                         2.492e+04\n",
       "Df Residuals:                    1432   BIC:                         2.494e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept  -1880.3356    962.718     -1.953      0.051   -3768.825       8.153\n",
       "Age_08_04   -120.2212      2.742    -43.841      0.000    -125.600    -114.842\n",
       "KM            -0.0242      0.001    -20.142      0.000      -0.027      -0.022\n",
       "Weight        19.5760      0.836     23.409      0.000      17.936      21.216\n",
       "==============================================================================\n",
       "Omnibus:                      221.061   Durbin-Watson:                   1.523\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2197.082\n",
       "Skew:                          -0.373   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.013   Cond. No.                     2.01e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.01e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Complex_Model3a = smf.ols('Price ~ Age_08_04 + KM + Weight', data = TDF).fit()\n",
    "Complex_Model3a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "45ba20f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept =  -4349.485791578851\n",
      "coefficients [-1.19105237e+02 -2.48810345e-02  2.19231205e+01]\n"
     ]
    }
   ],
   "source": [
    "print('intercept = ', linear_model3b.intercept_) # Printing the interecept for linear regression\n",
    "print('coefficients', linear_model3b.coef_ )   # Printing the coefficients for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e256c1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 2=> Price = 36.69290310118993 - 119.105237 * Age_08_04 - 0.0248810345 * KM + 21.9231205 * Weight\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 2=>','Price =', linear_model4.intercept_, '-',1.19105237e+02 ,'* Age_08_04','-', 2.48810345e-02,'* KM', '+', 2.19231205e+01, '* Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13571952",
   "metadata": {},
   "source": [
    "# Take note of any differences in model performance from 1. to 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb2826",
   "metadata": {},
   "source": [
    "\n",
    "MAPE for Model 2 is less than MAPE for model 1, Model 2 performs better than one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e39ed",
   "metadata": {},
   "source": [
    "\n",
    "# Do you notice any major changes in the magnitudes of your parameter estimates?  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadfcca",
   "metadata": {},
   "source": [
    "Considering Age_08_04 feature there is great difference in the change in the magnitudes, for model 1, it is ~171 & model 2 it is  ~ 119."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a821c7d",
   "metadata": {},
   "source": [
    "# Pick one parameter estimate and, in words, describe what it means?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1f373",
   "metadata": {},
   "source": [
    "Considering Age_08_04 here it is negatively correlated to the Price value, so Age_08_04 influences inversly on the Price values, as Age_08_04 increses MEDV value decreases.\n",
    "Older the car less pricey it is, or the price decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ff158",
   "metadata": {},
   "source": [
    "# Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f748def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price', 'Age_08_04', 'KM', 'HP', 'Met_Color', 'Automatic', 'CC',\n",
       "       'Doors', 'Cylinders', 'Gears', 'Weight', 'Mfr_Guarantee',\n",
       "       'BOVAG_Guarantee', 'Guarantee_Period', 'Airco', 'Fuel_Type_CNG',\n",
       "       'Fuel_Type_Diesel', 'Fuel_Type_Petrol', 'Color_Beige', 'Color_Black',\n",
       "       'Color_Blue', 'Color_Green', 'Color_Grey', 'Color_Red', 'Color_Silver',\n",
       "       'Color_Violet', 'Color_White', 'Color_Yellow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDF.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "152ee377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gears</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_Beige</th>\n",
       "      <th>Color_Black</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Grey</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Silver</th>\n",
       "      <th>Color_Violet</th>\n",
       "      <th>Color_White</th>\n",
       "      <th>Color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Age_08_04     KM  HP  Met_Color  Automatic    CC  Doors  Cylinders  \\\n",
       "0  13500         23  46986  90          1          0  2000      3          4   \n",
       "1  13750         23  72937  90          1          0  2000      3          4   \n",
       "2  13950         24  41711  90          1          0  2000      3          4   \n",
       "3  14950         26  48000  90          0          0  2000      3          4   \n",
       "4  13750         30  38500  90          0          0  2000      3          4   \n",
       "\n",
       "   Gears  ...  Color_Beige  Color_Black  Color_Blue  Color_Green  Color_Grey  \\\n",
       "0      5  ...            0            0           1            0           0   \n",
       "1      5  ...            0            0           0            0           0   \n",
       "2      5  ...            0            0           1            0           0   \n",
       "3      5  ...            0            1           0            0           0   \n",
       "4      5  ...            0            1           0            0           0   \n",
       "\n",
       "   Color_Red  Color_Silver  Color_Violet  Color_White  Color_Yellow  \n",
       "0          0             0             0            0             0  \n",
       "1          0             1             0            0             0  \n",
       "2          0             0             0            0             0  \n",
       "3          0             0             0            0             0  \n",
       "4          0             0             0            0             0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "be721a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Predictor  coefficent\n",
      "0          Age_08_04    -112.910\n",
      "1                 KM      -0.019\n",
      "2                 HP      47.252\n",
      "3          Automatic     357.852\n",
      "4                 CC      -2.689\n",
      "5          Cylinders       0.000\n",
      "6              Gears     373.637\n",
      "7             Weight      18.127\n",
      "8      Mfr_Guarantee     222.435\n",
      "9    BOVAG_Guarantee     337.107\n",
      "10             Airco     451.276\n",
      "11     Fuel_Type_CNG   -1851.140\n",
      "12  Fuel_Type_Diesel     867.234\n",
      "13  Fuel_Type_Petrol    -577.389\n",
      "\n",
      "\n",
      "             Train          Test\n",
      "R2    8.670000e-01  5.450000e-01\n",
      "MAE   9.500540e+02  1.029497e+03\n",
      "MAPE  9.300000e+00  9.700000e+00\n",
      "SSE   1.886870e+09  2.138015e+09\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anagbhid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alphas to: original_alphas * n_samples. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting necesaary columns only\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV,LassoCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, r2_score, mean_squared_error\n",
    "predictors = ['Age_08_04', 'KM', 'HP', 'Automatic', 'CC', 'Cylinders', 'Gears', 'Weight', 'Mfr_Guarantee',\n",
    "       'BOVAG_Guarantee', 'Airco', 'Fuel_Type_CNG',\n",
    "       'Fuel_Type_Diesel', 'Fuel_Type_Petrol'\n",
    "             ]\n",
    "X = TDF[predictors]\n",
    "y = TDF['Price']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.25,random_state=1)\n",
    "\n",
    "r_alphas = [0.04,0.06,0.08,0.085,0.09,0.099,.1,0.11,0.2,0.25]\n",
    "\n",
    "model = RidgeCV(alphas=r_alphas,normalize=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "train_test_metrics(X_train,X_test,y_train,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "4d8258ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Alpha Selection:  0.04\n"
     ]
    }
   ],
   "source": [
    "print('LassoCV Alpha Selection: ',model.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c45396b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Form 1 => Price = 20400.557220502684 + [-171.87956797] * Age_08_04\n",
      "\n",
      "Model Form 2=> Price = 36.69290310118993 - 119.105237 * Age_08_04 - 0.0248810345 * KM + 21.9231205 * Weight\n",
      "\n",
      "Model Form 3=> Price = -3806.5227196606593 - 112.91 * Age_08_04 - 0.019 * KM + 47.252 * HP + 357.852 * Automatic - 2.689 * CC 373.637 + * Gears 18.127 + * Weight 222.435 *Mfr_Guarantee 337.107 + * BOVAG_Guarantee 451.276 + * Airco - 1851.14 * Fuel_Type_CNG 867.234 + * Fuel_Type_Diesel - 577.389 * Fuel_Type_Petrol\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE) for model 1 : 12.2215\n",
      "Mean Absolute Percentage Error (MAPE) for model 2 : 9.9057\n",
      "Mean Absolute Percentage Error (MAPE) for model 3 : 9.7000\n"
     ]
    }
   ],
   "source": [
    "print ('Model Form 1 =>','Price =', linear_model3a.intercept_, '+', linear_model3a.coef_, '* Age_08_04')\n",
    "print()\n",
    "print ('Model Form 2=>','Price =', linear_model4.intercept_, '-',1.19105237e+02 ,'* Age_08_04','-', 2.48810345e-02,'* KM', \n",
    "       '+', 2.19231205e+01, '* Weight')\n",
    "print()\n",
    "print ('Model Form 3=>','Price =', model.intercept_, '-',112.910 ,'* Age_08_04','-', 0.019,'* KM', '+',47.252, '* HP', '+', \n",
    "       357.852, '* Automatic', '-', 2.689, '* CC', 373.637, '+','* Gears', 18.127, '+','* Weight', 222.435, \n",
    "       '*Mfr_Guarantee', 337.107, '+', '* BOVAG_Guarantee', 451.276, '+', '* Airco', '-', 1851.140, '* Fuel_Type_CNG', \n",
    "       867.234, '+', '* Fuel_Type_Diesel', '-', 577.389, '* Fuel_Type_Petrol' )\n",
    "\n",
    "print()\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 1 : 12.2215\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 2 : 9.9057\")\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for model 3 : 9.7000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cbb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efece930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
